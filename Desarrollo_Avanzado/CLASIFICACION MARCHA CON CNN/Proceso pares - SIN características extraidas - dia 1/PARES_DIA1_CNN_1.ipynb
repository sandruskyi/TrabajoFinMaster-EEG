{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4: Clasificación con CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con la arquitectura anterior: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primero\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambios realizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevos resultados: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "    \n",
    "    TRAIN                   DEV\n",
    "    loss       accuracy     val_loss    val_accuracy\n",
    "    0.001644\t1.0\t        25.486208\t0.438776\n",
    "    \n",
    "Por tanto: \n",
    "\n",
    "    E = 1 - Accuracy\n",
    "    Etrain = 1 - 1.0\t = 0\n",
    "    Etest = 1 - 0.438776 = 0.561224\n",
    "    \n",
    "    Bias = Etrain - Ehuman = 0\n",
    "    Variance = Etest - Etrain = 0.561224 \n",
    "\n",
    "El bias es muy bajo pero la varianza es muy alta (56%). Para ello habrá que o regularizar, o cambiar la arquitectura (menos neuronas => Mejor varianza, más capas => mayor abstracción), o añadir más datos (cosa que no es posible). \n",
    "\n",
    "Los resultados son horrorosos porque se observa overfitting desde el inicio. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Signal libraries\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROutput:\n",
    "    def __init__(self, task, data):\n",
    "        self.task = task\n",
    "        self.data = data\n",
    "        \n",
    "class OutTaskData: \n",
    "    def __init__(self, task, data): \n",
    "        self.task = task\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "# Primero leemos los registros\n",
    "def read_outputs(rec):\n",
    "    '''read_outputs(\"userS0091f1.mat\")'''\n",
    "    mat = sio.loadmat(rec)\n",
    "    mdata = mat['session']\n",
    "    val = mdata[0,0]\n",
    "    #output = ROutput(np.array(val[\"task\"]), np.array(val[\"data\"]))\n",
    "    output = ROutput(np.array(val[\"task_EEG\"]), np.array(val[\"data_EEG\"]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Perceptron\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "task1 = 402 # SE PUEDE CAMBIAR\n",
    "task2 = 404 # SE PUEDE CAMBIAR\n",
    "task_OneHotEnconding = {402: [1.,0.], 404: [0.,1.]}\n",
    "user = 'W29' # SE PUEDE CAMBIAR\n",
    "day = '0401'\n",
    "folder_day = 'W29-01_04_2021'\n",
    "total_records = 22 # CAMBIAR SI HAY MAS REGISTROS\n",
    "fm = 200\n",
    "electrodes_names_selected = ['F3', 'FZ', 'FC1','FCZ','C1','CZ','CP1','CPZ', 'FC5', 'FC3','C5','C3','CP5','CP3','P3',\n",
    "                             'PZ','F4','FC2','FC4','FC6','C2','C4','CP2','CP4','C6','CP6','P4','HR' ,'HL', 'VU', 'VD']\n",
    "number_channels = len(electrodes_names_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 22\n"
     ]
    }
   ],
   "source": [
    "# Lectura de registros\n",
    "lTaskData = []\n",
    "\n",
    "total_records_used = 0\n",
    "for i_rec in range(1,total_records+1):\n",
    "    i_rec_record = i_rec\n",
    "    if i_rec_record <10:\n",
    "        i_rec_record = \"0\"+str(i_rec_record)\n",
    "    if i_rec % 2 == 0: # Registros impares primero: USUARIO SIN MOVIMIENTO SOLO PENSANDO\n",
    "        record = \"./RegistrosSinProcesar/\"+folder_day+\"/W29_2021\"+day+\"_openloop_\"+str(i_rec_record)+\".mat\"\n",
    "        output = read_outputs(record) # output.task será y, output.data será x\n",
    "\n",
    "        outT = (output.task == task1) | (output.task == task2)\n",
    "\n",
    "        outData = output.data[0:np.shape(output.data)[0], outT[0,:]]\n",
    "        outTask = output.task[0, outT[0,:]]\n",
    "        outTD = OutTaskData(outTask, outData)\n",
    "        lTaskData.append(outTD)\n",
    "        total_records_used+=1\n",
    "\n",
    "print(total_records_used, total_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8, 31, 5600)\n",
      "y_train: (8, 5600)\n",
      "X_dev: (2, 31, 5600)\n",
      "y_dev: (2, 5600)\n",
      "X_test: (1, 31, 5600)\n",
      "y_test: (1, 5600)\n",
      "WINDOWING & ONE HOT ENCODER:\n",
      "X_train: (392, 31, 300, 1)\n",
      "y_train: (392, 2)\n",
      "X_dev: (98, 31, 300, 1)\n",
      "y_dev: (98, 2)\n",
      "X_test: (49, 31, 300, 1)\n",
      "y_test: (49, 2)\n"
     ]
    }
   ],
   "source": [
    "# Vamos a coger 2 registros para el entrenamiento, 1 para el conjunto dev set, 1 para el test set\n",
    "X_train, y_train, X_dev, y_dev, X_test, y_test = [],[],[],[],[],[] \n",
    "for j in range(0,total_records_used-3): # Cogemos 8 registros para entrenamiento\n",
    "    X_train.append(lTaskData[j].data)\n",
    "    y_train.append(lTaskData[j].task)\n",
    "\n",
    "for j in range(total_records_used-3,total_records_used-1): # Cogemos 2 registros para el dev set\n",
    "    X_dev.append(lTaskData[j].data)\n",
    "    y_dev.append(lTaskData[j].task)\n",
    "for j in range(total_records_used-1,total_records_used): # Cogemos 1 registros para el test set\n",
    "    X_test.append(lTaskData[j].data)\n",
    "    y_test.append(lTaskData[j].task)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "#y_train = np.ravel(np.array(y_train))\n",
    "y_train = np.array(y_train)\n",
    "X_dev = np.array(X_dev)\n",
    "#y_dev = np.ravel(np.array(y_dev))\n",
    "y_dev = np.array(y_dev)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "#y_test = np.ravel(np.array(y_test))\n",
    "\n",
    "print (\"X_train:\",X_train.shape)\n",
    "print (\"y_train:\",y_train.shape)\n",
    "print (\"X_dev:\",X_dev.shape)\n",
    "print (\"y_dev:\",y_dev.shape)\n",
    "print (\"X_test:\",X_test.shape)\n",
    "print (\"y_test:\",y_test.shape)\n",
    "\n",
    "\n",
    "# VENTANEO Y ONE HOT ENCODING \n",
    "window = 300\n",
    "samples_advance = 100\n",
    "\n",
    "# Ventaneo X_train\n",
    "\n",
    "X_train_l = []\n",
    "y_train_l = []\n",
    "for num_X_train in range(np.shape(X_train)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_train)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_train)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_train[num_X_train,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_train[num_X_train, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_train_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_train_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_train_l = np.array(X_train_l)\n",
    "y_train_l = np.array(y_train_l)\n",
    "\n",
    "\n",
    "# Ventaneo X_dev\n",
    "X_dev_l = []\n",
    "y_dev_l = []\n",
    "for num_X_dev in range(np.shape(X_dev)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_dev)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_dev)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_dev[num_X_dev,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_dev[num_X_dev, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_dev_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_dev_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_dev_l = np.array(X_dev_l)\n",
    "y_dev_l = np.array(y_dev_l)\n",
    "\n",
    "# Ventaneo X_test\n",
    "X_test_l = []\n",
    "y_test_l = []\n",
    "for num_X_test in range(np.shape(X_test)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_test)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_test)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_test[num_X_test,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_test[num_X_test, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_test_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_test_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_test_l = np.array(X_test_l)\n",
    "y_test_l = np.array(y_test_l)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_l = X_train_l.reshape((np.shape(X_train_l)[0],np.shape(X_train_l)[1],np.shape(X_train_l)[2], 1))\n",
    "X_dev_l = X_dev_l.reshape((np.shape(X_dev_l)[0],np.shape(X_dev_l)[1],np.shape(X_dev_l)[2], 1))\n",
    "X_test_l = X_test_l.reshape((np.shape(X_test_l)[0],np.shape(X_test_l)[1],np.shape(X_test_l)[2], 1))\n",
    "\n",
    "\n",
    "print(\"WINDOWING & ONE HOT ENCODER:\")\n",
    "print (\"X_train:\",X_train_l.shape)\n",
    "print (\"y_train:\",y_train_l.shape)\n",
    "print (\"X_dev:\",X_dev_l.shape)\n",
    "print (\"y_dev:\",y_dev_l.shape)\n",
    "print (\"X_test:\",X_test_l.shape)\n",
    "print (\"y_test:\",y_test_l.shape)\n",
    "\n",
    "X_train = X_train_l\n",
    "y_train = y_train_l\n",
    "X_dev = X_dev_l\n",
    "y_dev = y_dev_l\n",
    "X_test = X_test_l\n",
    "y_test = y_test_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = X_train.shape[1]\n",
    "OUTPUTS = y_train.shape[1]\n",
    "NUM_TRAINING_EXAMPLES = int(round(X_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int(round(y_train.shape[0]/1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data is displayed to test correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[   1.05922842],\n",
       "         [   2.78156328],\n",
       "         [  12.37676525],\n",
       "         ...,\n",
       "         [ -36.37259293],\n",
       "         [ -28.7280426 ],\n",
       "         [ -33.56076813]],\n",
       "\n",
       "        [[  24.22254372],\n",
       "         [  26.2840538 ],\n",
       "         [  35.65241241],\n",
       "         ...,\n",
       "         [ -35.03970718],\n",
       "         [ -27.40374947],\n",
       "         [ -30.37581444]],\n",
       "\n",
       "        [[  13.97421932],\n",
       "         [  15.38177681],\n",
       "         [  22.68283081],\n",
       "         ...,\n",
       "         [ -26.08811378],\n",
       "         [ -18.37837791],\n",
       "         [ -21.90642166]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  53.27894974],\n",
       "         [  59.78120041],\n",
       "         [  74.65661621],\n",
       "         ...,\n",
       "         [-126.25900269],\n",
       "         [-125.80121613],\n",
       "         [-127.17373657]],\n",
       "\n",
       "        [[   2.00171304],\n",
       "         [   3.11324358],\n",
       "         [  16.44838715],\n",
       "         ...,\n",
       "         [ -64.34633636],\n",
       "         [ -60.36686325],\n",
       "         [ -62.32144547]],\n",
       "\n",
       "        [[ -21.72632599],\n",
       "         [ -25.83040619],\n",
       "         [ -29.79340363],\n",
       "         ...,\n",
       "         [  -4.18305111],\n",
       "         [  -8.80941582],\n",
       "         [  -6.68447447]]],\n",
       "\n",
       "\n",
       "       [[[ -25.8978138 ],\n",
       "         [ -18.6819458 ],\n",
       "         [ -26.24561119],\n",
       "         ...,\n",
       "         [ -41.94849014],\n",
       "         [ -58.91005325],\n",
       "         [ -52.42457581]],\n",
       "\n",
       "        [[   4.67067385],\n",
       "         [  10.95300198],\n",
       "         [   3.14939141],\n",
       "         ...,\n",
       "         [ -16.24900627],\n",
       "         [ -33.76229095],\n",
       "         [ -25.99932098]],\n",
       "\n",
       "        [[  -5.42697239],\n",
       "         [   3.11662292],\n",
       "         [  -4.63280869],\n",
       "         ...,\n",
       "         [ -19.36476707],\n",
       "         [ -36.98393631],\n",
       "         [ -28.59781837]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  66.55978394],\n",
       "         [  67.80919647],\n",
       "         [  66.72714996],\n",
       "         ...,\n",
       "         [ -39.30596542],\n",
       "         [ -42.74671936],\n",
       "         [ -49.74935913]],\n",
       "\n",
       "        [[ -40.01016235],\n",
       "         [ -33.93629837],\n",
       "         [ -44.86202621],\n",
       "         ...,\n",
       "         [ -56.28870773],\n",
       "         [ -63.536129  ],\n",
       "         [ -69.40645599]],\n",
       "\n",
       "        [[   9.88655186],\n",
       "         [   4.94187117],\n",
       "         [  -5.91534662],\n",
       "         ...,\n",
       "         [  -8.30506325],\n",
       "         [ -24.11692619],\n",
       "         [ -26.13033295]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-3.55368710e+00],\n",
       "         [-9.55968285e+00],\n",
       "         [-9.63614368e+00],\n",
       "         ...,\n",
       "         [-7.17912979e+01],\n",
       "         [-6.19666786e+01],\n",
       "         [-6.81943359e+01]],\n",
       "\n",
       "        [[ 5.72333860e+00],\n",
       "         [-1.05083883e+00],\n",
       "         [-5.09739447e+00],\n",
       "         ...,\n",
       "         [-5.98232031e+00],\n",
       "         [ 3.29845285e+00],\n",
       "         [ 2.43864250e+00]],\n",
       "\n",
       "        [[ 1.92305679e+01],\n",
       "         [ 1.34838505e+01],\n",
       "         [ 1.12516832e+01],\n",
       "         ...,\n",
       "         [-2.51391363e+00],\n",
       "         [ 7.81327486e+00],\n",
       "         [ 4.11358643e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.28754120e+01],\n",
       "         [-3.01858349e+01],\n",
       "         [-3.36836777e+01],\n",
       "         ...,\n",
       "         [-8.32489777e+00],\n",
       "         [-1.64226377e+00],\n",
       "         [-3.05048561e+00]],\n",
       "\n",
       "        [[-2.09964695e+01],\n",
       "         [-2.87392273e+01],\n",
       "         [-2.88011379e+01],\n",
       "         ...,\n",
       "         [-7.84139557e+01],\n",
       "         [-7.43264313e+01],\n",
       "         [-7.95006485e+01]],\n",
       "\n",
       "        [[ 1.39321632e+01],\n",
       "         [ 1.00164948e+01],\n",
       "         [ 4.83290672e+00],\n",
       "         ...,\n",
       "         [ 6.47140503e+00],\n",
       "         [ 8.78861713e+00],\n",
       "         [-3.21027923e+00]]],\n",
       "\n",
       "\n",
       "       [[[-2.70412135e+00],\n",
       "         [ 1.40344515e-01],\n",
       "         [-2.48797464e+00],\n",
       "         ...,\n",
       "         [-1.24208710e+02],\n",
       "         [-1.30344437e+02],\n",
       "         [-1.17919540e+02]],\n",
       "\n",
       "        [[-1.24002943e+01],\n",
       "         [-8.14046288e+00],\n",
       "         [-7.24236298e+00],\n",
       "         ...,\n",
       "         [-6.49409580e+00],\n",
       "         [-1.09720535e+01],\n",
       "         [ 2.95427871e+00]],\n",
       "\n",
       "        [[ 4.59895468e+00],\n",
       "         [ 8.37252522e+00],\n",
       "         [ 8.56712437e+00],\n",
       "         ...,\n",
       "         [-1.86697197e+01],\n",
       "         [-2.48701248e+01],\n",
       "         [-1.03557940e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.33158798e+01],\n",
       "         [-2.91866188e+01],\n",
       "         [-3.38542786e+01],\n",
       "         ...,\n",
       "         [ 2.07278633e+01],\n",
       "         [ 1.38771029e+01],\n",
       "         [ 1.85666084e+01]],\n",
       "\n",
       "        [[ 6.18390608e+00],\n",
       "         [ 1.33524981e+01],\n",
       "         [ 5.15543652e+00],\n",
       "         ...,\n",
       "         [-1.41995636e+02],\n",
       "         [-1.48501755e+02],\n",
       "         [-1.39249069e+02]],\n",
       "\n",
       "        [[ 2.01151047e+01],\n",
       "         [ 2.85450325e+01],\n",
       "         [ 2.55099354e+01],\n",
       "         ...,\n",
       "         [-1.02244778e+01],\n",
       "         [-1.44616013e+01],\n",
       "         [-7.30726767e+00]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 300, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 31, 300, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 31, 300, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_epochs = 100 #2000\\n#learning_rate = 0.001\\nbatch_size = 32 #250 \\nn_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\\nrate_dropout = [0.8, 0.4, 0.2, 0.1]\\nweight_decay = 1e-4\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "n_epochs = 100 #2000\n",
    "#learning_rate = 0.001\n",
    "batch_size = 32 #250 \n",
    "n_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\n",
    "rate_dropout = [0.8, 0.4, 0.2, 0.1]\n",
    "weight_decay = 1e-4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Build the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 31, 300, 4)        104       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 300, 4)        500       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 150, 4)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 18002     \n",
      "=================================================================\n",
      "Total params: 18,606\n",
      "Trainable params: 18,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, DepthwiseConv2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import optimizers, regularizers\n",
    "import keras.backend as K\n",
    "#K.set_image_data_format('channels_first')\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "# Convolution2D(filtrosConv1, tamaño_filtro1, padding=\"same\", input_shape=(longitud, altura,3), activation = \"relu\")\n",
    "    # - filtrosConv1 número de filtros que aplicaremos tras la primera convolución, normalmente este tamaño va a aumentando\n",
    "    # tras convoluciones para que aumente la dimensión de profundidad (qué cosas hay en mi imagen)\n",
    "    # - tamaño_filtro1 tamaño espacial del kernel (de los filtros)\n",
    "    # - padding = si es same es que es igual que la imagen, vamos crea una imagen del mismo tamaño con el filtro, si es \n",
    "    # valid es que no hay padding y crea una imagen más pequeña que la imagen (creo)\n",
    "    # - input_shape = longitud y altura, tamaño que usará para convolucionar al entrenar\n",
    "    \n",
    "# CAPA PARA FILTRADO TEMPORAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(1,25), padding=\"same\", activation=\"relu\",input_shape=(31, 300,1 ), kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "# CAPA PARA FILTRADO ESPACIAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(31,1), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\"\"\"\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## Siguientes capas convolucionales: \n",
    "model.add(Conv2D(20, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(40, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Conv2D(80, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model.add(Conv2D(160, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\"\"\"\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y_train.shape[1], activation=\"softmax\"))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)        \n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x22a10fab550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x22a101893a0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x22a101c8d30>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x22a101891c0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22a101c8d60>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "conv2d_1\n",
      "max_pooling2d\n",
      "flatten\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers: print (l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the parameters of a layer can bee accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25, 1, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[0].get_weights()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.44220087,  0.47951838, -0.1495584 ,  0.2814844 ]],\n",
       "\n",
       "        [[-0.08136538,  0.14285944, -0.18356423, -0.14026563]],\n",
       "\n",
       "        [[ 0.07580703,  0.6216357 ,  0.02791446,  0.16245803]],\n",
       "\n",
       "        [[ 0.07544646,  0.1302963 , -0.11944715,  0.3621772 ]],\n",
       "\n",
       "        [[-0.22503588,  0.08456223,  0.02495377,  0.18966414]],\n",
       "\n",
       "        [[-0.2775548 ,  0.19017333, -0.53849906, -0.48413688]],\n",
       "\n",
       "        [[ 0.23125237,  0.24391606,  0.33790848,  0.3167078 ]],\n",
       "\n",
       "        [[-0.23781396,  0.54061306, -0.11286288,  0.4634773 ]],\n",
       "\n",
       "        [[ 0.1952087 ,  0.1028397 , -0.03967748, -0.06693976]],\n",
       "\n",
       "        [[-0.0408485 , -0.01955359, -0.11640771,  0.3771775 ]],\n",
       "\n",
       "        [[-0.11479988, -0.55058926, -0.19919781, -0.07410381]],\n",
       "\n",
       "        [[ 0.32748204,  0.3429448 ,  0.20075996, -0.5947161 ]],\n",
       "\n",
       "        [[-0.30248865, -0.22770585,  0.24981858,  0.21587974]],\n",
       "\n",
       "        [[ 0.10652866,  0.31512216,  0.04332427,  0.49300292]],\n",
       "\n",
       "        [[ 0.04224205, -0.37094644, -0.20146619, -0.31922007]],\n",
       "\n",
       "        [[-0.44015706, -0.07886018,  0.3604567 ,  0.33659163]],\n",
       "\n",
       "        [[-0.00308155,  0.29205713, -0.16121353,  0.29803187]],\n",
       "\n",
       "        [[-0.49376634, -0.2604567 , -0.10833694,  0.4385943 ]],\n",
       "\n",
       "        [[-0.339438  , -0.03651293, -0.01264303, -0.29909384]],\n",
       "\n",
       "        [[ 0.25019985,  0.21774419,  0.51203626,  0.27948314]],\n",
       "\n",
       "        [[-0.04978361, -0.63296497, -0.29975337,  0.3609811 ]],\n",
       "\n",
       "        [[-0.6231827 , -0.3365249 , -0.24848695,  0.30265135]],\n",
       "\n",
       "        [[-0.16179003, -0.16721487, -0.20533918,  0.15937802]],\n",
       "\n",
       "        [[-0.27063024,  0.11974288,  0.45869017,  0.04930328]],\n",
       "\n",
       "        [[ 0.30491912, -0.03433473, -0.24030265, -0.27650112]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases # Bias de la primera capa: 500 bias inicializados a 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train the model with M-BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 - 4s - loss: 62.7929 - accuracy: 0.5026 - val_loss: 81.3823 - val_accuracy: 0.5306\n",
      "Epoch 2/100\n",
      "13/13 - 3s - loss: 44.0392 - accuracy: 0.5459 - val_loss: 52.3169 - val_accuracy: 0.5102\n",
      "Epoch 3/100\n",
      "13/13 - 2s - loss: 8.9048 - accuracy: 0.6760 - val_loss: 40.1801 - val_accuracy: 0.4694\n",
      "Epoch 4/100\n",
      "13/13 - 2s - loss: 5.8458 - accuracy: 0.7321 - val_loss: 84.6925 - val_accuracy: 0.4388\n",
      "Epoch 5/100\n",
      "13/13 - 3s - loss: 4.9642 - accuracy: 0.7602 - val_loss: 24.7838 - val_accuracy: 0.4694\n",
      "Epoch 6/100\n",
      "13/13 - 2s - loss: 3.5882 - accuracy: 0.7653 - val_loss: 46.5637 - val_accuracy: 0.4694\n",
      "Epoch 7/100\n",
      "13/13 - 2s - loss: 2.1385 - accuracy: 0.8291 - val_loss: 25.0629 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "13/13 - 2s - loss: 1.7417 - accuracy: 0.8342 - val_loss: 41.3813 - val_accuracy: 0.4694\n",
      "Epoch 9/100\n",
      "13/13 - 2s - loss: 0.9096 - accuracy: 0.8878 - val_loss: 19.5101 - val_accuracy: 0.5306\n",
      "Epoch 10/100\n",
      "13/13 - 2s - loss: 0.7957 - accuracy: 0.8852 - val_loss: 26.4046 - val_accuracy: 0.4592\n",
      "Epoch 11/100\n",
      "13/13 - 2s - loss: 1.2666 - accuracy: 0.8546 - val_loss: 27.3114 - val_accuracy: 0.4592\n",
      "Epoch 12/100\n",
      "13/13 - 2s - loss: 1.1197 - accuracy: 0.8673 - val_loss: 27.7906 - val_accuracy: 0.4082\n",
      "Epoch 13/100\n",
      "13/13 - 2s - loss: 0.4657 - accuracy: 0.9388 - val_loss: 45.6116 - val_accuracy: 0.4796\n",
      "Epoch 14/100\n",
      "13/13 - 2s - loss: 1.0104 - accuracy: 0.8724 - val_loss: 24.7982 - val_accuracy: 0.4490\n",
      "Epoch 15/100\n",
      "13/13 - 2s - loss: 0.5097 - accuracy: 0.9133 - val_loss: 23.6227 - val_accuracy: 0.4286\n",
      "Epoch 16/100\n",
      "13/13 - 2s - loss: 0.1189 - accuracy: 0.9617 - val_loss: 30.9698 - val_accuracy: 0.4694\n",
      "Epoch 17/100\n",
      "13/13 - 2s - loss: 0.1916 - accuracy: 0.9515 - val_loss: 28.7259 - val_accuracy: 0.4490\n",
      "Epoch 18/100\n",
      "13/13 - 2s - loss: 0.1298 - accuracy: 0.9694 - val_loss: 27.9165 - val_accuracy: 0.4694\n",
      "Epoch 19/100\n",
      "13/13 - 3s - loss: 0.0168 - accuracy: 0.9949 - val_loss: 29.2838 - val_accuracy: 0.4082\n",
      "Epoch 20/100\n",
      "13/13 - 2s - loss: 0.0261 - accuracy: 0.9949 - val_loss: 19.9607 - val_accuracy: 0.4796\n",
      "Epoch 21/100\n",
      "13/13 - 2s - loss: 0.0106 - accuracy: 0.9949 - val_loss: 28.0610 - val_accuracy: 0.4388\n",
      "Epoch 22/100\n",
      "13/13 - 3s - loss: 0.0067 - accuracy: 0.9974 - val_loss: 24.1923 - val_accuracy: 0.4388\n",
      "Epoch 23/100\n",
      "13/13 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 23.4050 - val_accuracy: 0.4388\n",
      "Epoch 24/100\n",
      "13/13 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 24.7302 - val_accuracy: 0.4388\n",
      "Epoch 25/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.2918 - val_accuracy: 0.4286\n",
      "Epoch 26/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4801 - val_accuracy: 0.4286\n",
      "Epoch 27/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5449 - val_accuracy: 0.4286\n",
      "Epoch 28/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5134 - val_accuracy: 0.4286\n",
      "Epoch 29/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4684 - val_accuracy: 0.4286\n",
      "Epoch 30/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4753 - val_accuracy: 0.4286\n",
      "Epoch 31/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4384 - val_accuracy: 0.4286\n",
      "Epoch 32/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4826 - val_accuracy: 0.4286\n",
      "Epoch 33/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4583 - val_accuracy: 0.4286\n",
      "Epoch 34/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5503 - val_accuracy: 0.4286\n",
      "Epoch 35/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5849 - val_accuracy: 0.4286\n",
      "Epoch 36/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5944 - val_accuracy: 0.4286\n",
      "Epoch 37/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5049 - val_accuracy: 0.4286\n",
      "Epoch 38/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4921 - val_accuracy: 0.4286\n",
      "Epoch 39/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4827 - val_accuracy: 0.4286\n",
      "Epoch 40/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4989 - val_accuracy: 0.4286\n",
      "Epoch 41/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5154 - val_accuracy: 0.4286\n",
      "Epoch 42/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5662 - val_accuracy: 0.4286\n",
      "Epoch 43/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5722 - val_accuracy: 0.4286\n",
      "Epoch 44/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5368 - val_accuracy: 0.4286\n",
      "Epoch 45/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5492 - val_accuracy: 0.4286\n",
      "Epoch 46/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5363 - val_accuracy: 0.4286\n",
      "Epoch 47/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5195 - val_accuracy: 0.4388\n",
      "Epoch 48/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5244 - val_accuracy: 0.4388\n",
      "Epoch 49/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5151 - val_accuracy: 0.4388\n",
      "Epoch 50/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5329 - val_accuracy: 0.4388\n",
      "Epoch 51/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5359 - val_accuracy: 0.4388\n",
      "Epoch 52/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5330 - val_accuracy: 0.4388\n",
      "Epoch 53/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5179 - val_accuracy: 0.4388\n",
      "Epoch 54/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4903 - val_accuracy: 0.4388\n",
      "Epoch 55/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5066 - val_accuracy: 0.4388\n",
      "Epoch 56/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4668 - val_accuracy: 0.4388\n",
      "Epoch 57/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4056 - val_accuracy: 0.4388\n",
      "Epoch 58/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4230 - val_accuracy: 0.4388\n",
      "Epoch 59/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.3863 - val_accuracy: 0.4388\n",
      "Epoch 60/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4441 - val_accuracy: 0.4388\n",
      "Epoch 61/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4743 - val_accuracy: 0.4388\n",
      "Epoch 62/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4891 - val_accuracy: 0.4388\n",
      "Epoch 63/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5440 - val_accuracy: 0.4388\n",
      "Epoch 64/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5911 - val_accuracy: 0.4388\n",
      "Epoch 65/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5749 - val_accuracy: 0.4388\n",
      "Epoch 66/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5676 - val_accuracy: 0.4388\n",
      "Epoch 67/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5427 - val_accuracy: 0.4388\n",
      "Epoch 68/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5175 - val_accuracy: 0.4388\n",
      "Epoch 69/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4994 - val_accuracy: 0.4388\n",
      "Epoch 70/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4783 - val_accuracy: 0.4388\n",
      "Epoch 71/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4794 - val_accuracy: 0.4388\n",
      "Epoch 72/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4778 - val_accuracy: 0.4388\n",
      "Epoch 73/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4592 - val_accuracy: 0.4388\n",
      "Epoch 74/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4974 - val_accuracy: 0.4388\n",
      "Epoch 75/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5413 - val_accuracy: 0.4388\n",
      "Epoch 76/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5398 - val_accuracy: 0.4388\n",
      "Epoch 77/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5216 - val_accuracy: 0.4388\n",
      "Epoch 78/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5099 - val_accuracy: 0.4388\n",
      "Epoch 79/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5172 - val_accuracy: 0.4388\n",
      "Epoch 80/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.5033 - val_accuracy: 0.4388\n",
      "Epoch 81/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4962 - val_accuracy: 0.4388\n",
      "Epoch 82/100\n",
      "13/13 - 3s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4975 - val_accuracy: 0.4388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "13/13 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 25.4987 - val_accuracy: 0.4388\n",
      "Epoch 84/100\n",
      "13/13 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.5092 - val_accuracy: 0.4388\n",
      "Epoch 85/100\n",
      "13/13 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.5177 - val_accuracy: 0.4388\n",
      "Epoch 86/100\n",
      "13/13 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.4925 - val_accuracy: 0.4388\n",
      "Epoch 87/100\n",
      "13/13 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.4815 - val_accuracy: 0.4388\n",
      "Epoch 88/100\n",
      "13/13 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.4991 - val_accuracy: 0.4388\n",
      "Epoch 89/100\n",
      "13/13 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.4859 - val_accuracy: 0.4388\n",
      "Epoch 90/100\n",
      "13/13 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.4742 - val_accuracy: 0.4388\n",
      "Epoch 91/100\n",
      "13/13 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.4666 - val_accuracy: 0.4388\n",
      "Epoch 92/100\n",
      "13/13 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.4783 - val_accuracy: 0.4388\n",
      "Epoch 93/100\n",
      "13/13 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.4681 - val_accuracy: 0.4388\n",
      "Epoch 94/100\n",
      "13/13 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.4701 - val_accuracy: 0.4388\n",
      "Epoch 95/100\n",
      "13/13 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.4893 - val_accuracy: 0.4388\n",
      "Epoch 96/100\n",
      "13/13 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.5245 - val_accuracy: 0.4388\n",
      "Epoch 97/100\n",
      "13/13 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.5250 - val_accuracy: 0.4388\n",
      "Epoch 98/100\n",
      "13/13 - 3s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.5094 - val_accuracy: 0.4388\n",
      "Epoch 99/100\n",
      "13/13 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.5059 - val_accuracy: 0.4388\n",
      "Epoch 100/100\n",
      "13/13 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 25.4862 - val_accuracy: 0.4388\n",
      "252.00467371940613\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#history = model.fit(X_train, y_train, batch_size=32, steps_per_epoch=len(y_train)/32, epochs=100, verbose=2, validation_data=(X_dev, y_dev),callbacks=[tensorboard])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=2, validation_data=(X_dev, y_dev))\n",
    "print (time.time() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=pd.DataFrame(history.history)\n",
    "results.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel (\"Epochs\")\n",
    "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
    "plt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "# categorical_accuracy es el training accuracy\n",
    "# val_categorical_accuracy es el validation accuracy\n",
    "# loss es el training loss\n",
    "# val_loss es el validation loss\n",
    "\n",
    "# Overfitting:\n",
    "# Por un lado la Accuracy de los datos de entrenamiento aumenta con las epochs,\n",
    "# mientras que la Accuracy de los datos de validación disminuye o se mantiene constante a lo largo de las epochs. \n",
    "# La Loss de los datos de validación alcanza su mínimo después de pocos epochs y luego empieza a subir, \n",
    "# mientras que la Loss de los datos de entrenamiento disminuye linealmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 2, 'epochs': 100, 'steps': 13}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.001644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.486208</td>\n",
       "      <td>0.438776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy   val_loss  val_accuracy\n",
       "99  0.001644       1.0  25.486208      0.438776"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set:  1.0\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the training set: \", results.values[-1:][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the development test set:  0.43877550959587097\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the development test set: \", results.values[-1:][0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how the model predicts using the development test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions=model.predict(X_dev).round(2) \n",
    "dev_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_rounded_predictions=np.round(dev_predictions)\n",
    "indices = np.argmax(dev_predictions,1)\n",
    "for row, index in zip(dev_rounded_predictions, indices): row[index]=1\n",
    "dev_rounded_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True False  True  True  True  True  True False False\n",
      " False  True False False False False False False False False False  True\n",
      "  True False False False False False]\n"
     ]
    }
   ],
   "source": [
    "dev_correct_predictions = np.equal(np.argmax(dev_rounded_predictions,1),np.argmax(y_dev,1))\n",
    "print (dev_correct_predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 43, False: 55})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter (dev_correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model if it is better than others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "model.save('./Modelos/CNN_model1_PARES_DIA1.h5') # Change the name in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnew_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\\n\\nimport numpy as np\\n\\n# Verify state\\nnew_predictions = new_model.predict(X_dev)\\nnp.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\\n\\n# Note that the optimizer state is also preserved:\\n# you can resume training where you left off.\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract\n",
    "\"\"\"\n",
    "new_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Verify state\n",
    "new_predictions = new_model.predict(X_dev)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is also preserved:\n",
    "# you can resume training where you left off.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Final Test\n",
    "\n",
    "#### 10.1 - Load the final test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.pipeline import make_pipeline\\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\\nfrom sklearn.linear_model import Perceptron\\n\\ntotal_records = 4 # CAMBIAR SI HAY MAS REGISTROS\\n\\ntask1 = 122 # SE PUEDE CAMBIAR\\ntask2 = 123 # SE PUEDE CAMBIAR\\ntask3 = 127 # SE PUEDE CAMBIAR\\nusers = [\"0091\"] # SE PUEDE CAMBIAR\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "total_records = 4 # CAMBIAR SI HAY MAS REGISTROS\n",
    "\n",
    "task1 = 122 # SE PUEDE CAMBIAR\n",
    "task2 = 123 # SE PUEDE CAMBIAR\n",
    "task3 = 127 # SE PUEDE CAMBIAR\n",
    "users = [\"0091\"] # SE PUEDE CAMBIAR\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef readRegisterAndReturnXy(user, total_records, task1, task2, task3 = \"\"):\\n    lTaskData = []\\n    for i_rec in range(1,total_records+1):\\n            record = \"userS\"+user+\"f\"+str(i_rec)+\".mat\"\\n            output = read_outputs(record) # output.task será y, output.data será x\\n\\n            if task3 != \"\":\\n                outT = (output.task == task1) | (output.task == task2) | (output.task == task3) \\n            else: \\n                outT = (output.task == task1) | (output.task == task2)\\n            outData = output.data[outT[:,0],0:np.shape(output.data)[1]]\\n\\n            outTask = output.task[outT[:,0]]\\n            outTD = OutTaskData(outTask, outData)\\n            lTaskData.append(outTD)\\n\\n    X_test, y_test = [],[]\\n    for j in range(0,total_records):\\n        X_test.extend(lTaskData[j].data)\\n        y_test.extend(lTaskData[j].task)\\n\\n    X_test = np.array(X_test)\\n    y_test = np.ravel(np.array(y_test))\\n\\n    print (\"X_test:\",X_test.shape)\\n    print (\"y_test:\",y_test.shape)\\n\\n    # ONE HOT ENCODER\\n    encoder = make_pipeline(StandardScaler(), OneHotEncoder(categories=\"auto\", sparse=False)) # Function that one-hot encodes integers))\\n    y_test = encoder.fit_transform (y_test.reshape(-1,1)) # y_one_hot\\n\\n    print(\"ONE HOT ENCODER:\")\\n    print (\"X_test:\",X_test.shape)\\n    print (\"y_test:\",y_test.shape)\\n    \\n    return X_test, y_test\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def readRegisterAndReturnXy(user, total_records, task1, task2, task3 = \"\"):\n",
    "    lTaskData = []\n",
    "    for i_rec in range(1,total_records+1):\n",
    "            record = \"userS\"+user+\"f\"+str(i_rec)+\".mat\"\n",
    "            output = read_outputs(record) # output.task será y, output.data será x\n",
    "\n",
    "            if task3 != \"\":\n",
    "                outT = (output.task == task1) | (output.task == task2) | (output.task == task3) \n",
    "            else: \n",
    "                outT = (output.task == task1) | (output.task == task2)\n",
    "            outData = output.data[outT[:,0],0:np.shape(output.data)[1]]\n",
    "\n",
    "            outTask = output.task[outT[:,0]]\n",
    "            outTD = OutTaskData(outTask, outData)\n",
    "            lTaskData.append(outTD)\n",
    "\n",
    "    X_test, y_test = [],[]\n",
    "    for j in range(0,total_records):\n",
    "        X_test.extend(lTaskData[j].data)\n",
    "        y_test.extend(lTaskData[j].task)\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.ravel(np.array(y_test))\n",
    "\n",
    "    print (\"X_test:\",X_test.shape)\n",
    "    print (\"y_test:\",y_test.shape)\n",
    "\n",
    "    # ONE HOT ENCODER\n",
    "    encoder = make_pipeline(StandardScaler(), OneHotEncoder(categories=\"auto\", sparse=False)) # Function that one-hot encodes integers))\n",
    "    y_test = encoder.fit_transform (y_test.reshape(-1,1)) # y_one_hot\n",
    "\n",
    "    print(\"ONE HOT ENCODER:\")\n",
    "    print (\"X_test:\",X_test.shape)\n",
    "    print (\"y_test:\",y_test.shape)\n",
    "    \n",
    "    return X_test, y_test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_final_test = n_instances-n_train-n_dev\\n\\nx_final_test = attributes.values[n_train+n_dev:n_instances]\\nt_final_test = label.values[n_train+n_dev:n_instances]\\n\\nprint (\"x_test:\",x_final_test.shape)\\nprint (\"t_test:\",t_final_test.shape)\\n\\n\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "n_final_test = n_instances-n_train-n_dev\n",
    "\n",
    "x_final_test = attributes.values[n_train+n_dev:n_instances]\n",
    "t_final_test = label.values[n_train+n_dev:n_instances]\n",
    "\n",
    "print (\"x_test:\",x_final_test.shape)\n",
    "print (\"t_test:\",t_final_test.shape)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-42-01c14ef9ee9b>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-42-01c14ef9ee9b>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    return final_test_prediction_results, success\u001b[0m\n\u001b[1;37m                                                 \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from collections import Counter\n",
    "def predictWithModel(model, X_test, y_test, task1, task2, task3=\"\"):\n",
    "    model.evaluate(X_test, y_test)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_rounded_predictions=np.round(test_predictions)\n",
    "    indices = np.argmax(test_predictions,1)\n",
    "    for row, index in zip(test_rounded_predictions, indices): row[index]=1\n",
    "    print(test_rounded_predictions[:20])\n",
    "    \n",
    "    # ACCURACY:\n",
    "    test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(y_test,1))\n",
    "    print()\n",
    "    print(test_correct_predictions)\n",
    "    print(type(test_correct_predictions))\n",
    "    final_test_prediction_results=Counter(test_correct_predictions)\n",
    "    \n",
    "    success = np.mean(test_rounded_predictions == y_test)*100\n",
    "    \n",
    "    return final_test_prediction_results, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#X_test, y_test = readRegisterAndReturnXy(u, total_records, 122, 123, 127)\n",
    "accuracy, success = predictWithModel(model, X_test, y_test, 402,404)\n",
    "print(accuracy, success)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(x_final_test, t_final_test) # Un 77 es un accuracy bajo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs computed by the neural network for the final testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test_predictions=model.predict(x_final_test)\n",
    "test_rounded_predictions=np.round(test_predictions)\n",
    "indices = np.argmax(test_predictions,1)\n",
    "for row, index in zip(test_rounded_predictions, indices): row[index]=1\n",
    "test_rounded_predictions[:20]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_final_test[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 30 predictions. True means that the neural network correctly classifies the input vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(t_final_test,1))\n",
    "# test_correct_predictions[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from collections import Counter\n",
    "final_test_prediction_results=Counter(test_correct_predictions)\n",
    "final_test_prediction_results\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test_prediction_results[True]/sum(final_test_prediction_results.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
