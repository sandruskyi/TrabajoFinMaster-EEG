{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4: Clasificación con CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con la arquitectura anterior: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primero\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambios realizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevos resultados: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "    \n",
    "    TRAIN                   DEV\n",
    "    loss       accuracy     val_loss    val_accuracy\n",
    "    0.002013\t1.0\t        2.635027\t0.571429\n",
    "    \n",
    "Por tanto: \n",
    "\n",
    "    E = 1 - Accuracy\n",
    "    Etrain = 1 - 1.0\t = 0\n",
    "    Etest = 1 - 0.571429 = 0.428571\n",
    "    \n",
    "    Bias = Etrain - Ehuman = 0\n",
    "    Variance = Etest - Etrain = 0.428571\n",
    "\n",
    "El bias es muy bajo pero la varianza es muy alta (42%). Para ello habrá que o regularizar, o cambiar la arquitectura (menos neuronas => Mejor varianza, más capas => mayor abstracción), o añadir más datos (cosa que no es posible). \n",
    "\n",
    "Los resultados son horrorosos porque se observa overfitting desde el inicio. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Signal libraries\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROutput:\n",
    "    def __init__(self, task, data):\n",
    "        self.task = task\n",
    "        self.data = data\n",
    "        \n",
    "class OutTaskData: \n",
    "    def __init__(self, task, data): \n",
    "        self.task = task\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "# Primero leemos los registros\n",
    "def read_outputs(rec):\n",
    "    '''read_outputs(\"userS0091f1.mat\")'''\n",
    "    mat = sio.loadmat(rec)\n",
    "    mdata = mat['session']\n",
    "    val = mdata[0,0]\n",
    "    #output = ROutput(np.array(val[\"task\"]), np.array(val[\"data\"]))\n",
    "    output = ROutput(np.array(val[\"task_EEG\"]), np.array(val[\"data_EEG\"]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Perceptron\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "task1 = 402 # SE PUEDE CAMBIAR\n",
    "task2 = 404 # SE PUEDE CAMBIAR\n",
    "task_OneHotEnconding = {402: [1.,0.], 404: [0.,1.]}\n",
    "user = 'W29' # SE PUEDE CAMBIAR\n",
    "day = '0329'\n",
    "folder_day = 'W29-29_03_2021'\n",
    "total_records = 22 # CAMBIAR SI HAY MAS REGISTROS\n",
    "fm = 200\n",
    "electrodes_names_selected = ['F3', 'FZ', 'FC1','FCZ','C1','CZ','CP1','CPZ', 'FC5', 'FC3','C5','C3','CP5','CP3','P3',\n",
    "                             'PZ','F4','FC2','FC4','FC6','C2','C4','CP2','CP4','C6','CP6','P4','HR' ,'HL', 'VU', 'VD']\n",
    "number_channels = len(electrodes_names_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 22\n"
     ]
    }
   ],
   "source": [
    "# Lectura de registros\n",
    "lTaskData = []\n",
    "\n",
    "total_records_used = 0\n",
    "for i_rec in range(1,total_records+1):\n",
    "    i_rec_record = i_rec\n",
    "    if i_rec_record <10:\n",
    "        i_rec_record = \"0\"+str(i_rec_record)\n",
    "    if i_rec % 2 == 0: # Registros impares primero: USUARIO SIN MOVIMIENTO SOLO PENSANDO\n",
    "        record = \"./RegistrosSinProcesar/\"+folder_day+\"/W29_2021\"+day+\"_openloop_\"+str(i_rec_record)+\".mat\"\n",
    "        output = read_outputs(record) # output.task será y, output.data será x\n",
    "\n",
    "        outT = (output.task == task1) | (output.task == task2)\n",
    "\n",
    "        outData = output.data[0:np.shape(output.data)[0], outT[0,:]]\n",
    "        outTask = output.task[0, outT[0,:]]\n",
    "        outTD = OutTaskData(outTask, outData)\n",
    "        lTaskData.append(outTD)\n",
    "        total_records_used+=1\n",
    "\n",
    "print(total_records_used, total_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8, 31, 5600)\n",
      "y_train: (8, 5600)\n",
      "X_dev: (2, 31, 5600)\n",
      "y_dev: (2, 5600)\n",
      "X_test: (1, 31, 5600)\n",
      "y_test: (1, 5600)\n",
      "WINDOWING & ONE HOT ENCODER:\n",
      "X_train: (392, 31, 300, 1)\n",
      "y_train: (392, 2)\n",
      "X_dev: (98, 31, 300, 1)\n",
      "y_dev: (98, 2)\n",
      "X_test: (49, 31, 300, 1)\n",
      "y_test: (49, 2)\n"
     ]
    }
   ],
   "source": [
    "# Vamos a coger 2 registros para el entrenamiento, 1 para el conjunto dev set, 1 para el test set\n",
    "X_train, y_train, X_dev, y_dev, X_test, y_test = [],[],[],[],[],[] \n",
    "for j in range(0,total_records_used-3): # Cogemos 8 registros para entrenamiento\n",
    "    X_train.append(lTaskData[j].data)\n",
    "    y_train.append(lTaskData[j].task)\n",
    "\n",
    "for j in range(total_records_used-3,total_records_used-1): # Cogemos 2 registros para el dev set\n",
    "    X_dev.append(lTaskData[j].data)\n",
    "    y_dev.append(lTaskData[j].task)\n",
    "for j in range(total_records_used-1,total_records_used): # Cogemos 1 registros para el test set\n",
    "    X_test.append(lTaskData[j].data)\n",
    "    y_test.append(lTaskData[j].task)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "#y_train = np.ravel(np.array(y_train))\n",
    "y_train = np.array(y_train)\n",
    "X_dev = np.array(X_dev)\n",
    "#y_dev = np.ravel(np.array(y_dev))\n",
    "y_dev = np.array(y_dev)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "#y_test = np.ravel(np.array(y_test))\n",
    "\n",
    "print (\"X_train:\",X_train.shape)\n",
    "print (\"y_train:\",y_train.shape)\n",
    "print (\"X_dev:\",X_dev.shape)\n",
    "print (\"y_dev:\",y_dev.shape)\n",
    "print (\"X_test:\",X_test.shape)\n",
    "print (\"y_test:\",y_test.shape)\n",
    "\n",
    "\n",
    "# VENTANEO Y ONE HOT ENCODING \n",
    "window = 300\n",
    "samples_advance = 100\n",
    "\n",
    "# Ventaneo X_train\n",
    "\n",
    "X_train_l = []\n",
    "y_train_l = []\n",
    "for num_X_train in range(np.shape(X_train)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_train)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_train)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_train[num_X_train,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_train[num_X_train, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_train_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_train_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_train_l = np.array(X_train_l)\n",
    "y_train_l = np.array(y_train_l)\n",
    "\n",
    "\n",
    "# Ventaneo X_dev\n",
    "X_dev_l = []\n",
    "y_dev_l = []\n",
    "for num_X_dev in range(np.shape(X_dev)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_dev)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_dev)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_dev[num_X_dev,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_dev[num_X_dev, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_dev_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_dev_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_dev_l = np.array(X_dev_l)\n",
    "y_dev_l = np.array(y_dev_l)\n",
    "\n",
    "# Ventaneo X_test\n",
    "X_test_l = []\n",
    "y_test_l = []\n",
    "for num_X_test in range(np.shape(X_test)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_test)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_test)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_test[num_X_test,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_test[num_X_test, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_test_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_test_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_test_l = np.array(X_test_l)\n",
    "y_test_l = np.array(y_test_l)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_l = X_train_l.reshape((np.shape(X_train_l)[0],np.shape(X_train_l)[1],np.shape(X_train_l)[2], 1))\n",
    "X_dev_l = X_dev_l.reshape((np.shape(X_dev_l)[0],np.shape(X_dev_l)[1],np.shape(X_dev_l)[2], 1))\n",
    "X_test_l = X_test_l.reshape((np.shape(X_test_l)[0],np.shape(X_test_l)[1],np.shape(X_test_l)[2], 1))\n",
    "\n",
    "\n",
    "print(\"WINDOWING & ONE HOT ENCODER:\")\n",
    "print (\"X_train:\",X_train_l.shape)\n",
    "print (\"y_train:\",y_train_l.shape)\n",
    "print (\"X_dev:\",X_dev_l.shape)\n",
    "print (\"y_dev:\",y_dev_l.shape)\n",
    "print (\"X_test:\",X_test_l.shape)\n",
    "print (\"y_test:\",y_test_l.shape)\n",
    "\n",
    "X_train = X_train_l\n",
    "y_train = y_train_l\n",
    "X_dev = X_dev_l\n",
    "y_dev = y_dev_l\n",
    "X_test = X_test_l\n",
    "y_test = y_test_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = X_train.shape[1]\n",
    "OUTPUTS = y_train.shape[1]\n",
    "NUM_TRAINING_EXAMPLES = int(round(X_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int(round(y_train.shape[0]/1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data is displayed to test correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -1.46285617],\n",
       "         [  9.24858856],\n",
       "         [ 13.06202602],\n",
       "         ...,\n",
       "         [ 11.49806309],\n",
       "         [  4.27961063],\n",
       "         [ -7.35561275]],\n",
       "\n",
       "        [[ -0.19728436],\n",
       "         [  8.24236679],\n",
       "         [ 14.47707558],\n",
       "         ...,\n",
       "         [  2.49278688],\n",
       "         [ -8.74694061],\n",
       "         [-20.32823753]],\n",
       "\n",
       "        [[ -1.65373003],\n",
       "         [  7.5358305 ],\n",
       "         [ 11.9251194 ],\n",
       "         ...,\n",
       "         [ 14.22552776],\n",
       "         [  4.08782578],\n",
       "         [ -7.53046656]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -4.07560062],\n",
       "         [  2.41723967],\n",
       "         [  6.71837902],\n",
       "         ...,\n",
       "         [-16.94368744],\n",
       "         [-20.40544701],\n",
       "         [-28.18542099]],\n",
       "\n",
       "        [[ -0.48136061],\n",
       "         [  6.88277721],\n",
       "         [ 12.5394392 ],\n",
       "         ...,\n",
       "         [  6.86390543],\n",
       "         [ -0.96397668],\n",
       "         [-14.22110939]],\n",
       "\n",
       "        [[-10.04507351],\n",
       "         [-10.92294979],\n",
       "         [-12.16240215],\n",
       "         ...,\n",
       "         [ 19.16641235],\n",
       "         [ 16.05260277],\n",
       "         [  6.45253038]]],\n",
       "\n",
       "\n",
       "       [[[ -0.18412772],\n",
       "         [ -1.46684313],\n",
       "         [ -4.44646168],\n",
       "         ...,\n",
       "         [  2.61015964],\n",
       "         [  4.37181473],\n",
       "         [  2.31093431]],\n",
       "\n",
       "        [[  6.18472481],\n",
       "         [  5.37613392],\n",
       "         [  3.59826875],\n",
       "         ...,\n",
       "         [  7.95284939],\n",
       "         [  9.16329384],\n",
       "         [  7.01533699]],\n",
       "\n",
       "        [[  3.18457246],\n",
       "         [  2.81973338],\n",
       "         [  1.14940405],\n",
       "         ...,\n",
       "         [  9.88821602],\n",
       "         [ 12.2958107 ],\n",
       "         [  9.69403839]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-32.33745956],\n",
       "         [-35.87310028],\n",
       "         [-40.26018143],\n",
       "         ...,\n",
       "         [-24.55429459],\n",
       "         [-20.1878376 ],\n",
       "         [-22.15607643]],\n",
       "\n",
       "        [[ 13.80256176],\n",
       "         [  7.8867712 ],\n",
       "         [  3.23322511],\n",
       "         ...,\n",
       "         [  1.22555101],\n",
       "         [  2.73482084],\n",
       "         [  2.08545613]],\n",
       "\n",
       "        [[-18.99699402],\n",
       "         [-39.28790665],\n",
       "         [-31.01504135],\n",
       "         ...,\n",
       "         [  1.75268137],\n",
       "         [  1.57163   ],\n",
       "         [-10.58273602]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-14.11002541],\n",
       "         [-17.80276108],\n",
       "         [-17.5953598 ],\n",
       "         ...,\n",
       "         [-11.3914566 ],\n",
       "         [-17.96568298],\n",
       "         [-22.35505676]],\n",
       "\n",
       "        [[-10.62181377],\n",
       "         [-14.43393993],\n",
       "         [-16.67900848],\n",
       "         ...,\n",
       "         [ -4.16002655],\n",
       "         [ -4.8179121 ],\n",
       "         [ -8.88064289]],\n",
       "\n",
       "        [[ -8.96886826],\n",
       "         [-13.63510418],\n",
       "         [-15.53146648],\n",
       "         ...,\n",
       "         [  5.09067202],\n",
       "         [  1.14317751],\n",
       "         [ -5.9626832 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-45.85511017],\n",
       "         [-46.13648224],\n",
       "         [-42.80020905],\n",
       "         ...,\n",
       "         [ -4.04913807],\n",
       "         [ -7.68304825],\n",
       "         [ -9.90781212]],\n",
       "\n",
       "        [[ -2.57004666],\n",
       "         [ -6.47573233],\n",
       "         [ -6.66976357],\n",
       "         ...,\n",
       "         [-17.80778885],\n",
       "         [-27.01833153],\n",
       "         [-31.26036072]],\n",
       "\n",
       "        [[-13.96785164],\n",
       "         [-13.55069828],\n",
       "         [ -3.63626242],\n",
       "         ...,\n",
       "         [  1.26204252],\n",
       "         [  3.55167556],\n",
       "         [ -0.519023  ]]],\n",
       "\n",
       "\n",
       "       [[[-14.91018391],\n",
       "         [-19.89842796],\n",
       "         [-16.69747734],\n",
       "         ...,\n",
       "         [-34.92211151],\n",
       "         [-21.752882  ],\n",
       "         [-20.34329987]],\n",
       "\n",
       "        [[  3.82114506],\n",
       "         [  0.70071411],\n",
       "         [  5.63092709],\n",
       "         ...,\n",
       "         [-29.33329391],\n",
       "         [-14.75400734],\n",
       "         [-13.52703381]],\n",
       "\n",
       "        [[  2.12718725],\n",
       "         [ -0.64036286],\n",
       "         [  0.88972139],\n",
       "         ...,\n",
       "         [-26.81571579],\n",
       "         [-13.50374222],\n",
       "         [-11.28730392]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 28.69554138],\n",
       "         [ 31.09426308],\n",
       "         [ 26.21548653],\n",
       "         ...,\n",
       "         [-33.2127037 ],\n",
       "         [-24.92782784],\n",
       "         [-23.84699631]],\n",
       "\n",
       "        [[-13.5495491 ],\n",
       "         [-18.17882538],\n",
       "         [-23.02943039],\n",
       "         ...,\n",
       "         [-16.04459   ],\n",
       "         [ -5.39688826],\n",
       "         [ -5.95491838]],\n",
       "\n",
       "        [[ -0.36124176],\n",
       "         [  0.68827891],\n",
       "         [ -7.52974749],\n",
       "         ...,\n",
       "         [ -8.03001022],\n",
       "         [ -4.69289017],\n",
       "         [ -1.78728068]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 300, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 31, 300, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 31, 300, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_epochs = 100 #2000\\n#learning_rate = 0.001\\nbatch_size = 32 #250 \\nn_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\\nrate_dropout = [0.8, 0.4, 0.2, 0.1]\\nweight_decay = 1e-4\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "n_epochs = 100 #2000\n",
    "#learning_rate = 0.001\n",
    "batch_size = 32 #250 \n",
    "n_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\n",
    "rate_dropout = [0.8, 0.4, 0.2, 0.1]\n",
    "weight_decay = 1e-4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Build the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 31, 300, 4)        104       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 300, 4)        500       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 150, 4)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 18002     \n",
      "=================================================================\n",
      "Total params: 18,606\n",
      "Trainable params: 18,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, DepthwiseConv2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import optimizers, regularizers\n",
    "import keras.backend as K\n",
    "#K.set_image_data_format('channels_first')\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "# Convolution2D(filtrosConv1, tamaño_filtro1, padding=\"same\", input_shape=(longitud, altura,3), activation = \"relu\")\n",
    "    # - filtrosConv1 número de filtros que aplicaremos tras la primera convolución, normalmente este tamaño va a aumentando\n",
    "    # tras convoluciones para que aumente la dimensión de profundidad (qué cosas hay en mi imagen)\n",
    "    # - tamaño_filtro1 tamaño espacial del kernel (de los filtros)\n",
    "    # - padding = si es same es que es igual que la imagen, vamos crea una imagen del mismo tamaño con el filtro, si es \n",
    "    # valid es que no hay padding y crea una imagen más pequeña que la imagen (creo)\n",
    "    # - input_shape = longitud y altura, tamaño que usará para convolucionar al entrenar\n",
    "    \n",
    "# CAPA PARA FILTRADO TEMPORAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(1,25), padding=\"same\", activation=\"relu\",input_shape=(31, 300,1 ), kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "# CAPA PARA FILTRADO ESPACIAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(31,1), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\"\"\"\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## Siguientes capas convolucionales: \n",
    "model.add(Conv2D(20, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(40, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Conv2D(80, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model.add(Conv2D(160, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\"\"\"\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y_train.shape[1], activation=\"softmax\"))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)        \n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x249543c9490>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x249533f7040>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x249532eba00>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x249534438e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2495343a9d0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "conv2d_1\n",
      "max_pooling2d\n",
      "flatten\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers: print (l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the parameters of a layer can bee accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25, 1, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[0].get_weights()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.01651166,  0.08663373,  0.49462536,  0.22804618]],\n",
       "\n",
       "        [[ 0.25664356,  0.6050236 ,  0.01289036, -0.16121486]],\n",
       "\n",
       "        [[ 0.05042717, -0.15801734,  0.3621434 ,  0.0949944 ]],\n",
       "\n",
       "        [[-0.34026235,  0.03914388,  0.14131242,  0.09612828]],\n",
       "\n",
       "        [[-0.59915584, -0.31943935,  0.509768  , -0.23000866]],\n",
       "\n",
       "        [[ 0.21874116,  0.36818457, -0.07829569, -0.56172854]],\n",
       "\n",
       "        [[-0.4922212 , -0.3856256 ,  0.21320188, -0.16181752]],\n",
       "\n",
       "        [[-0.34504333, -0.2974819 ,  0.5629295 , -0.31362414]],\n",
       "\n",
       "        [[ 0.39801472,  0.38719943,  0.16597801,  0.18458818]],\n",
       "\n",
       "        [[ 0.2771827 ,  0.3598028 , -0.4163832 , -0.3400525 ]],\n",
       "\n",
       "        [[ 0.5261645 ,  0.15463755,  0.40380207,  0.3369314 ]],\n",
       "\n",
       "        [[-0.32794172,  0.29223984, -0.11871825, -0.1255793 ]],\n",
       "\n",
       "        [[-0.01244599,  0.45574895,  0.04595508,  0.05910585]],\n",
       "\n",
       "        [[-0.07024246, -0.2247747 ,  0.13398303, -0.15723635]],\n",
       "\n",
       "        [[ 0.1475136 , -0.12401386,  0.2019148 ,  0.19539253]],\n",
       "\n",
       "        [[-0.18043728, -0.18246098, -0.07421856, -0.02190348]],\n",
       "\n",
       "        [[-0.06320983, -0.07721135,  0.16794606, -0.52608854]],\n",
       "\n",
       "        [[ 0.0435314 ,  0.35462886,  0.04857059,  0.38435578]],\n",
       "\n",
       "        [[-0.26744854,  0.00666416,  0.1784381 ,  0.24481024]],\n",
       "\n",
       "        [[-0.08881257,  0.5198268 ,  0.3379782 , -0.06845527]],\n",
       "\n",
       "        [[ 0.03304636,  0.02159316,  0.07949068, -0.3096884 ]],\n",
       "\n",
       "        [[-0.1664487 ,  0.01520472,  0.15524393,  0.03502052]],\n",
       "\n",
       "        [[-0.20406382, -0.08954986,  0.03619194,  0.18189864]],\n",
       "\n",
       "        [[-0.47796634, -0.4056338 , -0.31656954,  0.2917186 ]],\n",
       "\n",
       "        [[ 0.37434503,  0.5346339 ,  0.05459794, -0.05851016]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases # Bias de la primera capa: 500 bias inicializados a 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train the model with M-BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 - 3s - loss: 26.8435 - accuracy: 0.5306 - val_loss: 6.0145 - val_accuracy: 0.5204\n",
      "Epoch 2/100\n",
      "13/13 - 2s - loss: 9.1628 - accuracy: 0.5638 - val_loss: 3.4246 - val_accuracy: 0.6224\n",
      "Epoch 3/100\n",
      "13/13 - 2s - loss: 3.5162 - accuracy: 0.6250 - val_loss: 2.3376 - val_accuracy: 0.5918\n",
      "Epoch 4/100\n",
      "13/13 - 2s - loss: 1.2374 - accuracy: 0.7347 - val_loss: 1.9932 - val_accuracy: 0.6020\n",
      "Epoch 5/100\n",
      "13/13 - 2s - loss: 0.5838 - accuracy: 0.8265 - val_loss: 2.6245 - val_accuracy: 0.5408\n",
      "Epoch 6/100\n",
      "13/13 - 2s - loss: 0.2944 - accuracy: 0.8852 - val_loss: 2.1498 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "13/13 - 2s - loss: 0.1496 - accuracy: 0.9464 - val_loss: 2.0384 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "13/13 - 2s - loss: 0.0756 - accuracy: 0.9770 - val_loss: 2.1551 - val_accuracy: 0.5918\n",
      "Epoch 9/100\n",
      "13/13 - 2s - loss: 0.0360 - accuracy: 1.0000 - val_loss: 2.2599 - val_accuracy: 0.5816\n",
      "Epoch 10/100\n",
      "13/13 - 2s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.1708 - val_accuracy: 0.6020\n",
      "Epoch 11/100\n",
      "13/13 - 2s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.2312 - val_accuracy: 0.5816\n",
      "Epoch 12/100\n",
      "13/13 - 2s - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.1825 - val_accuracy: 0.5918\n",
      "Epoch 13/100\n",
      "13/13 - 2s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.2396 - val_accuracy: 0.5816\n",
      "Epoch 14/100\n",
      "13/13 - 2s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.2179 - val_accuracy: 0.5918\n",
      "Epoch 15/100\n",
      "13/13 - 2s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.2365 - val_accuracy: 0.5918\n",
      "Epoch 16/100\n",
      "13/13 - 2s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.2585 - val_accuracy: 0.5816\n",
      "Epoch 17/100\n",
      "13/13 - 3s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.2688 - val_accuracy: 0.5816\n",
      "Epoch 18/100\n",
      "13/13 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.2601 - val_accuracy: 0.5816\n",
      "Epoch 19/100\n",
      "13/13 - 2s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.2592 - val_accuracy: 0.5918\n",
      "Epoch 20/100\n",
      "13/13 - 2s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.2818 - val_accuracy: 0.5918\n",
      "Epoch 21/100\n",
      "13/13 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.2873 - val_accuracy: 0.5918\n",
      "Epoch 22/100\n",
      "13/13 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.2978 - val_accuracy: 0.5918\n",
      "Epoch 23/100\n",
      "13/13 - 3s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.2948 - val_accuracy: 0.5918\n",
      "Epoch 24/100\n",
      "13/13 - 3s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.2988 - val_accuracy: 0.5816\n",
      "Epoch 25/100\n",
      "13/13 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.3217 - val_accuracy: 0.5816\n",
      "Epoch 26/100\n",
      "13/13 - 3s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.3151 - val_accuracy: 0.5816\n",
      "Epoch 27/100\n",
      "13/13 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.3326 - val_accuracy: 0.5816\n",
      "Epoch 28/100\n",
      "13/13 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.3444 - val_accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "13/13 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.3388 - val_accuracy: 0.5816\n",
      "Epoch 30/100\n",
      "13/13 - 3s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.3472 - val_accuracy: 0.5816\n",
      "Epoch 31/100\n",
      "13/13 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.3747 - val_accuracy: 0.5714\n",
      "Epoch 32/100\n",
      "13/13 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.3510 - val_accuracy: 0.5816\n",
      "Epoch 33/100\n",
      "13/13 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.3593 - val_accuracy: 0.5816\n",
      "Epoch 34/100\n",
      "13/13 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.3842 - val_accuracy: 0.5714\n",
      "Epoch 35/100\n",
      "13/13 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.3636 - val_accuracy: 0.5816\n",
      "Epoch 36/100\n",
      "13/13 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3828 - val_accuracy: 0.5714\n",
      "Epoch 37/100\n",
      "13/13 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3968 - val_accuracy: 0.5714\n",
      "Epoch 38/100\n",
      "13/13 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3913 - val_accuracy: 0.5714\n",
      "Epoch 39/100\n",
      "13/13 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3997 - val_accuracy: 0.5714\n",
      "Epoch 40/100\n",
      "13/13 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.4062 - val_accuracy: 0.5714\n",
      "Epoch 41/100\n",
      "13/13 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.4210 - val_accuracy: 0.5714\n",
      "Epoch 42/100\n",
      "13/13 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4082 - val_accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "13/13 - 3s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4356 - val_accuracy: 0.5714\n",
      "Epoch 44/100\n",
      "13/13 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4211 - val_accuracy: 0.5714\n",
      "Epoch 45/100\n",
      "13/13 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4277 - val_accuracy: 0.5714\n",
      "Epoch 46/100\n",
      "13/13 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4380 - val_accuracy: 0.5714\n",
      "Epoch 47/100\n",
      "13/13 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4429 - val_accuracy: 0.5714\n",
      "Epoch 48/100\n",
      "13/13 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4530 - val_accuracy: 0.5714\n",
      "Epoch 49/100\n",
      "13/13 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4581 - val_accuracy: 0.5714\n",
      "Epoch 50/100\n",
      "13/13 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.4496 - val_accuracy: 0.5714\n",
      "Epoch 51/100\n",
      "13/13 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.4555 - val_accuracy: 0.5714\n",
      "Epoch 52/100\n",
      "13/13 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.4730 - val_accuracy: 0.5714\n",
      "Epoch 53/100\n",
      "13/13 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4600 - val_accuracy: 0.5612\n",
      "Epoch 54/100\n",
      "13/13 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4791 - val_accuracy: 0.5714\n",
      "Epoch 55/100\n",
      "13/13 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4807 - val_accuracy: 0.5612\n",
      "Epoch 56/100\n",
      "13/13 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4704 - val_accuracy: 0.5612\n",
      "Epoch 57/100\n",
      "13/13 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4754 - val_accuracy: 0.5612\n",
      "Epoch 58/100\n",
      "13/13 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4870 - val_accuracy: 0.5612\n",
      "Epoch 59/100\n",
      "13/13 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4965 - val_accuracy: 0.5612\n",
      "Epoch 60/100\n",
      "13/13 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5077 - val_accuracy: 0.5816\n",
      "Epoch 61/100\n",
      "13/13 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4881 - val_accuracy: 0.5612\n",
      "Epoch 62/100\n",
      "13/13 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5114 - val_accuracy: 0.5816\n",
      "Epoch 63/100\n",
      "13/13 - 3s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5052 - val_accuracy: 0.5612\n",
      "Epoch 64/100\n",
      "13/13 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5083 - val_accuracy: 0.5612\n",
      "Epoch 65/100\n",
      "13/13 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5026 - val_accuracy: 0.5612\n",
      "Epoch 66/100\n",
      "13/13 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5252 - val_accuracy: 0.5714\n",
      "Epoch 67/100\n",
      "13/13 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5218 - val_accuracy: 0.5714\n",
      "Epoch 68/100\n",
      "13/13 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5335 - val_accuracy: 0.5714\n",
      "Epoch 69/100\n",
      "13/13 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5257 - val_accuracy: 0.5714\n",
      "Epoch 70/100\n",
      "13/13 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5318 - val_accuracy: 0.5714\n",
      "Epoch 71/100\n",
      "13/13 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5423 - val_accuracy: 0.5612\n",
      "Epoch 72/100\n",
      "13/13 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5434 - val_accuracy: 0.5612\n",
      "Epoch 73/100\n",
      "13/13 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5278 - val_accuracy: 0.5612\n",
      "Epoch 74/100\n",
      "13/13 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5455 - val_accuracy: 0.5714\n",
      "Epoch 75/100\n",
      "13/13 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5469 - val_accuracy: 0.5714\n",
      "Epoch 76/100\n",
      "13/13 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5469 - val_accuracy: 0.5714\n",
      "Epoch 77/100\n",
      "13/13 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5502 - val_accuracy: 0.5714\n",
      "Epoch 78/100\n",
      "13/13 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5548 - val_accuracy: 0.5714\n",
      "Epoch 79/100\n",
      "13/13 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5596 - val_accuracy: 0.5714\n",
      "Epoch 80/100\n",
      "13/13 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5650 - val_accuracy: 0.5714\n",
      "Epoch 81/100\n",
      "13/13 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5691 - val_accuracy: 0.5714\n",
      "Epoch 82/100\n",
      "13/13 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5745 - val_accuracy: 0.5714\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5783 - val_accuracy: 0.5714\n",
      "Epoch 84/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5681 - val_accuracy: 0.5714\n",
      "Epoch 85/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5842 - val_accuracy: 0.5714\n",
      "Epoch 86/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5906 - val_accuracy: 0.5714\n",
      "Epoch 87/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5866 - val_accuracy: 0.5714\n",
      "Epoch 88/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6035 - val_accuracy: 0.5612\n",
      "Epoch 89/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5967 - val_accuracy: 0.5714\n",
      "Epoch 90/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5924 - val_accuracy: 0.5714\n",
      "Epoch 91/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6019 - val_accuracy: 0.5714\n",
      "Epoch 92/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6099 - val_accuracy: 0.5714\n",
      "Epoch 93/100\n",
      "13/13 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6071 - val_accuracy: 0.5714\n",
      "Epoch 94/100\n",
      "13/13 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5919 - val_accuracy: 0.5714\n",
      "Epoch 95/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6128 - val_accuracy: 0.5714\n",
      "Epoch 96/100\n",
      "13/13 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6197 - val_accuracy: 0.5714\n",
      "Epoch 97/100\n",
      "13/13 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6197 - val_accuracy: 0.5714\n",
      "Epoch 98/100\n",
      "13/13 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6173 - val_accuracy: 0.5714\n",
      "Epoch 99/100\n",
      "13/13 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6271 - val_accuracy: 0.5714\n",
      "Epoch 100/100\n",
      "13/13 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6350 - val_accuracy: 0.5714\n",
      "251.25532746315002\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#history = model.fit(X_train, y_train, batch_size=32, steps_per_epoch=len(y_train)/32, epochs=100, verbose=2, validation_data=(X_dev, y_dev),callbacks=[tensorboard])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=2, validation_data=(X_dev, y_dev))\n",
    "print (time.time() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=pd.DataFrame(history.history)\n",
    "results.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel (\"Epochs\")\n",
    "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
    "plt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "# categorical_accuracy es el training accuracy\n",
    "# val_categorical_accuracy es el validation accuracy\n",
    "# loss es el training loss\n",
    "# val_loss es el validation loss\n",
    "\n",
    "# Overfitting:\n",
    "# Por un lado la Accuracy de los datos de entrenamiento aumenta con las epochs,\n",
    "# mientras que la Accuracy de los datos de validación disminuye o se mantiene constante a lo largo de las epochs. \n",
    "# La Loss de los datos de validación alcanza su mínimo después de pocos epochs y luego empieza a subir, \n",
    "# mientras que la Loss de los datos de entrenamiento disminuye linealmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 2, 'epochs': 100, 'steps': 13}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.002013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.635027</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "99  0.002013       1.0  2.635027      0.571429"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set:  1.0\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the training set: \", results.values[-1:][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the development test set:  0.5714285969734192\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the development test set: \", results.values[-1:][0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how the model predicts using the development test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98, 0.02],\n",
       "       [1.  , 0.  ],\n",
       "       [0.99, 0.01],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.96, 0.04],\n",
       "       [0.  , 1.  ],\n",
       "       [0.01, 0.99],\n",
       "       [0.55, 0.45],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.19, 0.81],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions=model.predict(X_dev).round(2) \n",
    "dev_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_rounded_predictions=np.round(dev_predictions)\n",
    "indices = np.argmax(dev_predictions,1)\n",
    "for row, index in zip(dev_rounded_predictions, indices): row[index]=1\n",
    "dev_rounded_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True False False  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True False False False\n",
      " False False False  True False False]\n"
     ]
    }
   ],
   "source": [
    "dev_correct_predictions = np.equal(np.argmax(dev_rounded_predictions,1),np.argmax(y_dev,1))\n",
    "print (dev_correct_predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 55, False: 43})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter (dev_correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model if it is better than others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "model.save('./Modelos/CNN_model1_PARES_DIA29.h5') # Change the name in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnew_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\\n\\nimport numpy as np\\n\\n# Verify state\\nnew_predictions = new_model.predict(X_dev)\\nnp.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\\n\\n# Note that the optimizer state is also preserved:\\n# you can resume training where you left off.\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract\n",
    "\"\"\"\n",
    "new_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Verify state\n",
    "new_predictions = new_model.predict(X_dev)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is also preserved:\n",
    "# you can resume training where you left off.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Final Test\n",
    "\n",
    "#### 10.1 - Load the final test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "def predictWithModel(model, X_test, y_test, task1, task2, task3=\"\"):\n",
    "    model.evaluate(X_test, y_test)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_rounded_predictions=np.round(test_predictions)\n",
    "    indices = np.argmax(test_predictions,1)\n",
    "    for row, index in zip(test_rounded_predictions, indices): row[index]=1\n",
    "    print(test_rounded_predictions[:20])\n",
    "    \n",
    "    # ACCURACY:\n",
    "    test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(y_test,1))\n",
    "    print()\n",
    "    print(test_correct_predictions)\n",
    "    print(type(test_correct_predictions))\n",
    "    final_test_prediction_results=Counter(test_correct_predictions)\n",
    "    \n",
    "    success = np.mean(test_rounded_predictions == y_test)*100\n",
    "    \n",
    "    return final_test_prediction_results, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 30ms/step - loss: 3.4345 - accuracy: 0.5306\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "[ True False  True  True  True False False False False False  True False\n",
      " False  True  True  True  True False  True  True  True False  True False\n",
      " False  True  True False False False False False  True  True False False\n",
      " False  True  True  True  True  True  True  True  True False False  True\n",
      " False]\n",
      "<class 'numpy.ndarray'>\n",
      "Counter({True: 26, False: 23}) 53.06122448979592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#X_test, y_test = readRegisterAndReturnXy(u, total_records, 122, 123, 127)\n",
    "accuracy, success = predictWithModel(model, X_test, y_test, 402,404)\n",
    "print(accuracy, success)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
