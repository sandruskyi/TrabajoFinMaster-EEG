{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4: Clasificación con CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con la arquitectura anterior: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Resultados:\n",
    "    \n",
    "    TRAIN                   DEV\n",
    "    loss       accuracy     val_loss    val_accuracy\n",
    "    0.596408\t0.711538\t0.649262\t0.615385\n",
    "    \n",
    "Por tanto: \n",
    "\n",
    "    E = 1 - Accuracy\n",
    "    Etrain = 1 - 0.711538 = 0.288462\n",
    "    Etest = 1 - 0.615385 = 0.384615\n",
    "    \n",
    "    Bias = Etrain - Ehuman = 0.288462\n",
    "    Variance = Etest - Etrain = 0.384615 - 0.288462 = 0.096153\n",
    "\n",
    "La varianza se ha reducido (de 46% a 9%) pero el bias ha aumentado a un 28%\n",
    "El bias se encuentra bajo (1%), pero la varianza es alta (46%), hay que tratar de reducirla.  Se tratará de mejorar el bias. Para mejorar esto será necesario añadir más complejidad, elegir una mejor optimización, cambiando la arquitectura (más neuronas, más capas)...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambios realizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a probar con un mejor optimizador NAG optimizers.opt = optimizers.SGD(lr=0.001, momentum = 0.9, nesterov = True)         (momentum con un vector más efectivo) (Antiguo Adam(lr=0.001, beta_1=0.9, beta_2=0.999). El resultado obtenido no es el que se buscaba asi que se vuelve a poner Adam. \n",
    "\n",
    "Se vuelve a cambiar el l1 por el l2.\n",
    "\n",
    "Se cambia el tamaño de todos los filtros, pero solo ha empeorado las cosas. \n",
    "\n",
    "DESPUÉS DE VARIAS PRUEBAS SE OBSERVA QUE EL MEJOR CLASIFICADOR ES EL MODELO 2 (2parte_CNN_Marcha_2-caracteristicasextraidas)\n",
    "POR TANTO SE SELECCIONA ESE MODELO PARA HACER LA EVALUACIÓN CON EL TEST SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevos resultados: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Signal libraries\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROutput:\n",
    "    def __init__(self, task, data):\n",
    "        self.task = task\n",
    "        self.data = data\n",
    "        \n",
    "class OutTaskData: \n",
    "    def __init__(self, task, data): \n",
    "        self.task = task\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "# Primero leemos los registros\n",
    "def read_outputs(rec):\n",
    "    '''read_outputs(\"userS0091f1.mat\")'''\n",
    "    mat = sio.loadmat(rec)\n",
    "    mdata = mat['session']\n",
    "    val = mdata[0,0]\n",
    "    #output = ROutput(np.array(val[\"task\"]), np.array(val[\"data\"]))\n",
    "    output = ROutput(np.array(val[\"task_EEG_p\"]), np.array(val[\"data_processed_EEG\"]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Perceptron\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "task1 = 402 # SE PUEDE CAMBIAR\n",
    "task2 = 404 # SE PUEDE CAMBIAR\n",
    "task_OneHotEnconding = {402: [1.,0.], 404: [0.,1.]}\n",
    "user = 'W29' # SE PUEDE CAMBIAR\n",
    "day = '0401'\n",
    "folder_day = 'W29-01_04_2021'\n",
    "total_records = 22 # CAMBIAR SI HAY MAS REGISTROS\n",
    "fm = 200\n",
    "electrodes_names_selected = ['F3', 'FZ', 'FC1','FCZ','C1','CZ','CP1','CPZ', 'FC5', 'FC3','C5','C3','CP5','CP3','P3',\n",
    "                             'PZ','F4','FC2','FC4','FC6','C2','C4','CP2','CP4','C6','CP6','P4','HR' ,'HL', 'VU', 'VD']\n",
    "number_channels = len(electrodes_names_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 22\n"
     ]
    }
   ],
   "source": [
    "lTaskData = []\n",
    "total_records_used = 0\n",
    "for i_rec in range(1,total_records+1):\n",
    "    i_rec_record = i_rec\n",
    "    if i_rec_record <10:\n",
    "        i_rec_record = \"0\"+str(i_rec_record)\n",
    "    if i_rec % 2 != 0: # Registros impares primero: USUARIO SIN MOVIMIENTO SOLO PENSANDO\n",
    "        record = \"./RegistrosProcesados2/\"+folder_day+\"/W29_2021\"+day+\"_openloop_\"+str(i_rec_record)+\"_processed.mat\"\n",
    "        output = read_outputs(record) # output.task será y, output.data será x\n",
    "\n",
    "\n",
    "        output.task = np.transpose(output.task)\n",
    "        output.data = output.data.reshape((np.shape(output.data)[0],np.shape(output.data)[1]))\n",
    "        output.data = np.transpose(output.data)\n",
    "        #output.data = output.data.reshape((np.shape(output.data)[0],np.shape(output.data)[1],1))\n",
    "\n",
    "        outT = (output.task == task1) | (output.task == task2)\n",
    "        outData = output.data[0:np.shape(output.data)[0], outT[0,:]]\n",
    "        outTask = output.task[0, outT[0,:]]\n",
    "        outTD = OutTaskData(outTask, outData)\n",
    "\n",
    "        lTaskData.append(outTD)\n",
    "        total_records_used+=1\n",
    "print(total_records_used, total_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8, 32, 49)\n",
      "y_train: (8, 49)\n",
      "X_dev: (2, 32, 49)\n",
      "y_dev: (2, 49)\n",
      "X_test: (1, 32, 49)\n",
      "y_test: (1, 49)\n",
      "ONE HOT ENCODER:\n",
      "X_train: (104, 32, 5, 1)\n",
      "y_train: (104, 2)\n",
      "X_dev: (26, 32, 5, 1)\n",
      "y_dev: (26, 2)\n",
      "X_test: (13, 32, 5, 1)\n",
      "y_test: (13, 2)\n"
     ]
    }
   ],
   "source": [
    "# Vamos a coger 2 registros para el entrenamiento, 1 para el conjunto dev set, 1 para el test set\n",
    "X_train, y_train, X_dev, y_dev, X_test, y_test = [],[],[],[],[],[] \n",
    "for j in range(0,total_records_used-3): # Cogemos 18 registros para entrenamiento\n",
    "    X_train.append(lTaskData[j].data)\n",
    "    y_train.append(lTaskData[j].task)\n",
    "\n",
    "for j in range(total_records_used-3,total_records_used-1): # Cogemos 2 registros para el dev set\n",
    "    X_dev.append(lTaskData[j].data)\n",
    "    y_dev.append(lTaskData[j].task)\n",
    "for j in range(total_records_used-1,total_records_used): # Cogemos 2 registros para el test set\n",
    "    X_test.append(lTaskData[j].data)\n",
    "    y_test.append(lTaskData[j].task)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "#y_train = np.ravel(np.array(y_train))\n",
    "y_train = np.array(y_train)\n",
    "X_dev = np.array(X_dev)\n",
    "#y_dev = np.ravel(np.array(y_dev))\n",
    "y_dev = np.array(y_dev)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "#y_test = np.ravel(np.array(y_test))\n",
    "\n",
    "print (\"X_train:\",X_train.shape)\n",
    "print (\"y_train:\",y_train.shape)\n",
    "print (\"X_dev:\",X_dev.shape)\n",
    "print (\"y_dev:\",y_dev.shape)\n",
    "print (\"X_test:\",X_test.shape)\n",
    "print (\"y_test:\",y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# VENTANEO Y ONE HOT ENCODING \n",
    "window = 5\n",
    "samples_advance = 3\n",
    "\n",
    "# Ventaneo X_train\n",
    "\n",
    "X_train_l = []\n",
    "y_train_l = []\n",
    "for num_X_train in range(np.shape(X_train)[0]): # Para no mezclar registros\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_train)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_train)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_train[num_X_train,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_train[num_X_train, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_train_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_train_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_train_l = np.array(X_train_l)\n",
    "y_train_l = np.array(y_train_l)\n",
    "\n",
    "\n",
    "# Ventaneo X_dev\n",
    "X_dev_l = []\n",
    "y_dev_l = []\n",
    "for num_X_dev in range(np.shape(X_dev)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_dev)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_dev)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_dev[num_X_dev,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_dev[num_X_dev, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_dev_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_dev_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_dev_l = np.array(X_dev_l)\n",
    "y_dev_l = np.array(y_dev_l)\n",
    "\n",
    "# Ventaneo X_test\n",
    "X_test_l = []\n",
    "y_test_l = []\n",
    "for num_X_test in range(np.shape(X_test)[0]): \n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_test)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_test)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_test[num_X_test,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_test[num_X_test, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_test_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_test_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_test_l = np.array(X_test_l)\n",
    "y_test_l = np.array(y_test_l)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_l = X_train_l.reshape((np.shape(X_train_l)[0],np.shape(X_train_l)[1],np.shape(X_train_l)[2], 1))\n",
    "X_dev_l = X_dev_l.reshape((np.shape(X_dev_l)[0],np.shape(X_dev_l)[1],np.shape(X_dev_l)[2], 1))\n",
    "X_test_l = X_test_l.reshape((np.shape(X_test_l)[0],np.shape(X_test_l)[1],np.shape(X_test_l)[2], 1))\n",
    "\n",
    "\n",
    "print(\"ONE HOT ENCODER:\")\n",
    "print (\"X_train:\",X_train_l.shape)\n",
    "print (\"y_train:\",y_train_l.shape)\n",
    "print (\"X_dev:\",X_dev_l.shape)\n",
    "print (\"y_dev:\",y_dev_l.shape)\n",
    "print (\"X_test:\",X_test_l.shape)\n",
    "print (\"y_test:\",y_test_l.shape)\n",
    "\n",
    "X_train = X_train_l\n",
    "y_train = y_train_l\n",
    "X_dev = X_dev_l\n",
    "y_dev = y_dev_l\n",
    "X_test = X_test_l\n",
    "y_test = y_test_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = X_train.shape[1]\n",
    "OUTPUTS = y_train.shape[1]\n",
    "NUM_TRAINING_EXAMPLES = int(round(X_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int(round(y_train.shape[0]/1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data is displayed to test correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1.10091475],\n",
       "         [-1.18560955],\n",
       "         [-1.22540958],\n",
       "         [-1.30127027],\n",
       "         [-1.14601052]],\n",
       "\n",
       "        [[-0.73933969],\n",
       "         [-0.6522277 ],\n",
       "         [-0.60960244],\n",
       "         [-0.62635203],\n",
       "         [-0.75554883]],\n",
       "\n",
       "        [[-0.65035738],\n",
       "         [-0.78916911],\n",
       "         [-0.74388342],\n",
       "         [-0.8335337 ],\n",
       "         [-0.71300404]],\n",
       "\n",
       "        [[-0.87346323],\n",
       "         [-0.91497745],\n",
       "         [-1.01676848],\n",
       "         [-1.16910068],\n",
       "         [-1.1302377 ]],\n",
       "\n",
       "        [[-0.96936541],\n",
       "         [-0.83515715],\n",
       "         [-0.91614968],\n",
       "         [-0.867686  ],\n",
       "         [-0.9775851 ]],\n",
       "\n",
       "        [[-1.08371702],\n",
       "         [-1.04183855],\n",
       "         [-1.04259551],\n",
       "         [-0.91319117],\n",
       "         [-0.85486867]],\n",
       "\n",
       "        [[-1.08475912],\n",
       "         [-0.9985104 ],\n",
       "         [-0.92636541],\n",
       "         [-0.90100283],\n",
       "         [-0.92114033]],\n",
       "\n",
       "        [[-0.96285848],\n",
       "         [-1.04281849],\n",
       "         [-1.05650712],\n",
       "         [-0.93621123],\n",
       "         [-0.91950371]],\n",
       "\n",
       "        [[-1.11986017],\n",
       "         [-1.13755911],\n",
       "         [-1.10725991],\n",
       "         [-1.23916743],\n",
       "         [-1.10527364]],\n",
       "\n",
       "        [[-1.19593847],\n",
       "         [-1.10944223],\n",
       "         [-1.11470031],\n",
       "         [-1.1161685 ],\n",
       "         [-1.07972332]],\n",
       "\n",
       "        [[-1.15576314],\n",
       "         [-1.17940457],\n",
       "         [-1.13249148],\n",
       "         [-1.08961971],\n",
       "         [-1.02243438]],\n",
       "\n",
       "        [[-0.67371055],\n",
       "         [-0.55738688],\n",
       "         [-0.5055594 ],\n",
       "         [-0.51167953],\n",
       "         [-0.7238865 ]],\n",
       "\n",
       "        [[-0.87216162],\n",
       "         [-0.80653999],\n",
       "         [-0.85271813],\n",
       "         [-0.86422332],\n",
       "         [-0.75432136]],\n",
       "\n",
       "        [[-0.83084721],\n",
       "         [-1.00929969],\n",
       "         [-0.96519016],\n",
       "         [-0.97046271],\n",
       "         [-0.9335852 ]],\n",
       "\n",
       "        [[-0.85781069],\n",
       "         [-0.93625877],\n",
       "         [-1.01390328],\n",
       "         [-0.94499817],\n",
       "         [-0.85290566]],\n",
       "\n",
       "        [[-0.80132806],\n",
       "         [-0.86528783],\n",
       "         [-0.94456309],\n",
       "         [-0.92305878],\n",
       "         [-0.91513922]],\n",
       "\n",
       "        [[-0.69026097],\n",
       "         [-0.76478067],\n",
       "         [-0.78086435],\n",
       "         [-0.87597447],\n",
       "         [-0.79194332]],\n",
       "\n",
       "        [[-1.01166919],\n",
       "         [-0.9863516 ],\n",
       "         [-1.14491136],\n",
       "         [-1.1210355 ],\n",
       "         [-1.03845465]],\n",
       "\n",
       "        [[-1.43728241],\n",
       "         [-1.11944436],\n",
       "         [-1.16021034],\n",
       "         [-1.03388904],\n",
       "         [-1.24732427]],\n",
       "\n",
       "        [[-0.79012112],\n",
       "         [-0.80274877],\n",
       "         [-0.76560969],\n",
       "         [-0.69933888],\n",
       "         [-0.63491454]],\n",
       "\n",
       "        [[-0.89005627],\n",
       "         [-1.00420612],\n",
       "         [-0.97938257],\n",
       "         [-0.95741949],\n",
       "         [-0.95285456]],\n",
       "\n",
       "        [[-1.05628657],\n",
       "         [-0.95559817],\n",
       "         [-0.82211222],\n",
       "         [-0.81654804],\n",
       "         [-0.86459248]],\n",
       "\n",
       "        [[-0.89811214],\n",
       "         [-0.97799064],\n",
       "         [-0.94208457],\n",
       "         [-1.01784109],\n",
       "         [-0.94228649]],\n",
       "\n",
       "        [[-0.80455702],\n",
       "         [-0.75328942],\n",
       "         [-0.81731808],\n",
       "         [-0.85354457],\n",
       "         [-1.01599284]],\n",
       "\n",
       "        [[-0.79864351],\n",
       "         [-0.98207379],\n",
       "         [-1.07800206],\n",
       "         [-0.87563628],\n",
       "         [-0.8697048 ]],\n",
       "\n",
       "        [[-0.92575908],\n",
       "         [-0.84292542],\n",
       "         [-0.72741675],\n",
       "         [-0.6875535 ],\n",
       "         [-0.73375828]],\n",
       "\n",
       "        [[-0.76652337],\n",
       "         [-0.73444433],\n",
       "         [-0.725692  ],\n",
       "         [-0.85024511],\n",
       "         [-0.88140641]],\n",
       "\n",
       "        [[-0.75696097],\n",
       "         [-0.70981838],\n",
       "         [-0.81786427],\n",
       "         [-0.84539216],\n",
       "         [-0.85608652]],\n",
       "\n",
       "        [[-1.26119661],\n",
       "         [-1.23673734],\n",
       "         [-1.36479313],\n",
       "         [-1.29642572],\n",
       "         [-1.06455931]],\n",
       "\n",
       "        [[-0.98314232],\n",
       "         [-0.96446208],\n",
       "         [-0.78567208],\n",
       "         [-0.93559047],\n",
       "         [-0.86715842]],\n",
       "\n",
       "        [[-1.07013712],\n",
       "         [-0.99441305],\n",
       "         [-1.06293222],\n",
       "         [-1.0700215 ],\n",
       "         [-1.00480823]],\n",
       "\n",
       "        [[-0.87832613],\n",
       "         [-0.97867105],\n",
       "         [-1.02015518],\n",
       "         [-0.89979547],\n",
       "         [-1.05132901]]],\n",
       "\n",
       "\n",
       "       [[[-1.30127027],\n",
       "         [-1.14601052],\n",
       "         [-1.0826931 ],\n",
       "         [-1.07282014],\n",
       "         [-1.29356845]],\n",
       "\n",
       "        [[-0.62635203],\n",
       "         [-0.75554883],\n",
       "         [-0.72569138],\n",
       "         [-0.8704877 ],\n",
       "         [-0.87795692]],\n",
       "\n",
       "        [[-0.8335337 ],\n",
       "         [-0.71300404],\n",
       "         [-0.77986452],\n",
       "         [-0.77552735],\n",
       "         [-0.67418434]],\n",
       "\n",
       "        [[-1.16910068],\n",
       "         [-1.1302377 ],\n",
       "         [-1.11151525],\n",
       "         [-1.10913778],\n",
       "         [-0.97327019]],\n",
       "\n",
       "        [[-0.867686  ],\n",
       "         [-0.9775851 ],\n",
       "         [-1.01680516],\n",
       "         [-1.12514172],\n",
       "         [-0.9374036 ]],\n",
       "\n",
       "        [[-0.91319117],\n",
       "         [-0.85486867],\n",
       "         [-0.79689263],\n",
       "         [-0.73315104],\n",
       "         [-0.87198972]],\n",
       "\n",
       "        [[-0.90100283],\n",
       "         [-0.92114033],\n",
       "         [-1.02185477],\n",
       "         [-0.84871805],\n",
       "         [-0.86486941]],\n",
       "\n",
       "        [[-0.93621123],\n",
       "         [-0.91950371],\n",
       "         [-0.86971872],\n",
       "         [-0.87374605],\n",
       "         [-0.94958525]],\n",
       "\n",
       "        [[-1.23916743],\n",
       "         [-1.10527364],\n",
       "         [-1.14524653],\n",
       "         [-1.149992  ],\n",
       "         [-1.28315254]],\n",
       "\n",
       "        [[-1.1161685 ],\n",
       "         [-1.07972332],\n",
       "         [-1.1348109 ],\n",
       "         [-1.05598282],\n",
       "         [-1.35181873]],\n",
       "\n",
       "        [[-1.08961971],\n",
       "         [-1.02243438],\n",
       "         [-1.11534765],\n",
       "         [-1.09073733],\n",
       "         [-1.07438782]],\n",
       "\n",
       "        [[-0.51167953],\n",
       "         [-0.7238865 ],\n",
       "         [-0.77757535],\n",
       "         [-0.87881164],\n",
       "         [-0.91596249]],\n",
       "\n",
       "        [[-0.86422332],\n",
       "         [-0.75432136],\n",
       "         [-0.82502551],\n",
       "         [-0.76243959],\n",
       "         [-0.81869767]],\n",
       "\n",
       "        [[-0.97046271],\n",
       "         [-0.9335852 ],\n",
       "         [-0.76587553],\n",
       "         [-0.76862296],\n",
       "         [-0.82908209]],\n",
       "\n",
       "        [[-0.94499817],\n",
       "         [-0.85290566],\n",
       "         [-0.85389605],\n",
       "         [-0.86573315],\n",
       "         [-0.72030671]],\n",
       "\n",
       "        [[-0.92305878],\n",
       "         [-0.91513922],\n",
       "         [-0.82247075],\n",
       "         [-0.82807512],\n",
       "         [-0.68326757]],\n",
       "\n",
       "        [[-0.87597447],\n",
       "         [-0.79194332],\n",
       "         [-0.90853638],\n",
       "         [-0.60041789],\n",
       "         [-0.55282205]],\n",
       "\n",
       "        [[-1.1210355 ],\n",
       "         [-1.03845465],\n",
       "         [-1.06361556],\n",
       "         [-1.17259745],\n",
       "         [-1.28374372]],\n",
       "\n",
       "        [[-1.03388904],\n",
       "         [-1.24732427],\n",
       "         [-1.10487579],\n",
       "         [-1.28140199],\n",
       "         [-1.28020926]],\n",
       "\n",
       "        [[-0.69933888],\n",
       "         [-0.63491454],\n",
       "         [-0.75764787],\n",
       "         [-0.90301076],\n",
       "         [-0.8920131 ]],\n",
       "\n",
       "        [[-0.95741949],\n",
       "         [-0.95285456],\n",
       "         [-0.8402441 ],\n",
       "         [-0.77761998],\n",
       "         [-0.78766634]],\n",
       "\n",
       "        [[-0.81654804],\n",
       "         [-0.86459248],\n",
       "         [-0.7830593 ],\n",
       "         [-0.84197823],\n",
       "         [-1.03075584]],\n",
       "\n",
       "        [[-1.01784109],\n",
       "         [-0.94228649],\n",
       "         [-0.9637223 ],\n",
       "         [-1.12033937],\n",
       "         [-0.98544514]],\n",
       "\n",
       "        [[-0.85354457],\n",
       "         [-1.01599284],\n",
       "         [-0.92465332],\n",
       "         [-0.92827578],\n",
       "         [-0.89399259]],\n",
       "\n",
       "        [[-0.87563628],\n",
       "         [-0.8697048 ],\n",
       "         [-0.77697152],\n",
       "         [-0.82709404],\n",
       "         [-0.86974732]],\n",
       "\n",
       "        [[-0.6875535 ],\n",
       "         [-0.73375828],\n",
       "         [-0.66615977],\n",
       "         [-0.66272497],\n",
       "         [-0.75899196]],\n",
       "\n",
       "        [[-0.85024511],\n",
       "         [-0.88140641],\n",
       "         [-0.83030454],\n",
       "         [-0.84346497],\n",
       "         [-0.87135678]],\n",
       "\n",
       "        [[-0.84539216],\n",
       "         [-0.85608652],\n",
       "         [-0.95341249],\n",
       "         [-0.95432555],\n",
       "         [-0.89340753]],\n",
       "\n",
       "        [[-1.29642572],\n",
       "         [-1.06455931],\n",
       "         [-1.08681023],\n",
       "         [-0.91658729],\n",
       "         [-0.8693267 ]],\n",
       "\n",
       "        [[-0.93559047],\n",
       "         [-0.86715842],\n",
       "         [-1.09960327],\n",
       "         [-1.20589291],\n",
       "         [-1.20695556]],\n",
       "\n",
       "        [[-1.0700215 ],\n",
       "         [-1.00480823],\n",
       "         [-1.0606739 ],\n",
       "         [-1.01504186],\n",
       "         [-1.02191622]],\n",
       "\n",
       "        [[-0.89979547],\n",
       "         [-1.05132901],\n",
       "         [-0.95977319],\n",
       "         [-1.00354475],\n",
       "         [-0.86559982]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1.7609531 ],\n",
       "         [-1.70947652],\n",
       "         [-1.45426169],\n",
       "         [-1.30297408],\n",
       "         [-1.05137947]],\n",
       "\n",
       "        [[-1.53095232],\n",
       "         [-1.3035732 ],\n",
       "         [-0.95293351],\n",
       "         [-1.30393792],\n",
       "         [-1.19464448]],\n",
       "\n",
       "        [[-0.49054619],\n",
       "         [-0.3859702 ],\n",
       "         [-0.45525626],\n",
       "         [-0.42108582],\n",
       "         [-0.55282466]],\n",
       "\n",
       "        [[-0.87348834],\n",
       "         [-0.92687503],\n",
       "         [-0.82310628],\n",
       "         [-0.94430777],\n",
       "         [-1.19249275]],\n",
       "\n",
       "        [[-1.44225092],\n",
       "         [-1.39678332],\n",
       "         [-1.26183112],\n",
       "         [-1.04571504],\n",
       "         [-0.82918066]],\n",
       "\n",
       "        [[-0.72677448],\n",
       "         [-0.90734664],\n",
       "         [-1.08261998],\n",
       "         [-1.20004651],\n",
       "         [-1.09914864]],\n",
       "\n",
       "        [[-1.39393049],\n",
       "         [-1.44384667],\n",
       "         [-1.30435787],\n",
       "         [-1.23660723],\n",
       "         [-0.97944169]],\n",
       "\n",
       "        [[-0.63428626],\n",
       "         [-0.69598645],\n",
       "         [-0.78099493],\n",
       "         [-0.70654519],\n",
       "         [-0.76841452]],\n",
       "\n",
       "        [[-1.21923233],\n",
       "         [-1.41287307],\n",
       "         [-1.43154543],\n",
       "         [-1.12788723],\n",
       "         [-1.02287944]],\n",
       "\n",
       "        [[-1.50088037],\n",
       "         [-1.40875456],\n",
       "         [-1.50151153],\n",
       "         [-1.2926847 ],\n",
       "         [-1.08473019]],\n",
       "\n",
       "        [[-0.90852469],\n",
       "         [-0.97004856],\n",
       "         [-1.11190528],\n",
       "         [-1.10971714],\n",
       "         [-1.2470141 ]],\n",
       "\n",
       "        [[-0.52636852],\n",
       "         [-0.46495362],\n",
       "         [-0.40846008],\n",
       "         [-0.55626671],\n",
       "         [-0.90450869]],\n",
       "\n",
       "        [[-1.16580738],\n",
       "         [-1.41625806],\n",
       "         [-1.36127875],\n",
       "         [-1.04400882],\n",
       "         [-0.76393127]],\n",
       "\n",
       "        [[-0.68899364],\n",
       "         [-0.9054443 ],\n",
       "         [-0.92701545],\n",
       "         [-0.86859734],\n",
       "         [-0.79772185]],\n",
       "\n",
       "        [[-0.82752073],\n",
       "         [-0.61419355],\n",
       "         [-0.6864462 ],\n",
       "         [-0.81128404],\n",
       "         [-0.72355851]],\n",
       "\n",
       "        [[-1.18465514],\n",
       "         [-1.17647846],\n",
       "         [-1.01737157],\n",
       "         [-0.85716885],\n",
       "         [-0.91680605]],\n",
       "\n",
       "        [[-0.96911518],\n",
       "         [-1.19898667],\n",
       "         [-1.15466677],\n",
       "         [-0.88673111],\n",
       "         [-0.98329667]],\n",
       "\n",
       "        [[-0.96595128],\n",
       "         [-0.56966912],\n",
       "         [-0.5663827 ],\n",
       "         [-0.67654589],\n",
       "         [-0.75581582]],\n",
       "\n",
       "        [[-0.98442826],\n",
       "         [-0.92248688],\n",
       "         [-0.87440865],\n",
       "         [-1.31168941],\n",
       "         [-1.30028873]],\n",
       "\n",
       "        [[-1.15500851],\n",
       "         [-1.26629295],\n",
       "         [-1.117054  ],\n",
       "         [-1.25895605],\n",
       "         [-1.19717312]],\n",
       "\n",
       "        [[-0.463178  ],\n",
       "         [-0.6790194 ],\n",
       "         [-0.87637654],\n",
       "         [-0.67636099],\n",
       "         [-0.86869918]],\n",
       "\n",
       "        [[-0.912633  ],\n",
       "         [-1.03185586],\n",
       "         [-0.85462331],\n",
       "         [-0.84053901],\n",
       "         [-0.63400747]],\n",
       "\n",
       "        [[-1.19840428],\n",
       "         [-1.03111324],\n",
       "         [-1.30622103],\n",
       "         [-1.11994855],\n",
       "         [-1.072183  ]],\n",
       "\n",
       "        [[-1.09140494],\n",
       "         [-1.00753988],\n",
       "         [-0.89771919],\n",
       "         [-0.90374829],\n",
       "         [-0.81032531]],\n",
       "\n",
       "        [[-0.51175287],\n",
       "         [-0.59046067],\n",
       "         [-0.49183915],\n",
       "         [-0.64445668],\n",
       "         [-0.80897428]],\n",
       "\n",
       "        [[-1.49318311],\n",
       "         [-1.42258799],\n",
       "         [-1.31620415],\n",
       "         [-1.25415841],\n",
       "         [-1.20751826]],\n",
       "\n",
       "        [[-0.755176  ],\n",
       "         [-0.59401213],\n",
       "         [-0.87718734],\n",
       "         [-0.84760157],\n",
       "         [-0.8066049 ]],\n",
       "\n",
       "        [[-1.01991083],\n",
       "         [-1.16746064],\n",
       "         [-0.9304    ],\n",
       "         [-0.83913567],\n",
       "         [-0.73712137]],\n",
       "\n",
       "        [[-1.13200723],\n",
       "         [-1.12157327],\n",
       "         [-1.03990657],\n",
       "         [-0.93934209],\n",
       "         [-0.96933448]],\n",
       "\n",
       "        [[-1.38408796],\n",
       "         [-1.18630348],\n",
       "         [-1.12702597],\n",
       "         [-0.98718622],\n",
       "         [-1.02160662]],\n",
       "\n",
       "        [[-0.89365758],\n",
       "         [-0.93278236],\n",
       "         [-1.07665684],\n",
       "         [-1.05206985],\n",
       "         [-0.81991994]],\n",
       "\n",
       "        [[-0.83558163],\n",
       "         [-0.9019832 ],\n",
       "         [-0.88690409],\n",
       "         [-0.90657589],\n",
       "         [-1.04761977]]],\n",
       "\n",
       "\n",
       "       [[[-1.30297408],\n",
       "         [-1.05137947],\n",
       "         [-1.03958248],\n",
       "         [-1.32905766],\n",
       "         [-1.13837166]],\n",
       "\n",
       "        [[-1.30393792],\n",
       "         [-1.19464448],\n",
       "         [-1.3048773 ],\n",
       "         [-1.14709931],\n",
       "         [-1.02415777]],\n",
       "\n",
       "        [[-0.42108582],\n",
       "         [-0.55282466],\n",
       "         [-0.87870995],\n",
       "         [-0.83694795],\n",
       "         [-0.87734876]],\n",
       "\n",
       "        [[-0.94430777],\n",
       "         [-1.19249275],\n",
       "         [-0.77864236],\n",
       "         [-0.51928877],\n",
       "         [-0.64406663]],\n",
       "\n",
       "        [[-1.04571504],\n",
       "         [-0.82918066],\n",
       "         [-1.22465469],\n",
       "         [-1.1767269 ],\n",
       "         [-1.21122556]],\n",
       "\n",
       "        [[-1.20004651],\n",
       "         [-1.09914864],\n",
       "         [-0.84005316],\n",
       "         [-0.8139863 ],\n",
       "         [-0.70338839]],\n",
       "\n",
       "        [[-1.23660723],\n",
       "         [-0.97944169],\n",
       "         [-0.8380694 ],\n",
       "         [-0.91107691],\n",
       "         [-1.05175668]],\n",
       "\n",
       "        [[-0.70654519],\n",
       "         [-0.76841452],\n",
       "         [-0.67545376],\n",
       "         [-1.04074631],\n",
       "         [-0.90349413]],\n",
       "\n",
       "        [[-1.12788723],\n",
       "         [-1.02287944],\n",
       "         [-1.092663  ],\n",
       "         [-1.25486502],\n",
       "         [-1.17891113]],\n",
       "\n",
       "        [[-1.2926847 ],\n",
       "         [-1.08473019],\n",
       "         [-0.99863625],\n",
       "         [-0.95248724],\n",
       "         [-1.09419931]],\n",
       "\n",
       "        [[-1.10971714],\n",
       "         [-1.2470141 ],\n",
       "         [-1.2213605 ],\n",
       "         [-1.32285129],\n",
       "         [-1.24269283]],\n",
       "\n",
       "        [[-0.55626671],\n",
       "         [-0.90450869],\n",
       "         [-0.92372337],\n",
       "         [-1.03072795],\n",
       "         [-0.80404142]],\n",
       "\n",
       "        [[-1.04400882],\n",
       "         [-0.76393127],\n",
       "         [-0.90302372],\n",
       "         [-0.80001004],\n",
       "         [-0.78976188]],\n",
       "\n",
       "        [[-0.86859734],\n",
       "         [-0.79772185],\n",
       "         [-0.89775509],\n",
       "         [-0.88489912],\n",
       "         [-0.8692502 ]],\n",
       "\n",
       "        [[-0.81128404],\n",
       "         [-0.72355851],\n",
       "         [-0.69161284],\n",
       "         [-0.7462586 ],\n",
       "         [-0.91258672]],\n",
       "\n",
       "        [[-0.85716885],\n",
       "         [-0.91680605],\n",
       "         [-0.733649  ],\n",
       "         [-0.64992044],\n",
       "         [-0.65884519]],\n",
       "\n",
       "        [[-0.88673111],\n",
       "         [-0.98329667],\n",
       "         [-1.12191242],\n",
       "         [-1.34670356],\n",
       "         [-1.27929835]],\n",
       "\n",
       "        [[-0.67654589],\n",
       "         [-0.75581582],\n",
       "         [-0.61656918],\n",
       "         [-0.45210341],\n",
       "         [-0.53911991]],\n",
       "\n",
       "        [[-1.31168941],\n",
       "         [-1.30028873],\n",
       "         [-1.14778234],\n",
       "         [-1.01043775],\n",
       "         [-0.93191376]],\n",
       "\n",
       "        [[-1.25895605],\n",
       "         [-1.19717312],\n",
       "         [-1.16529707],\n",
       "         [-1.36505914],\n",
       "         [-1.2337955 ]],\n",
       "\n",
       "        [[-0.67636099],\n",
       "         [-0.86869918],\n",
       "         [-0.8736377 ],\n",
       "         [-0.9809631 ],\n",
       "         [-0.86579363]],\n",
       "\n",
       "        [[-0.84053901],\n",
       "         [-0.63400747],\n",
       "         [-0.74713844],\n",
       "         [-0.79318301],\n",
       "         [-0.87217144]],\n",
       "\n",
       "        [[-1.11994855],\n",
       "         [-1.072183  ],\n",
       "         [-0.96969498],\n",
       "         [-0.88685652],\n",
       "         [-0.88771047]],\n",
       "\n",
       "        [[-0.90374829],\n",
       "         [-0.81032531],\n",
       "         [-0.9094369 ],\n",
       "         [-1.18122979],\n",
       "         [-1.08007256]],\n",
       "\n",
       "        [[-0.64445668],\n",
       "         [-0.80897428],\n",
       "         [-0.86112492],\n",
       "         [-0.78712782],\n",
       "         [-0.70002908]],\n",
       "\n",
       "        [[-1.25415841],\n",
       "         [-1.20751826],\n",
       "         [-1.08008613],\n",
       "         [-1.0449586 ],\n",
       "         [-1.11208614]],\n",
       "\n",
       "        [[-0.84760157],\n",
       "         [-0.8066049 ],\n",
       "         [-0.87398244],\n",
       "         [-0.86288049],\n",
       "         [-0.89161455]],\n",
       "\n",
       "        [[-0.83913567],\n",
       "         [-0.73712137],\n",
       "         [-0.82825395],\n",
       "         [-0.93986052],\n",
       "         [-0.78534585]],\n",
       "\n",
       "        [[-0.93934209],\n",
       "         [-0.96933448],\n",
       "         [-0.84044497],\n",
       "         [-0.73943757],\n",
       "         [-0.77420072]],\n",
       "\n",
       "        [[-0.98718622],\n",
       "         [-1.02160662],\n",
       "         [-0.96804594],\n",
       "         [-1.04476719],\n",
       "         [-1.14267752]],\n",
       "\n",
       "        [[-1.05206985],\n",
       "         [-0.81991994],\n",
       "         [-0.84484277],\n",
       "         [-0.84217903],\n",
       "         [-0.92736944]],\n",
       "\n",
       "        [[-0.90657589],\n",
       "         [-1.04761977],\n",
       "         [-0.99133642],\n",
       "         [-1.10586628],\n",
       "         [-1.13925761]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 5, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 32, 5, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 32, 5, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_epochs = 100 #2000\\n#learning_rate = 0.001\\nbatch_size = 32 #250 \\nn_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\\nrate_dropout = [0.8, 0.4, 0.2, 0.1]\\nweight_decay = 1e-4\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "n_epochs = 100 #2000\n",
    "#learning_rate = 0.001\n",
    "batch_size = 32 #250 \n",
    "n_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\n",
    "rate_dropout = [0.8, 0.4, 0.2, 0.1]\n",
    "weight_decay = 1e-4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Build the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,8,1,100].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1852\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,8,1,100].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-be8493ccda3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"he_normal\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"he_normal\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    221\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                                 input_list)\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1089\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    861\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mpool_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m     outputs = self.pool_function(\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpool_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[0;32m   4604\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ksize cannot be zero.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4606\u001b[1;33m     return gen_nn_ops.max_pool(\n\u001b[0m\u001b[0;32m   4607\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4608\u001b[0m         \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(input, ksize, strides, padding, explicit_paddings, data_format, name)\u001b[0m\n\u001b[0;32m   5324\u001b[0m     \u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"NHWC\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5325\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data_format\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5326\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m   5327\u001b[0m         \u001b[1;34m\"MaxPool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5328\u001b[0m                    \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    746\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         compute_device)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3526\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3527\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3528\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2013\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2015\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1854\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1856\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1858\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_4/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,8,1,100]."
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, DepthwiseConv2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import optimizers, regularizers\n",
    "import keras.backend as K\n",
    "#K.set_image_data_format('channels_first')\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "# Convolution2D(filtrosConv1, tamaño_filtro1, padding=\"same\", input_shape=(longitud, altura,3), activation = \"relu\")\n",
    "    # - filtrosConv1 número de filtros que aplicaremos tras la primera convolución, normalmente este tamaño va a aumentando\n",
    "    # tras convoluciones para que aumente la dimensión de profundidad (qué cosas hay en mi imagen)\n",
    "    # - tamaño_filtro1 tamaño espacial del kernel (de los filtros)\n",
    "    # - padding = si es same es que es igual que la imagen, vamos crea una imagen del mismo tamaño con el filtro, si es \n",
    "    # valid es que no hay padding y crea una imagen más pequeña que la imagen (creo)\n",
    "    # - input_shape = longitud y altura, tamaño que usará para convolucionar al entrenar\n",
    "    \n",
    "# CAPA PARA FILTRADO TEMPORAL \n",
    "model.add(Conv2D(filters = 40, kernel_size=(1,25), padding=\"same\", activation=\"sigmoid\",input_shape=(32, 5, 1 ), kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l1_l2(weight_decay)))\n",
    "# CAPA PARA FILTRADO ESPACIAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(32,1), padding=\"same\", activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "## Siguientes capas convolucionales: \n",
    "model.add(Conv2D(20, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\"\"\"\n",
    "\n",
    "model.add(Flatten())\n",
    "\"\"\"\n",
    "model.add(Dense(20, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Dropout(0.5))\n",
    "\"\"\"\n",
    "model.add(Dense(y_train.shape[1], activation=\"softmax\"))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x1f78e766940>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1f78e7fe8e0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1f78e7fe460>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1f78e8af4f0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1f78e8b3eb0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1f78e9083a0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1f78e8f0670>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1f78e90dd00>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x1f78e91c790>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1f78e91c9a0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "conv2d_1\n",
      "max_pooling2d\n",
      "dropout\n",
      "conv2d_2\n",
      "conv2d_3\n",
      "max_pooling2d_1\n",
      "dropout_1\n",
      "flatten\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers: print (l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the parameters of a layer can bee accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25, 1, 40)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[0].get_weights()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 3.33490103e-01, -1.57580525e-01,  3.35452914e-01,\n",
       "          -1.94632217e-01, -3.96762669e-01,  9.95909944e-02,\n",
       "           1.15123205e-01, -1.01073831e-02, -1.13926522e-01,\n",
       "           3.95340055e-01,  2.33635642e-02,  4.93222177e-01,\n",
       "          -3.68203223e-02,  2.16262519e-01, -2.46117234e-01,\n",
       "          -1.84759676e-01, -2.28400186e-01, -3.74564916e-01,\n",
       "          -2.22217701e-02,  1.78992927e-01,  3.72651607e-01,\n",
       "          -1.43623188e-01,  2.58541796e-02, -2.37669155e-01,\n",
       "          -2.48324290e-01,  1.22617401e-01, -1.55442744e-01,\n",
       "           3.33344460e-01, -4.69481610e-02, -2.74087280e-01,\n",
       "          -1.33975908e-01, -1.42787723e-02, -5.45610525e-02,\n",
       "           3.65148127e-01,  4.96513508e-02, -6.26240969e-01,\n",
       "          -3.43262374e-01, -1.87661976e-01,  1.98268235e-01,\n",
       "           2.44861066e-01]],\n",
       "\n",
       "        [[ 1.67041749e-01,  1.69391572e-01,  6.20174646e-01,\n",
       "           1.09318318e-02,  5.01342773e-01,  1.17305266e-02,\n",
       "          -1.73585549e-01,  1.68081969e-02,  3.80380601e-01,\n",
       "           1.91032052e-01,  2.79262960e-01, -1.25333918e-02,\n",
       "           4.38140780e-02, -1.93098515e-01, -2.12036788e-01,\n",
       "          -2.84728017e-02,  5.33417881e-01, -8.55076015e-02,\n",
       "           1.02814250e-01,  2.39881724e-01,  1.92138761e-01,\n",
       "          -1.31083369e-01, -9.52198207e-02,  6.99331090e-02,\n",
       "           2.48887405e-01, -3.22545558e-01, -6.55058771e-02,\n",
       "          -4.56169158e-01, -9.73432139e-02,  1.12748899e-01,\n",
       "          -2.38799334e-01,  7.72813261e-02, -8.76827091e-02,\n",
       "          -1.43079713e-01,  5.07114649e-01, -5.63116252e-01,\n",
       "          -2.04691499e-01,  1.88604102e-01,  1.01876907e-01,\n",
       "          -4.00173873e-01]],\n",
       "\n",
       "        [[ 6.17617145e-02, -5.53739965e-01, -1.92007765e-01,\n",
       "           1.30386442e-01, -3.43714416e-01, -2.71961004e-01,\n",
       "          -4.37878042e-01, -2.94300020e-02, -5.26104309e-02,\n",
       "          -4.71883006e-02,  5.70806377e-02,  4.18335021e-01,\n",
       "          -7.63518885e-02,  8.14091042e-02,  1.00579530e-01,\n",
       "          -2.49975875e-01,  2.07045674e-01,  1.97435707e-01,\n",
       "          -1.70236409e-01, -2.15707719e-01,  5.53783596e-01,\n",
       "           3.75832915e-01, -4.67283070e-01,  4.12790120e-01,\n",
       "          -4.91934456e-02, -9.60600749e-03,  1.04969181e-01,\n",
       "          -4.17428583e-01, -2.06749871e-01, -2.17780486e-01,\n",
       "           2.31286913e-01,  1.09486602e-01,  1.80737063e-01,\n",
       "          -3.85176130e-02,  1.03923619e-01, -7.09997714e-02,\n",
       "          -3.84381324e-01, -5.69447696e-01, -3.41230005e-01,\n",
       "          -2.40429752e-02]],\n",
       "\n",
       "        [[ 2.50503182e-01,  1.01438403e-01, -5.38944542e-01,\n",
       "           1.05741121e-01,  2.80762743e-02, -5.78239262e-01,\n",
       "           4.78389740e-01,  7.41107911e-02,  3.68493676e-01,\n",
       "          -4.39033091e-01,  3.85232896e-01,  7.56891295e-02,\n",
       "           5.42460740e-01,  5.13560832e-01, -1.25547945e-01,\n",
       "          -6.42828643e-02, -4.99234408e-01,  2.19934300e-01,\n",
       "           1.83785353e-02,  4.04228240e-01,  1.14199463e-02,\n",
       "          -8.92036036e-02,  5.98094799e-03,  4.66512665e-02,\n",
       "          -2.25364745e-01, -2.50988454e-01, -3.80934805e-01,\n",
       "          -1.29180223e-01, -3.17855746e-01, -5.48523009e-01,\n",
       "          -8.71627331e-02, -2.42073387e-01,  2.43083201e-02,\n",
       "           6.91161975e-02, -4.46999371e-01,  3.17876041e-01,\n",
       "          -2.58024991e-01,  5.35335302e-01, -4.01231378e-01,\n",
       "           5.81668794e-01]],\n",
       "\n",
       "        [[-3.22857559e-01,  4.49748218e-01, -5.17068684e-01,\n",
       "           2.52860457e-01, -4.38737050e-02,  1.61282316e-01,\n",
       "          -3.03850591e-01,  3.56033607e-03, -1.07886270e-01,\n",
       "          -3.19326706e-02,  4.49665874e-01, -1.00244470e-01,\n",
       "          -1.64909184e-01,  5.87788299e-02, -5.99340439e-01,\n",
       "           2.15763360e-01, -2.68485159e-01,  2.39577447e-03,\n",
       "           3.05040032e-01,  5.32313943e-01,  1.33910984e-01,\n",
       "           6.31953105e-02, -1.90491855e-01, -1.24664970e-01,\n",
       "           1.73235908e-01, -1.26682535e-01,  8.24969560e-02,\n",
       "          -2.94646379e-02,  3.15265656e-01,  2.20551535e-01,\n",
       "           1.65988833e-01, -8.64654779e-02, -5.41667826e-02,\n",
       "           3.62181030e-02, -3.27412724e-01,  1.19431250e-01,\n",
       "          -1.19053833e-01,  2.68030345e-01,  3.47766876e-01,\n",
       "          -4.90833223e-02]],\n",
       "\n",
       "        [[-3.37084621e-01, -2.07510397e-01,  4.35200781e-01,\n",
       "           1.60692155e-01, -4.40602005e-01, -4.33614776e-02,\n",
       "           3.19786876e-01, -5.70624948e-01,  5.76593637e-01,\n",
       "          -5.61337888e-01, -1.48431122e-01, -2.47477487e-01,\n",
       "          -9.43019167e-02, -1.51029676e-01,  5.74204564e-01,\n",
       "           3.06729853e-01, -3.15841377e-01, -7.43646845e-02,\n",
       "           7.81178400e-02, -3.33890826e-01, -2.91361809e-01,\n",
       "          -2.32757822e-01,  4.95617062e-01, -1.75754979e-01,\n",
       "           2.64361184e-02,  5.80043197e-02,  8.04768205e-02,\n",
       "           3.63169819e-01,  2.74768740e-01,  5.08982018e-02,\n",
       "           4.19374675e-01, -4.28599924e-01,  3.57661754e-01,\n",
       "          -4.60629284e-01, -1.45217314e-01,  5.46859562e-01,\n",
       "          -7.49900118e-02,  2.31022298e-01,  2.17652097e-01,\n",
       "           3.47418606e-01]],\n",
       "\n",
       "        [[ 1.71938449e-01, -2.10474059e-01,  9.11868550e-03,\n",
       "          -1.83254138e-01,  1.82510450e-01, -5.04974186e-01,\n",
       "           1.39246807e-01, -4.49136505e-03,  5.32484911e-02,\n",
       "           1.65590972e-01, -3.97378117e-01, -1.43747941e-01,\n",
       "           1.88539329e-03, -1.06386758e-01, -5.83575591e-02,\n",
       "          -3.32827240e-01,  1.49624981e-02,  5.79683185e-01,\n",
       "          -2.91306768e-02,  1.97177485e-01,  4.52056110e-01,\n",
       "           3.20952475e-01,  4.86956626e-01,  1.05046846e-01,\n",
       "          -1.00391693e-01, -5.33603907e-01, -1.99288487e-01,\n",
       "          -1.96643740e-01, -5.01495041e-02,  2.34928772e-01,\n",
       "          -1.31859351e-02, -4.31748927e-01, -1.25024334e-01,\n",
       "           1.19098993e-02, -5.42984188e-01,  1.89150870e-01,\n",
       "          -7.85959363e-02,  2.19145000e-01, -1.33788392e-01,\n",
       "          -1.38923645e-01]],\n",
       "\n",
       "        [[-2.98993379e-01,  2.24795640e-01,  5.54625452e-01,\n",
       "           3.56433898e-01, -2.25707501e-01,  4.39743102e-01,\n",
       "          -3.46797615e-01,  3.21591944e-01, -1.12111561e-01,\n",
       "           5.63177355e-02, -2.47304156e-01,  4.82411683e-01,\n",
       "           1.71003312e-01,  3.54746878e-01, -3.50191385e-01,\n",
       "          -1.58830330e-01, -7.88752288e-02, -1.90468013e-01,\n",
       "           7.60152414e-02,  5.10367751e-01,  1.16542876e-01,\n",
       "          -3.00359249e-01,  8.30024257e-02, -1.10756449e-01,\n",
       "           2.13326529e-01, -3.85580987e-01,  3.48620981e-01,\n",
       "           3.96102786e-01,  4.75131124e-01,  2.00345740e-01,\n",
       "          -1.34352416e-01,  2.14859471e-01,  2.40816697e-01,\n",
       "          -1.54854788e-03,  3.28516424e-01, -2.86712140e-01,\n",
       "          -1.51457906e-01,  2.58298904e-01, -1.45277888e-01,\n",
       "          -4.79189664e-01]],\n",
       "\n",
       "        [[ 7.13328794e-02,  2.03088671e-01,  1.11674435e-01,\n",
       "           4.22876552e-02,  2.86470562e-01, -1.07300766e-01,\n",
       "           9.99059230e-02,  3.15455467e-01,  3.17480266e-01,\n",
       "           2.68031299e-01,  2.46002823e-01,  3.52647960e-01,\n",
       "           2.28697166e-01, -1.14122838e-01,  2.79978272e-02,\n",
       "           3.77564400e-01, -1.37843698e-01,  2.30646253e-01,\n",
       "          -3.90376240e-01,  1.42572030e-01, -2.94776678e-01,\n",
       "          -1.79095164e-01,  2.31429249e-01,  7.24858642e-02,\n",
       "           2.80678242e-01, -1.68725088e-01, -1.29857168e-01,\n",
       "           2.90351152e-01, -2.32463896e-01, -5.67277074e-01,\n",
       "           4.99686599e-03, -4.28668082e-01, -4.57093343e-02,\n",
       "          -2.62786806e-01, -5.93292899e-02,  1.43718317e-01,\n",
       "          -3.31249058e-01,  3.75352800e-01, -2.32542560e-01,\n",
       "           2.57123023e-01]],\n",
       "\n",
       "        [[ 1.30913153e-01, -1.44977003e-01, -7.92434663e-02,\n",
       "          -2.87180632e-01,  1.25547171e-01, -2.26773441e-01,\n",
       "           1.43158004e-01, -2.05233581e-02,  6.04782760e-01,\n",
       "          -6.00438863e-02, -4.93522048e-01, -1.51682496e-01,\n",
       "          -1.77508295e-01,  2.24586934e-01, -3.06535214e-01,\n",
       "          -9.01768878e-02,  2.91398197e-01,  4.71128881e-01,\n",
       "           3.85551862e-02, -9.64777917e-02,  2.94885755e-01,\n",
       "          -3.10745418e-01,  9.12775695e-02, -1.90254629e-01,\n",
       "          -8.53800923e-02, -2.47156262e-01, -1.37707248e-01,\n",
       "          -4.26290989e-01,  2.27414235e-01, -3.63195777e-01,\n",
       "           1.87527895e-01,  4.08528477e-01, -2.17161477e-02,\n",
       "          -3.11961204e-01,  5.08179307e-01,  4.77959067e-01,\n",
       "           1.34685695e-01, -5.35214841e-01, -2.87571788e-01,\n",
       "           3.94132286e-01]],\n",
       "\n",
       "        [[ 2.92164415e-01,  2.54151344e-01, -3.72774117e-02,\n",
       "           1.89095572e-01,  4.98320669e-01,  2.55727977e-01,\n",
       "          -6.26405358e-01,  3.30633640e-01, -8.13842788e-02,\n",
       "           1.73529953e-01,  1.08047709e-01,  5.19519746e-02,\n",
       "          -1.12745076e-01,  1.26682386e-01, -9.29855704e-02,\n",
       "           8.57655331e-02,  1.46544158e-01, -4.51358467e-01,\n",
       "           2.60134879e-03,  5.20597138e-02, -2.99633332e-02,\n",
       "          -3.64672393e-02,  2.92438865e-02,  4.60029334e-01,\n",
       "           4.40949708e-01, -2.06140950e-02,  5.48076689e-01,\n",
       "           3.46406877e-01, -5.17181337e-01,  1.69646870e-02,\n",
       "           1.77023426e-01,  1.64134894e-02, -1.76415339e-01,\n",
       "          -1.22346334e-01, -3.48838866e-01,  6.08103454e-01,\n",
       "           1.07458727e-02, -1.04845025e-01,  2.56697182e-03,\n",
       "          -3.69307101e-01]],\n",
       "\n",
       "        [[ 6.12414122e-01,  5.87966263e-01, -3.60628292e-02,\n",
       "           3.06336194e-01, -1.30633399e-01, -1.68775409e-01,\n",
       "          -1.58535540e-02,  8.95873010e-02,  6.53515309e-02,\n",
       "           1.60870999e-01,  8.16489309e-02,  1.86529994e-01,\n",
       "           1.62354915e-03,  5.38661033e-02, -1.18718103e-01,\n",
       "          -7.70496950e-02,  4.03200209e-01, -4.64625388e-01,\n",
       "          -1.05792180e-01, -2.81552672e-01,  8.67396519e-02,\n",
       "          -2.21171722e-01, -8.63074884e-02, -2.41734341e-01,\n",
       "           2.21324023e-02,  8.55887756e-02,  1.28002405e-01,\n",
       "           2.67585456e-01,  2.64215022e-01,  1.98916823e-01,\n",
       "           1.15612827e-01, -1.60975698e-02, -5.48113525e-01,\n",
       "          -4.93447781e-01, -5.65521605e-02, -1.97128788e-01,\n",
       "          -2.86983728e-01,  3.80081385e-01, -4.71776545e-01,\n",
       "           2.30858073e-01]],\n",
       "\n",
       "        [[ 4.90902066e-01,  3.90137851e-01,  2.12069437e-01,\n",
       "          -1.32977635e-01, -3.13265324e-01,  1.83120593e-01,\n",
       "           5.50374508e-01,  3.38229448e-01,  1.44547656e-01,\n",
       "           5.22337198e-01,  3.73267233e-01,  4.83317584e-01,\n",
       "          -7.18623996e-02,  4.63795774e-02,  3.94671261e-01,\n",
       "          -5.83868697e-02,  1.39952660e-01,  4.57611859e-01,\n",
       "          -2.89836586e-01,  5.06700397e-01, -2.72732615e-01,\n",
       "           3.74587998e-02, -2.16985568e-02,  1.51955649e-01,\n",
       "           2.47585326e-01,  2.29698405e-01,  1.12986192e-01,\n",
       "           2.93744057e-01, -2.38823071e-02, -1.12437904e-01,\n",
       "           1.83387443e-01,  4.17830050e-02, -5.23277409e-02,\n",
       "           1.27089530e-01, -3.24562080e-02,  1.59936711e-01,\n",
       "           4.51247126e-01, -3.77144814e-01, -2.69559957e-02,\n",
       "          -3.75826538e-01]],\n",
       "\n",
       "        [[ 5.13428986e-01,  2.28523925e-01,  2.91534793e-02,\n",
       "           9.23719704e-02,  1.90947488e-01,  8.40469543e-03,\n",
       "           2.82402158e-01, -2.49691054e-01,  9.70064998e-02,\n",
       "           3.56529862e-01, -5.08659109e-02,  2.06550896e-01,\n",
       "          -3.48698884e-01,  1.52448341e-01, -1.67905509e-01,\n",
       "          -2.10125312e-01,  1.01378806e-01, -1.51333004e-01,\n",
       "          -4.29923207e-01, -1.47618935e-01, -4.95801389e-01,\n",
       "          -1.33139715e-01, -5.58317721e-01, -2.01183677e-01,\n",
       "          -9.82241705e-02,  1.94174588e-01, -2.13579252e-01,\n",
       "          -3.08900923e-01,  3.56168747e-01, -2.65067536e-02,\n",
       "          -5.09506047e-01,  1.52333930e-01, -3.97280343e-02,\n",
       "           1.18180327e-01,  7.28706568e-02, -2.34524086e-01,\n",
       "           1.34248227e-01,  1.38408169e-01,  1.47860106e-02,\n",
       "           1.08564720e-01]],\n",
       "\n",
       "        [[ 5.90072155e-01,  9.98049527e-02, -5.34942448e-01,\n",
       "          -2.11409107e-01,  1.95786625e-01,  3.04921895e-01,\n",
       "           1.32184075e-02, -2.16507733e-01, -2.59166479e-01,\n",
       "          -1.06406242e-01,  2.41793677e-01, -5.23590982e-01,\n",
       "           2.36973763e-01, -2.78084487e-01,  5.77382632e-02,\n",
       "          -1.62894085e-01, -1.66284576e-01,  1.02731744e-02,\n",
       "          -1.19858898e-01,  2.21098457e-02,  2.14891300e-01,\n",
       "          -1.84240073e-01, -2.58931220e-01, -1.44731790e-01,\n",
       "           1.84195161e-01,  5.07045269e-01, -3.48740280e-01,\n",
       "           2.86845267e-01,  2.58802682e-01,  1.43438950e-01,\n",
       "           4.85623002e-01, -3.96681339e-01, -5.47276974e-01,\n",
       "          -4.47701871e-01,  3.76387656e-01,  2.19498605e-01,\n",
       "          -9.42427367e-02,  1.46006316e-01,  1.39329970e-01,\n",
       "           1.73649546e-02]],\n",
       "\n",
       "        [[-4.34234202e-01, -2.26400077e-01, -2.05395952e-01,\n",
       "          -2.33575508e-01,  6.19968057e-01, -4.49525893e-01,\n",
       "           2.16161177e-01,  1.14241116e-01, -2.28489518e-01,\n",
       "          -2.19782725e-01, -3.46655846e-01, -1.71735182e-01,\n",
       "          -3.21468383e-01,  2.82477438e-01,  8.77228901e-02,\n",
       "          -5.41952020e-03,  1.02981687e-01, -4.18060631e-01,\n",
       "           1.29011884e-01, -3.38981390e-01,  4.91028339e-01,\n",
       "          -5.42406976e-01,  1.04709253e-01,  6.51513040e-02,\n",
       "          -3.93419534e-01, -6.33618474e-01, -2.09624693e-01,\n",
       "           6.19669743e-02,  2.73814380e-01, -6.08230196e-02,\n",
       "           5.90308607e-02,  6.14554584e-02, -2.04141419e-02,\n",
       "           5.68048358e-01,  2.90250897e-01, -2.03442648e-01,\n",
       "           3.50723654e-01, -1.38861775e-01, -6.00549579e-01,\n",
       "           4.11588222e-01]],\n",
       "\n",
       "        [[-1.54822871e-01,  3.46337497e-01,  1.94653571e-01,\n",
       "           4.74632263e-01, -5.49404263e-01,  2.41519529e-02,\n",
       "           8.62092376e-02,  2.55273044e-01, -5.89624643e-02,\n",
       "          -6.29399061e-01,  1.17178768e-01, -4.87022549e-02,\n",
       "          -4.44201171e-01, -2.92275965e-01,  1.45861119e-01,\n",
       "          -4.75126296e-01, -1.35789305e-01, -2.73107857e-01,\n",
       "          -2.87590593e-01, -4.95786071e-02, -3.99363160e-01,\n",
       "          -3.28317523e-01, -4.36088651e-01,  1.44932151e-01,\n",
       "          -1.99456513e-01,  4.26278085e-01, -1.26545176e-01,\n",
       "           3.97997737e-01,  2.56459445e-01, -2.10914165e-01,\n",
       "          -5.12590170e-01,  1.53721049e-01, -4.47764620e-02,\n",
       "          -3.07414979e-01, -3.93527180e-01,  1.41611800e-01,\n",
       "           2.78885096e-01, -6.29578158e-02,  1.47717997e-01,\n",
       "          -2.93157790e-02]],\n",
       "\n",
       "        [[-2.90636271e-01,  5.24809957e-01,  2.05504641e-01,\n",
       "          -1.88823819e-01,  3.09038788e-01, -1.97112903e-01,\n",
       "           1.74489558e-01, -1.23048440e-01,  9.89149511e-02,\n",
       "           3.41191709e-01,  3.68507177e-01,  2.13298164e-02,\n",
       "          -1.27896816e-01, -4.14625138e-01, -5.39633155e-01,\n",
       "          -3.97283673e-01,  5.36473095e-01,  5.27565897e-01,\n",
       "           6.81202114e-02,  1.96699530e-01, -3.23238254e-01,\n",
       "           2.01941907e-01, -1.91281572e-01, -7.86208839e-05,\n",
       "           6.13972783e-01,  3.69934663e-02,  1.64203625e-02,\n",
       "           2.27191269e-01,  2.08502069e-01, -1.59313634e-01,\n",
       "           3.62677090e-02,  4.34308022e-01, -2.10480735e-01,\n",
       "           1.42023027e-01,  1.47649392e-01, -2.88716018e-01,\n",
       "          -1.03954606e-01,  6.42144121e-03, -2.61887491e-01,\n",
       "           4.62786466e-01]],\n",
       "\n",
       "        [[ 7.35986307e-02,  3.75960678e-01, -2.79854178e-01,\n",
       "           4.74713221e-02,  8.39150622e-02, -1.12368889e-01,\n",
       "           7.59347975e-02, -3.10421400e-02,  4.38575596e-01,\n",
       "           3.87141965e-02, -4.97965254e-02, -3.14033329e-01,\n",
       "          -2.67684042e-01,  1.01623327e-01,  2.11849228e-01,\n",
       "           3.07809830e-01,  4.94762026e-02,  5.23383200e-01,\n",
       "          -1.19774468e-01, -3.98591049e-02, -1.33785933e-01,\n",
       "          -1.02748387e-02,  2.80482769e-02,  5.83008707e-01,\n",
       "           4.30562764e-01, -1.83562085e-01, -3.72773230e-01,\n",
       "           2.70636499e-01,  4.09902871e-01, -2.73955464e-01,\n",
       "           5.31010479e-02, -2.36806616e-01, -5.32946400e-02,\n",
       "          -2.09290177e-01,  2.11476222e-01,  1.38304710e-01,\n",
       "          -2.16780245e-01,  3.21366906e-01,  5.07765748e-02,\n",
       "           3.87268037e-01]],\n",
       "\n",
       "        [[ 3.12393904e-01, -6.68922886e-02, -2.18257725e-01,\n",
       "           8.11615679e-03, -4.57443744e-01,  3.64419520e-01,\n",
       "           2.99500614e-01, -7.51044527e-02,  1.07970640e-01,\n",
       "          -1.86493650e-01,  1.69892043e-01, -2.99237937e-01,\n",
       "           6.14556074e-01, -2.59078741e-01,  1.01374183e-02,\n",
       "           5.23082078e-01, -2.43514031e-02,  2.70219296e-02,\n",
       "           4.79443610e-01,  2.35797614e-01, -2.60529429e-01,\n",
       "          -4.81434643e-01, -4.53478515e-01,  3.10761571e-01,\n",
       "           1.15696974e-01, -4.77379709e-02, -1.53901652e-01,\n",
       "           6.58039302e-02,  1.84159443e-01, -1.00788571e-01,\n",
       "          -1.14990681e-01, -3.17219123e-02, -4.55745459e-01,\n",
       "           2.81907827e-01,  2.70181268e-01, -5.93321800e-01,\n",
       "          -3.60059142e-01, -3.31358224e-01, -1.91883221e-01,\n",
       "           7.21753836e-02]],\n",
       "\n",
       "        [[-1.08534545e-01, -1.14946298e-01,  5.40409565e-01,\n",
       "          -1.20552659e-01, -1.19296305e-01,  8.00217763e-02,\n",
       "           1.44659951e-01,  9.42057222e-02, -3.16875608e-04,\n",
       "           5.94060779e-01,  6.18815958e-01, -1.24099441e-01,\n",
       "           2.63765991e-01, -2.16241375e-01,  4.99250233e-01,\n",
       "           7.52648860e-02, -6.64678812e-02, -4.44709361e-01,\n",
       "          -1.45286450e-03, -2.00651154e-01, -6.19645178e-01,\n",
       "           1.61894560e-01,  1.44913316e-01, -2.88194150e-01,\n",
       "           5.00318229e-01,  2.24628150e-01, -1.28634006e-01,\n",
       "           1.54859409e-01,  2.05819771e-01,  4.30280328e-01,\n",
       "          -3.43580902e-01,  3.11966062e-01,  2.44616970e-01,\n",
       "          -2.19398022e-01, -2.09514186e-01,  2.13259067e-02,\n",
       "          -2.21446201e-01, -6.22307174e-02,  5.34032106e-01,\n",
       "           9.33957025e-02]],\n",
       "\n",
       "        [[-1.53631866e-02, -1.51622489e-01, -5.21308601e-01,\n",
       "           1.58782110e-01,  1.23898692e-01,  2.66832113e-01,\n",
       "           2.38448933e-01,  1.53611144e-02,  7.62960985e-02,\n",
       "          -1.54294088e-01, -2.24004835e-01, -1.91604093e-01,\n",
       "           1.61513180e-01, -6.76825047e-02, -4.27053750e-01,\n",
       "           2.24886313e-02, -1.57080412e-01, -1.05812520e-01,\n",
       "           5.20295560e-01, -2.41807342e-01,  1.11887030e-01,\n",
       "          -1.78432465e-01, -5.41074693e-01, -6.41105652e-01,\n",
       "          -3.77946831e-02, -2.16095358e-01,  2.39134848e-01,\n",
       "          -3.85062732e-02, -6.42576456e-01,  5.18247150e-02,\n",
       "           6.83461353e-02,  1.65876180e-01, -3.39313656e-01,\n",
       "          -4.02638525e-01, -1.50764406e-01, -6.96721720e-03,\n",
       "          -1.88783273e-01,  4.31790411e-01, -5.84093094e-01,\n",
       "           1.42843023e-01]],\n",
       "\n",
       "        [[ 5.38945317e-01,  5.36736906e-01, -2.39830986e-01,\n",
       "          -2.21167132e-01,  4.00710404e-01, -1.19011961e-01,\n",
       "           2.47976080e-01, -1.03201941e-01, -4.28913236e-01,\n",
       "           6.42471090e-02, -5.70685975e-02, -3.66642833e-01,\n",
       "           1.94664657e-01, -4.97180551e-01,  6.84295073e-02,\n",
       "          -4.70894426e-01, -3.83962095e-01, -5.98978221e-01,\n",
       "           4.96015102e-02, -2.17848644e-01, -5.34455299e-01,\n",
       "           8.79057869e-02,  1.07605003e-01,  2.13309437e-01,\n",
       "           3.11139643e-01,  1.92816094e-01, -1.57927871e-01,\n",
       "          -2.81392694e-01, -4.93515767e-02,  4.97127622e-01,\n",
       "          -3.23979616e-01,  2.67387718e-01,  2.52965063e-01,\n",
       "           1.63234130e-01,  3.33801448e-01,  2.82054842e-02,\n",
       "           3.92171264e-01,  4.14804876e-01,  1.14178583e-01,\n",
       "          -1.71653226e-01]],\n",
       "\n",
       "        [[ 1.95351511e-01, -2.30194360e-01,  7.19820783e-02,\n",
       "          -1.92850903e-01,  1.94057792e-01,  1.20829694e-01,\n",
       "           1.16616450e-01,  2.83374727e-01, -1.88201398e-01,\n",
       "          -9.43775401e-02, -3.05751324e-01,  2.67963447e-02,\n",
       "           1.26247600e-01, -5.06089449e-01, -2.13442311e-01,\n",
       "           4.06399578e-01,  2.51808494e-01, -1.51772797e-01,\n",
       "          -1.44205034e-01, -5.97906530e-01,  2.52550513e-01,\n",
       "          -2.87747979e-01,  1.12671353e-01,  4.80626583e-01,\n",
       "           5.14918983e-01, -1.71497628e-01,  2.73429245e-01,\n",
       "          -8.36567059e-02, -1.38299897e-01, -8.59844536e-02,\n",
       "          -1.79554597e-01,  1.66255787e-01, -1.76214442e-01,\n",
       "           3.13441098e-01,  5.05584441e-02,  3.27748107e-03,\n",
       "          -1.58920273e-01,  1.32285610e-01,  3.37582558e-01,\n",
       "          -5.49142003e-01]],\n",
       "\n",
       "        [[ 3.24392259e-01, -2.00969353e-01,  3.38943392e-01,\n",
       "           1.08952202e-01, -3.73139650e-01,  2.09252685e-01,\n",
       "           8.07914883e-02, -7.59962425e-02, -2.74418354e-01,\n",
       "           2.17585325e-01,  1.18111029e-01, -1.29104644e-01,\n",
       "          -1.42880663e-01, -1.29578471e-01, -6.35477960e-01,\n",
       "           7.14977905e-02, -3.42819005e-01,  2.75172889e-01,\n",
       "           1.88096866e-01, -6.15193844e-01,  2.43377671e-01,\n",
       "           6.10979870e-02, -3.64506960e-01,  1.53409794e-01,\n",
       "          -1.31099626e-01, -2.85015762e-01, -3.10153365e-01,\n",
       "           4.78947699e-01, -9.24682841e-02, -4.37919535e-02,\n",
       "           4.10213768e-01,  1.56095162e-01,  1.66813791e-01,\n",
       "          -5.61119080e-01,  5.58514476e-01,  5.63562334e-01,\n",
       "           3.97765011e-01,  4.62420493e-01,  2.74388254e-01,\n",
       "          -4.28684562e-01]]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases # Bias de la primera capa: 500 bias inicializados a 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train the model with M-BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 - 8s - loss: 0.8314 - accuracy: 0.5673 - val_loss: 0.7132 - val_accuracy: 0.6154\n",
      "Epoch 2/100\n",
      "4/4 - 0s - loss: 0.7633 - accuracy: 0.5577 - val_loss: 0.7253 - val_accuracy: 0.6154\n",
      "Epoch 3/100\n",
      "4/4 - 0s - loss: 0.8214 - accuracy: 0.5769 - val_loss: 0.7749 - val_accuracy: 0.3846\n",
      "Epoch 4/100\n",
      "4/4 - 0s - loss: 0.9302 - accuracy: 0.3750 - val_loss: 0.7280 - val_accuracy: 0.6154\n",
      "Epoch 5/100\n",
      "4/4 - 0s - loss: 0.8070 - accuracy: 0.6058 - val_loss: 0.7207 - val_accuracy: 0.6154\n",
      "Epoch 6/100\n",
      "4/4 - 0s - loss: 0.7362 - accuracy: 0.6250 - val_loss: 0.7225 - val_accuracy: 0.6154\n",
      "Epoch 7/100\n",
      "4/4 - 0s - loss: 0.6889 - accuracy: 0.6154 - val_loss: 0.7121 - val_accuracy: 0.6154\n",
      "Epoch 8/100\n",
      "4/4 - 1s - loss: 0.7483 - accuracy: 0.5096 - val_loss: 0.7149 - val_accuracy: 0.6154\n",
      "Epoch 9/100\n",
      "4/4 - 1s - loss: 0.7201 - accuracy: 0.6442 - val_loss: 0.7146 - val_accuracy: 0.6154\n",
      "Epoch 10/100\n",
      "4/4 - 0s - loss: 0.7770 - accuracy: 0.5577 - val_loss: 0.7153 - val_accuracy: 0.6154\n",
      "Epoch 11/100\n",
      "4/4 - 0s - loss: 0.7335 - accuracy: 0.5385 - val_loss: 0.7206 - val_accuracy: 0.6154\n",
      "Epoch 12/100\n",
      "4/4 - 0s - loss: 0.7197 - accuracy: 0.5577 - val_loss: 0.7129 - val_accuracy: 0.6154\n",
      "Epoch 13/100\n",
      "4/4 - 0s - loss: 0.7136 - accuracy: 0.6058 - val_loss: 0.7159 - val_accuracy: 0.6154\n",
      "Epoch 14/100\n",
      "4/4 - 0s - loss: 0.7091 - accuracy: 0.6154 - val_loss: 0.7174 - val_accuracy: 0.6154\n",
      "Epoch 15/100\n",
      "4/4 - 0s - loss: 0.7086 - accuracy: 0.6154 - val_loss: 0.7109 - val_accuracy: 0.6154\n",
      "Epoch 16/100\n",
      "4/4 - 1s - loss: 0.7105 - accuracy: 0.6154 - val_loss: 0.7113 - val_accuracy: 0.6154\n",
      "Epoch 17/100\n",
      "4/4 - 0s - loss: 0.7134 - accuracy: 0.6154 - val_loss: 0.7140 - val_accuracy: 0.6154\n",
      "Epoch 18/100\n",
      "4/4 - 0s - loss: 0.7051 - accuracy: 0.6154 - val_loss: 0.7112 - val_accuracy: 0.6154\n",
      "Epoch 19/100\n",
      "4/4 - 0s - loss: 0.7086 - accuracy: 0.6154 - val_loss: 0.7108 - val_accuracy: 0.6154\n",
      "Epoch 20/100\n",
      "4/4 - 0s - loss: 0.7138 - accuracy: 0.6154 - val_loss: 0.7104 - val_accuracy: 0.6154\n",
      "Epoch 21/100\n",
      "4/4 - 0s - loss: 0.7167 - accuracy: 0.6154 - val_loss: 0.7090 - val_accuracy: 0.6154\n",
      "Epoch 22/100\n",
      "4/4 - 0s - loss: 0.7118 - accuracy: 0.6154 - val_loss: 0.7090 - val_accuracy: 0.6154\n",
      "Epoch 23/100\n",
      "4/4 - 0s - loss: 0.7053 - accuracy: 0.6154 - val_loss: 0.7140 - val_accuracy: 0.6154\n",
      "Epoch 24/100\n",
      "4/4 - 0s - loss: 0.7087 - accuracy: 0.6154 - val_loss: 0.7116 - val_accuracy: 0.6154\n",
      "Epoch 25/100\n",
      "4/4 - 0s - loss: 0.7122 - accuracy: 0.6154 - val_loss: 0.7089 - val_accuracy: 0.6154\n",
      "Epoch 26/100\n",
      "4/4 - 0s - loss: 0.7070 - accuracy: 0.6154 - val_loss: 0.7093 - val_accuracy: 0.6154\n",
      "Epoch 27/100\n",
      "4/4 - 0s - loss: 0.7076 - accuracy: 0.6154 - val_loss: 0.7079 - val_accuracy: 0.6154\n",
      "Epoch 28/100\n",
      "4/4 - 0s - loss: 0.7087 - accuracy: 0.6154 - val_loss: 0.7081 - val_accuracy: 0.6154\n",
      "Epoch 29/100\n",
      "4/4 - 0s - loss: 0.7026 - accuracy: 0.6154 - val_loss: 0.7131 - val_accuracy: 0.6154\n",
      "Epoch 30/100\n",
      "4/4 - 0s - loss: 0.7104 - accuracy: 0.6154 - val_loss: 0.7103 - val_accuracy: 0.6154\n",
      "Epoch 31/100\n",
      "4/4 - 0s - loss: 0.7073 - accuracy: 0.6154 - val_loss: 0.7093 - val_accuracy: 0.6154\n",
      "Epoch 32/100\n",
      "4/4 - 1s - loss: 0.7131 - accuracy: 0.6154 - val_loss: 0.7081 - val_accuracy: 0.6154\n",
      "Epoch 33/100\n",
      "4/4 - 0s - loss: 0.7262 - accuracy: 0.6154 - val_loss: 0.7084 - val_accuracy: 0.6154\n",
      "Epoch 34/100\n",
      "4/4 - 0s - loss: 0.7120 - accuracy: 0.6154 - val_loss: 0.7078 - val_accuracy: 0.6154\n",
      "Epoch 35/100\n",
      "4/4 - 0s - loss: 0.6969 - accuracy: 0.6154 - val_loss: 0.7072 - val_accuracy: 0.6154\n",
      "Epoch 36/100\n",
      "4/4 - 0s - loss: 0.7015 - accuracy: 0.6154 - val_loss: 0.7101 - val_accuracy: 0.6154\n",
      "Epoch 37/100\n",
      "4/4 - 0s - loss: 0.6975 - accuracy: 0.6154 - val_loss: 0.7082 - val_accuracy: 0.6154\n",
      "Epoch 38/100\n",
      "4/4 - 0s - loss: 0.7016 - accuracy: 0.6250 - val_loss: 0.7227 - val_accuracy: 0.6154\n",
      "Epoch 39/100\n",
      "4/4 - 0s - loss: 0.6941 - accuracy: 0.6442 - val_loss: 0.7228 - val_accuracy: 0.6154\n",
      "Epoch 40/100\n",
      "4/4 - 0s - loss: 0.7124 - accuracy: 0.6250 - val_loss: 0.7134 - val_accuracy: 0.6154\n",
      "Epoch 41/100\n",
      "4/4 - 0s - loss: 0.6983 - accuracy: 0.6058 - val_loss: 0.7131 - val_accuracy: 0.6154\n",
      "Epoch 42/100\n",
      "4/4 - 0s - loss: 0.6949 - accuracy: 0.6154 - val_loss: 0.7097 - val_accuracy: 0.6154\n",
      "Epoch 43/100\n",
      "4/4 - 0s - loss: 0.7061 - accuracy: 0.6154 - val_loss: 0.7093 - val_accuracy: 0.6154\n",
      "Epoch 44/100\n",
      "4/4 - 0s - loss: 0.6894 - accuracy: 0.6154 - val_loss: 0.7084 - val_accuracy: 0.6154\n",
      "Epoch 45/100\n",
      "4/4 - 0s - loss: 0.6990 - accuracy: 0.6058 - val_loss: 0.7077 - val_accuracy: 0.6154\n",
      "Epoch 46/100\n",
      "4/4 - 0s - loss: 0.7039 - accuracy: 0.6058 - val_loss: 0.7080 - val_accuracy: 0.6154\n",
      "Epoch 47/100\n",
      "4/4 - 1s - loss: 0.6715 - accuracy: 0.6154 - val_loss: 0.7080 - val_accuracy: 0.6154\n",
      "Epoch 48/100\n",
      "4/4 - 0s - loss: 0.6910 - accuracy: 0.6154 - val_loss: 0.7157 - val_accuracy: 0.6154\n",
      "Epoch 49/100\n",
      "4/4 - 0s - loss: 0.6831 - accuracy: 0.6058 - val_loss: 0.7196 - val_accuracy: 0.6154\n",
      "Epoch 50/100\n",
      "4/4 - 0s - loss: 0.6877 - accuracy: 0.5962 - val_loss: 0.7098 - val_accuracy: 0.6154\n",
      "Epoch 51/100\n",
      "4/4 - 0s - loss: 0.6787 - accuracy: 0.6154 - val_loss: 0.7097 - val_accuracy: 0.6154\n",
      "Epoch 52/100\n",
      "4/4 - 0s - loss: 0.6842 - accuracy: 0.6154 - val_loss: 0.7125 - val_accuracy: 0.6154\n",
      "Epoch 53/100\n",
      "4/4 - 0s - loss: 0.6830 - accuracy: 0.6154 - val_loss: 0.7144 - val_accuracy: 0.6154\n",
      "Epoch 54/100\n",
      "4/4 - 0s - loss: 0.6802 - accuracy: 0.6346 - val_loss: 0.7125 - val_accuracy: 0.6154\n",
      "Epoch 55/100\n",
      "4/4 - 1s - loss: 0.6728 - accuracy: 0.6442 - val_loss: 0.7450 - val_accuracy: 0.3462\n",
      "Epoch 56/100\n",
      "4/4 - 0s - loss: 0.6625 - accuracy: 0.7212 - val_loss: 0.7383 - val_accuracy: 0.5385\n",
      "Epoch 57/100\n",
      "4/4 - 0s - loss: 0.6825 - accuracy: 0.6442 - val_loss: 0.7197 - val_accuracy: 0.6538\n",
      "Epoch 58/100\n",
      "4/4 - 0s - loss: 0.6131 - accuracy: 0.7115 - val_loss: 0.7148 - val_accuracy: 0.6154\n",
      "Epoch 59/100\n",
      "4/4 - 0s - loss: 0.6409 - accuracy: 0.6154 - val_loss: 0.7249 - val_accuracy: 0.6923\n",
      "Epoch 60/100\n",
      "4/4 - 0s - loss: 0.6410 - accuracy: 0.6731 - val_loss: 0.7352 - val_accuracy: 0.6538\n",
      "Epoch 61/100\n",
      "4/4 - 0s - loss: 0.6287 - accuracy: 0.7308 - val_loss: 0.7404 - val_accuracy: 0.6923\n",
      "Epoch 62/100\n",
      "4/4 - 0s - loss: 0.6084 - accuracy: 0.7019 - val_loss: 0.7440 - val_accuracy: 0.7308\n",
      "Epoch 63/100\n",
      "4/4 - 0s - loss: 0.5821 - accuracy: 0.7308 - val_loss: 0.7414 - val_accuracy: 0.7308\n",
      "Epoch 64/100\n",
      "4/4 - 0s - loss: 0.5348 - accuracy: 0.7788 - val_loss: 0.7667 - val_accuracy: 0.6538\n",
      "Epoch 65/100\n",
      "4/4 - 1s - loss: 0.5513 - accuracy: 0.7308 - val_loss: 0.7615 - val_accuracy: 0.6538\n",
      "Epoch 66/100\n",
      "4/4 - 0s - loss: 0.5231 - accuracy: 0.7788 - val_loss: 0.8331 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "4/4 - 1s - loss: 0.5225 - accuracy: 0.7404 - val_loss: 0.7901 - val_accuracy: 0.6923\n",
      "Epoch 68/100\n",
      "4/4 - 0s - loss: 0.5234 - accuracy: 0.7596 - val_loss: 0.7825 - val_accuracy: 0.4615\n",
      "Epoch 69/100\n",
      "4/4 - 0s - loss: 0.5789 - accuracy: 0.7981 - val_loss: 1.0928 - val_accuracy: 0.3077\n",
      "Epoch 70/100\n",
      "4/4 - 0s - loss: 0.5328 - accuracy: 0.7500 - val_loss: 0.8889 - val_accuracy: 0.6538\n",
      "Epoch 71/100\n",
      "4/4 - 0s - loss: 0.5231 - accuracy: 0.7692 - val_loss: 0.7819 - val_accuracy: 0.7308\n",
      "Epoch 72/100\n",
      "4/4 - 0s - loss: 0.4976 - accuracy: 0.7500 - val_loss: 0.9061 - val_accuracy: 0.6154\n",
      "Epoch 73/100\n",
      "4/4 - 0s - loss: 0.3784 - accuracy: 0.8654 - val_loss: 1.0529 - val_accuracy: 0.3462\n",
      "Epoch 74/100\n",
      "4/4 - 0s - loss: 0.4515 - accuracy: 0.8173 - val_loss: 0.9827 - val_accuracy: 0.4615\n",
      "Epoch 75/100\n",
      "4/4 - 0s - loss: 0.4077 - accuracy: 0.8462 - val_loss: 0.9550 - val_accuracy: 0.6538\n",
      "Epoch 76/100\n",
      "4/4 - 1s - loss: 0.4690 - accuracy: 0.7885 - val_loss: 0.9364 - val_accuracy: 0.6538\n",
      "Epoch 77/100\n",
      "4/4 - 0s - loss: 0.4361 - accuracy: 0.8269 - val_loss: 0.9396 - val_accuracy: 0.4615\n",
      "Epoch 78/100\n",
      "4/4 - 0s - loss: 0.4063 - accuracy: 0.8654 - val_loss: 0.9088 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "4/4 - 0s - loss: 0.3916 - accuracy: 0.8462 - val_loss: 0.9115 - val_accuracy: 0.6538\n",
      "Epoch 80/100\n",
      "4/4 - 0s - loss: 0.4093 - accuracy: 0.8269 - val_loss: 0.8189 - val_accuracy: 0.5769\n",
      "Epoch 81/100\n",
      "4/4 - 0s - loss: 0.4282 - accuracy: 0.8462 - val_loss: 1.0640 - val_accuracy: 0.7308\n",
      "Epoch 82/100\n",
      "4/4 - 0s - loss: 0.4300 - accuracy: 0.7981 - val_loss: 1.0783 - val_accuracy: 0.4231\n",
      "Epoch 83/100\n",
      "4/4 - 0s - loss: 0.3664 - accuracy: 0.8654 - val_loss: 1.1860 - val_accuracy: 0.4231\n",
      "Epoch 84/100\n",
      "4/4 - 0s - loss: 0.3543 - accuracy: 0.8654 - val_loss: 1.1526 - val_accuracy: 0.4231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "4/4 - 0s - loss: 0.3813 - accuracy: 0.8654 - val_loss: 1.1173 - val_accuracy: 0.5769\n",
      "Epoch 86/100\n",
      "4/4 - 0s - loss: 0.3531 - accuracy: 0.8750 - val_loss: 1.1718 - val_accuracy: 0.5769\n",
      "Epoch 87/100\n",
      "4/4 - 0s - loss: 0.3117 - accuracy: 0.8558 - val_loss: 1.2249 - val_accuracy: 0.6538\n",
      "Epoch 88/100\n",
      "4/4 - 0s - loss: 0.3284 - accuracy: 0.8654 - val_loss: 1.1952 - val_accuracy: 0.5385\n",
      "Epoch 89/100\n",
      "4/4 - 0s - loss: 0.3086 - accuracy: 0.8654 - val_loss: 1.0028 - val_accuracy: 0.5769\n",
      "Epoch 90/100\n",
      "4/4 - 0s - loss: 0.3964 - accuracy: 0.8654 - val_loss: 1.0470 - val_accuracy: 0.6538\n",
      "Epoch 91/100\n",
      "4/4 - 0s - loss: 0.3441 - accuracy: 0.8654 - val_loss: 1.0170 - val_accuracy: 0.5769\n",
      "Epoch 92/100\n",
      "4/4 - 0s - loss: 0.3834 - accuracy: 0.8462 - val_loss: 1.2916 - val_accuracy: 0.6538\n",
      "Epoch 93/100\n",
      "4/4 - 0s - loss: 0.3243 - accuracy: 0.8654 - val_loss: 1.3607 - val_accuracy: 0.6538\n",
      "Epoch 94/100\n",
      "4/4 - 0s - loss: 0.3372 - accuracy: 0.8462 - val_loss: 1.3591 - val_accuracy: 0.3462\n",
      "Epoch 95/100\n",
      "4/4 - 0s - loss: 0.4155 - accuracy: 0.8077 - val_loss: 1.1065 - val_accuracy: 0.4231\n",
      "Epoch 96/100\n",
      "4/4 - 0s - loss: 0.3243 - accuracy: 0.8365 - val_loss: 1.2990 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "4/4 - 0s - loss: 0.3254 - accuracy: 0.8750 - val_loss: 1.3113 - val_accuracy: 0.7308\n",
      "Epoch 98/100\n",
      "4/4 - 0s - loss: 0.4164 - accuracy: 0.8462 - val_loss: 1.2723 - val_accuracy: 0.6154\n",
      "Epoch 99/100\n",
      "4/4 - 1s - loss: 0.3500 - accuracy: 0.8462 - val_loss: 1.0480 - val_accuracy: 0.5769\n",
      "Epoch 100/100\n",
      "4/4 - 0s - loss: 0.3899 - accuracy: 0.8365 - val_loss: 1.2783 - val_accuracy: 0.3462\n",
      "45.78370952606201\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#history = model.fit(X_train, y_train, batch_size=32, steps_per_epoch=len(y_train)/32, epochs=100, verbose=2, validation_data=(X_dev, y_dev),callbacks=[tensorboard])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=2, validation_data=(X_dev, y_dev))\n",
    "print (time.time() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=pd.DataFrame(history.history)\n",
    "results.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel (\"Epochs\")\n",
    "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
    "plt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "# categorical_accuracy es el training accuracy\n",
    "# val_categorical_accuracy es el validation accuracy\n",
    "# loss es el training loss\n",
    "# val_loss es el validation loss\n",
    "\n",
    "# Overfitting:\n",
    "# Por un lado la Accuracy de los datos de entrenamiento aumenta con las epochs,\n",
    "# mientras que la Accuracy de los datos de validación disminuye o se mantiene constante a lo largo de las epochs. \n",
    "# La Loss de los datos de validación alcanza su mínimo después de pocos epochs y luego empieza a subir, \n",
    "# mientras que la Loss de los datos de entrenamiento disminuye linealmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 2, 'epochs': 100, 'steps': 4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.389858</td>\n",
       "      <td>0.836538</td>\n",
       "      <td>1.278267</td>\n",
       "      <td>0.346154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "99  0.389858  0.836538  1.278267      0.346154"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set:  0.8365384340286255\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the training set: \", results.values[-1:][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the development test set:  0.3461538553237915\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the development test set: \", results.values[-1:][0][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how the model predicts using the development test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.11],\n",
       "       [0.88, 0.12],\n",
       "       [0.81, 0.19],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.81, 0.19],\n",
       "       [0.86, 0.14],\n",
       "       [0.53, 0.47],\n",
       "       [0.15, 0.85],\n",
       "       [0.74, 0.26],\n",
       "       [0.54, 0.46],\n",
       "       [0.21, 0.79],\n",
       "       [0.93, 0.07],\n",
       "       [0.83, 0.17],\n",
       "       [0.07, 0.93],\n",
       "       [0.33, 0.67],\n",
       "       [0.12, 0.88],\n",
       "       [0.86, 0.14],\n",
       "       [0.92, 0.08],\n",
       "       [0.62, 0.38],\n",
       "       [0.12, 0.88]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions=model.predict(X_dev).round(2) \n",
    "dev_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_rounded_predictions=np.round(dev_predictions)\n",
    "indices = np.argmax(dev_predictions,1)\n",
    "for row, index in zip(dev_rounded_predictions, indices): row[index]=1\n",
    "dev_rounded_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False False False False  True False False  True  True\n",
      "  True False False False False False False  True  True False False False\n",
      " False False]\n"
     ]
    }
   ],
   "source": [
    "dev_correct_predictions = np.equal(np.argmax(dev_rounded_predictions,1),np.argmax(y_dev,1))\n",
    "print (dev_correct_predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 9, False: 17})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter (dev_correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model if it is better than others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "model.save('./Modelos/CNN_model4_ce.h5') # Change the name in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnew_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\\n\\nimport numpy as np\\n\\n# Verify state\\nnew_predictions = new_model.predict(X_dev)\\nnp.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\\n\\n# Note that the optimizer state is also preserved:\\n# you can resume training where you left off.\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract\n",
    "\"\"\"\n",
    "new_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Verify state\n",
    "new_predictions = new_model.predict(X_dev)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is also preserved:\n",
    "# you can resume training where you left off.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Final Test\n",
    "\n",
    "#### 10.1 - Load the final test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom collections import Counter\\ndef predictWithModel(model, X_test, y_test, task1, task2, task3=\"\"):\\n    model.evaluate(X_test, y_test)\\n    test_predictions = model.predict(X_test)\\n    test_rounded_predictions=np.round(test_predictions)\\n    indices = np.argmax(test_predictions,1)\\n    for row, index in zip(test_rounded_predictions, indices): row[index]=1\\n    print(test_rounded_predictions[:20])\\n    \\n    # ACCURACY:\\n    test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(y_test,1))\\n    print()\\n    print(test_correct_predictions)\\n    print(type(test_correct_predictions))\\n    final_test_prediction_results=Counter(test_correct_predictions)\\n    \\n    success = np.mean(test_rounded_predictions == y_test)*100\\n    \\n    return final_test_prediction_results, success\\n    '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from collections import Counter\n",
    "def predictWithModel(model, X_test, y_test, task1, task2, task3=\"\"):\n",
    "    model.evaluate(X_test, y_test)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_rounded_predictions=np.round(test_predictions)\n",
    "    indices = np.argmax(test_predictions,1)\n",
    "    for row, index in zip(test_rounded_predictions, indices): row[index]=1\n",
    "    print(test_rounded_predictions[:20])\n",
    "    \n",
    "    # ACCURACY:\n",
    "    test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(y_test,1))\n",
    "    print()\n",
    "    print(test_correct_predictions)\n",
    "    print(type(test_correct_predictions))\n",
    "    final_test_prediction_results=Counter(test_correct_predictions)\n",
    "    \n",
    "    success = np.mean(test_rounded_predictions == y_test)*100\n",
    "    \n",
    "    return final_test_prediction_results, success\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nusers = [\"0091\"]\\nfor u in users:   \\n    print(\"USER:\", u)\\n    #X_test, y_test = readRegisterAndReturnXy(u, total_records, 122, 123, 127)\\n    accuracy, success = predictWithModel(model, X_test, y_test, 402,404)\\n    print(u, accuracy, success)\\n    print()\\n    '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "users = [\"0091\"]\n",
    "for u in users:   \n",
    "    print(\"USER:\", u)\n",
    "    #X_test, y_test = readRegisterAndReturnXy(u, total_records, 122, 123, 127)\n",
    "    accuracy, success = predictWithModel(model, X_test, y_test, 402,404)\n",
    "    print(u, accuracy, success)\n",
    "    print()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
