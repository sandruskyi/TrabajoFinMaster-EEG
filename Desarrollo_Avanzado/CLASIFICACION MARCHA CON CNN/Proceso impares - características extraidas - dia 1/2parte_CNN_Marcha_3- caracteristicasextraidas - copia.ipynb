{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4: Clasificación con CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con la arquitectura anterior: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "    \n",
    "    TRAIN                   DEV\n",
    "    loss       accuracy     val_loss    val_accuracy\n",
    "    0.408548\t0.923077\t0.868668\t0.730769\n",
    "    \n",
    "Por tanto: \n",
    "\n",
    "    E = 1 - Accuracy\n",
    "    Etrain = 1 - 0.923077 = 0.076923\n",
    "    Etest = 1 - 0.730769 = 0.269231\n",
    "    \n",
    "    Bias = Etrain - Ehuman = 0.076923\n",
    "    Variance = Etest - Etrain = 0.269231 - 0.076923 = 0.192308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambios realizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa una tendencia a mejorar, se va a aumentar el número de epochs a 200, pero eso solo ha creado un gran overfitting, así que se vuelve ha poner a 100. \n",
    "\n",
    "Se va a probar con la funcion sigmoid y la inicialización Xavier. Se ha probado con activation=\"sigmoid\", kernel_initializer=\"glorot_normal\". Pero no ha habido mejora.\n",
    "\n",
    "Se va a probar con la función activation='relu', kernel_initializer=\"he_uniform\" (antes era \"he_normal\"). Tampoco se ha visto una mejora, asi que se vuelve a poner los mismos inicializadores. \n",
    "\n",
    "Se va a probar con el regularizador l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevos resultados: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Resultados:\n",
    "    \n",
    "    TRAIN                   DEV\n",
    "    loss       accuracy     val_loss    val_accuracy\n",
    "    0.596408\t0.711538\t0.649262\t0.615385\n",
    "    \n",
    "Por tanto: \n",
    "\n",
    "    E = 1 - Accuracy\n",
    "    Etrain = 1 - 0.711538 = 0.288462\n",
    "    Etest = 1 - 0.615385 = 0.384615\n",
    "    \n",
    "    Bias = Etrain - Ehuman = 0.288462\n",
    "    Variance = Etest - Etrain = 0.384615 - 0.288462 = 0.096153\n",
    "\n",
    "La varianza se ha reducido (de 46% a 9%) pero el bias ha aumentado a un 28%\n",
    "El bias se encuentra bajo (1%), pero la varianza es alta (46%), hay que tratar de reducirla.  Se tratará de mejorar el bias. Para mejorar esto será necesario añadir más complejidad, elegir una mejor optimización, cambiando la arquitectura (más neuronas, más capas)...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Signal libraries\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROutput:\n",
    "    def __init__(self, task, data):\n",
    "        self.task = task\n",
    "        self.data = data\n",
    "        \n",
    "class OutTaskData: \n",
    "    def __init__(self, task, data): \n",
    "        self.task = task\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "# Primero leemos los registros\n",
    "def read_outputs(rec):\n",
    "    '''read_outputs(\"userS0091f1.mat\")'''\n",
    "    mat = sio.loadmat(rec)\n",
    "    mdata = mat['session']\n",
    "    val = mdata[0,0]\n",
    "    #output = ROutput(np.array(val[\"task\"]), np.array(val[\"data\"]))\n",
    "    output = ROutput(np.array(val[\"task_EEG_p\"]), np.array(val[\"data_processed_EEG\"]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Perceptron\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "task1 = 402 # SE PUEDE CAMBIAR\n",
    "task2 = 404 # SE PUEDE CAMBIAR\n",
    "task_OneHotEnconding = {402: [1.,0.], 404: [0.,1.]}\n",
    "user = 'W29' # SE PUEDE CAMBIAR\n",
    "day = '0401'\n",
    "folder_day = 'W29-01_04_2021'\n",
    "total_records = 22 # CAMBIAR SI HAY MAS REGISTROS\n",
    "fm = 200\n",
    "electrodes_names_selected = ['F3', 'FZ', 'FC1','FCZ','C1','CZ','CP1','CPZ', 'FC5', 'FC3','C5','C3','CP5','CP3','P3',\n",
    "                             'PZ','F4','FC2','FC4','FC6','C2','C4','CP2','CP4','C6','CP6','P4','HR' ,'HL', 'VU', 'VD']\n",
    "number_channels = len(electrodes_names_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 22\n"
     ]
    }
   ],
   "source": [
    "lTaskData = []\n",
    "total_records_used = 0\n",
    "for i_rec in range(1,total_records+1):\n",
    "    i_rec_record = i_rec\n",
    "    if i_rec_record <10:\n",
    "        i_rec_record = \"0\"+str(i_rec_record)\n",
    "    if i_rec % 2 != 0: # Registros impares primero: USUARIO SIN MOVIMIENTO SOLO PENSANDO\n",
    "        record = \"./RegistrosProcesados2/\"+folder_day+\"/W29_2021\"+day+\"_openloop_\"+str(i_rec_record)+\"_processed.mat\"\n",
    "        output = read_outputs(record) # output.task será y, output.data será x\n",
    "\n",
    "\n",
    "        output.task = np.transpose(output.task)\n",
    "        output.data = output.data.reshape((np.shape(output.data)[0],np.shape(output.data)[1]))\n",
    "        output.data = np.transpose(output.data)\n",
    "        #output.data = output.data.reshape((np.shape(output.data)[0],np.shape(output.data)[1],1))\n",
    "\n",
    "        outT = (output.task == task1) | (output.task == task2)\n",
    "        outData = output.data[0:np.shape(output.data)[0], outT[0,:]]\n",
    "        outTask = output.task[0, outT[0,:]]\n",
    "        outTD = OutTaskData(outTask, outData)\n",
    "\n",
    "        lTaskData.append(outTD)\n",
    "        total_records_used+=1\n",
    "print(total_records_used, total_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8, 32, 49)\n",
      "y_train: (8, 49)\n",
      "X_dev: (2, 32, 49)\n",
      "y_dev: (2, 49)\n",
      "X_test: (1, 32, 49)\n",
      "y_test: (1, 49)\n",
      "ONE HOT ENCODER:\n",
      "X_train: (104, 32, 5, 1)\n",
      "y_train: (104, 2)\n",
      "X_dev: (26, 32, 5, 1)\n",
      "y_dev: (26, 2)\n",
      "X_test: (13, 32, 5, 1)\n",
      "y_test: (13, 2)\n"
     ]
    }
   ],
   "source": [
    "# Vamos a coger 2 registros para el entrenamiento, 1 para el conjunto dev set, 1 para el test set\n",
    "X_train, y_train, X_dev, y_dev, X_test, y_test = [],[],[],[],[],[] \n",
    "for j in range(0,total_records_used-3): # Cogemos 18 registros para entrenamiento\n",
    "    X_train.append(lTaskData[j].data)\n",
    "    y_train.append(lTaskData[j].task)\n",
    "\n",
    "for j in range(total_records_used-3,total_records_used-1): # Cogemos 2 registros para el dev set\n",
    "    X_dev.append(lTaskData[j].data)\n",
    "    y_dev.append(lTaskData[j].task)\n",
    "for j in range(total_records_used-1,total_records_used): # Cogemos 2 registros para el test set\n",
    "    X_test.append(lTaskData[j].data)\n",
    "    y_test.append(lTaskData[j].task)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "#y_train = np.ravel(np.array(y_train))\n",
    "y_train = np.array(y_train)\n",
    "X_dev = np.array(X_dev)\n",
    "#y_dev = np.ravel(np.array(y_dev))\n",
    "y_dev = np.array(y_dev)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "#y_test = np.ravel(np.array(y_test))\n",
    "\n",
    "print (\"X_train:\",X_train.shape)\n",
    "print (\"y_train:\",y_train.shape)\n",
    "print (\"X_dev:\",X_dev.shape)\n",
    "print (\"y_dev:\",y_dev.shape)\n",
    "print (\"X_test:\",X_test.shape)\n",
    "print (\"y_test:\",y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# VENTANEO Y ONE HOT ENCODING \n",
    "window = 5\n",
    "samples_advance = 3\n",
    "\n",
    "# Ventaneo X_train\n",
    "\n",
    "X_train_l = []\n",
    "y_train_l = []\n",
    "for num_X_train in range(np.shape(X_train)[0]): # Para no mezclar registros\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_train)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_train)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_train[num_X_train,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_train[num_X_train, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_train_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_train_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_train_l = np.array(X_train_l)\n",
    "y_train_l = np.array(y_train_l)\n",
    "\n",
    "\n",
    "# Ventaneo X_dev\n",
    "X_dev_l = []\n",
    "y_dev_l = []\n",
    "for num_X_dev in range(np.shape(X_dev)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_dev)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_dev)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_dev[num_X_dev,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_dev[num_X_dev, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_dev_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_dev_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_dev_l = np.array(X_dev_l)\n",
    "y_dev_l = np.array(y_dev_l)\n",
    "\n",
    "# Ventaneo X_test\n",
    "X_test_l = []\n",
    "y_test_l = []\n",
    "for num_X_test in range(np.shape(X_test)[0]): \n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_test)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_test)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_test[num_X_test,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_test[num_X_test, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_test_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_test_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_test_l = np.array(X_test_l)\n",
    "y_test_l = np.array(y_test_l)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_l = X_train_l.reshape((np.shape(X_train_l)[0],np.shape(X_train_l)[1],np.shape(X_train_l)[2], 1))\n",
    "X_dev_l = X_dev_l.reshape((np.shape(X_dev_l)[0],np.shape(X_dev_l)[1],np.shape(X_dev_l)[2], 1))\n",
    "X_test_l = X_test_l.reshape((np.shape(X_test_l)[0],np.shape(X_test_l)[1],np.shape(X_test_l)[2], 1))\n",
    "\n",
    "\n",
    "print(\"ONE HOT ENCODER:\")\n",
    "print (\"X_train:\",X_train_l.shape)\n",
    "print (\"y_train:\",y_train_l.shape)\n",
    "print (\"X_dev:\",X_dev_l.shape)\n",
    "print (\"y_dev:\",y_dev_l.shape)\n",
    "print (\"X_test:\",X_test_l.shape)\n",
    "print (\"y_test:\",y_test_l.shape)\n",
    "\n",
    "X_train = X_train_l\n",
    "y_train = y_train_l\n",
    "X_dev = X_dev_l\n",
    "y_dev = y_dev_l\n",
    "X_test = X_test_l\n",
    "y_test = y_test_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = X_train.shape[1]\n",
    "OUTPUTS = y_train.shape[1]\n",
    "NUM_TRAINING_EXAMPLES = int(round(X_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int(round(y_train.shape[0]/1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data is displayed to test correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1.10091475],\n",
       "         [-1.18560955],\n",
       "         [-1.22540958],\n",
       "         [-1.30127027],\n",
       "         [-1.14601052]],\n",
       "\n",
       "        [[-0.73933969],\n",
       "         [-0.6522277 ],\n",
       "         [-0.60960244],\n",
       "         [-0.62635203],\n",
       "         [-0.75554883]],\n",
       "\n",
       "        [[-0.65035738],\n",
       "         [-0.78916911],\n",
       "         [-0.74388342],\n",
       "         [-0.8335337 ],\n",
       "         [-0.71300404]],\n",
       "\n",
       "        [[-0.87346323],\n",
       "         [-0.91497745],\n",
       "         [-1.01676848],\n",
       "         [-1.16910068],\n",
       "         [-1.1302377 ]],\n",
       "\n",
       "        [[-0.96936541],\n",
       "         [-0.83515715],\n",
       "         [-0.91614968],\n",
       "         [-0.867686  ],\n",
       "         [-0.9775851 ]],\n",
       "\n",
       "        [[-1.08371702],\n",
       "         [-1.04183855],\n",
       "         [-1.04259551],\n",
       "         [-0.91319117],\n",
       "         [-0.85486867]],\n",
       "\n",
       "        [[-1.08475912],\n",
       "         [-0.9985104 ],\n",
       "         [-0.92636541],\n",
       "         [-0.90100283],\n",
       "         [-0.92114033]],\n",
       "\n",
       "        [[-0.96285848],\n",
       "         [-1.04281849],\n",
       "         [-1.05650712],\n",
       "         [-0.93621123],\n",
       "         [-0.91950371]],\n",
       "\n",
       "        [[-1.11986017],\n",
       "         [-1.13755911],\n",
       "         [-1.10725991],\n",
       "         [-1.23916743],\n",
       "         [-1.10527364]],\n",
       "\n",
       "        [[-1.19593847],\n",
       "         [-1.10944223],\n",
       "         [-1.11470031],\n",
       "         [-1.1161685 ],\n",
       "         [-1.07972332]],\n",
       "\n",
       "        [[-1.15576314],\n",
       "         [-1.17940457],\n",
       "         [-1.13249148],\n",
       "         [-1.08961971],\n",
       "         [-1.02243438]],\n",
       "\n",
       "        [[-0.67371055],\n",
       "         [-0.55738688],\n",
       "         [-0.5055594 ],\n",
       "         [-0.51167953],\n",
       "         [-0.7238865 ]],\n",
       "\n",
       "        [[-0.87216162],\n",
       "         [-0.80653999],\n",
       "         [-0.85271813],\n",
       "         [-0.86422332],\n",
       "         [-0.75432136]],\n",
       "\n",
       "        [[-0.83084721],\n",
       "         [-1.00929969],\n",
       "         [-0.96519016],\n",
       "         [-0.97046271],\n",
       "         [-0.9335852 ]],\n",
       "\n",
       "        [[-0.85781069],\n",
       "         [-0.93625877],\n",
       "         [-1.01390328],\n",
       "         [-0.94499817],\n",
       "         [-0.85290566]],\n",
       "\n",
       "        [[-0.80132806],\n",
       "         [-0.86528783],\n",
       "         [-0.94456309],\n",
       "         [-0.92305878],\n",
       "         [-0.91513922]],\n",
       "\n",
       "        [[-0.69026097],\n",
       "         [-0.76478067],\n",
       "         [-0.78086435],\n",
       "         [-0.87597447],\n",
       "         [-0.79194332]],\n",
       "\n",
       "        [[-1.01166919],\n",
       "         [-0.9863516 ],\n",
       "         [-1.14491136],\n",
       "         [-1.1210355 ],\n",
       "         [-1.03845465]],\n",
       "\n",
       "        [[-1.43728241],\n",
       "         [-1.11944436],\n",
       "         [-1.16021034],\n",
       "         [-1.03388904],\n",
       "         [-1.24732427]],\n",
       "\n",
       "        [[-0.79012112],\n",
       "         [-0.80274877],\n",
       "         [-0.76560969],\n",
       "         [-0.69933888],\n",
       "         [-0.63491454]],\n",
       "\n",
       "        [[-0.89005627],\n",
       "         [-1.00420612],\n",
       "         [-0.97938257],\n",
       "         [-0.95741949],\n",
       "         [-0.95285456]],\n",
       "\n",
       "        [[-1.05628657],\n",
       "         [-0.95559817],\n",
       "         [-0.82211222],\n",
       "         [-0.81654804],\n",
       "         [-0.86459248]],\n",
       "\n",
       "        [[-0.89811214],\n",
       "         [-0.97799064],\n",
       "         [-0.94208457],\n",
       "         [-1.01784109],\n",
       "         [-0.94228649]],\n",
       "\n",
       "        [[-0.80455702],\n",
       "         [-0.75328942],\n",
       "         [-0.81731808],\n",
       "         [-0.85354457],\n",
       "         [-1.01599284]],\n",
       "\n",
       "        [[-0.79864351],\n",
       "         [-0.98207379],\n",
       "         [-1.07800206],\n",
       "         [-0.87563628],\n",
       "         [-0.8697048 ]],\n",
       "\n",
       "        [[-0.92575908],\n",
       "         [-0.84292542],\n",
       "         [-0.72741675],\n",
       "         [-0.6875535 ],\n",
       "         [-0.73375828]],\n",
       "\n",
       "        [[-0.76652337],\n",
       "         [-0.73444433],\n",
       "         [-0.725692  ],\n",
       "         [-0.85024511],\n",
       "         [-0.88140641]],\n",
       "\n",
       "        [[-0.75696097],\n",
       "         [-0.70981838],\n",
       "         [-0.81786427],\n",
       "         [-0.84539216],\n",
       "         [-0.85608652]],\n",
       "\n",
       "        [[-1.26119661],\n",
       "         [-1.23673734],\n",
       "         [-1.36479313],\n",
       "         [-1.29642572],\n",
       "         [-1.06455931]],\n",
       "\n",
       "        [[-0.98314232],\n",
       "         [-0.96446208],\n",
       "         [-0.78567208],\n",
       "         [-0.93559047],\n",
       "         [-0.86715842]],\n",
       "\n",
       "        [[-1.07013712],\n",
       "         [-0.99441305],\n",
       "         [-1.06293222],\n",
       "         [-1.0700215 ],\n",
       "         [-1.00480823]],\n",
       "\n",
       "        [[-0.87832613],\n",
       "         [-0.97867105],\n",
       "         [-1.02015518],\n",
       "         [-0.89979547],\n",
       "         [-1.05132901]]],\n",
       "\n",
       "\n",
       "       [[[-1.30127027],\n",
       "         [-1.14601052],\n",
       "         [-1.0826931 ],\n",
       "         [-1.07282014],\n",
       "         [-1.29356845]],\n",
       "\n",
       "        [[-0.62635203],\n",
       "         [-0.75554883],\n",
       "         [-0.72569138],\n",
       "         [-0.8704877 ],\n",
       "         [-0.87795692]],\n",
       "\n",
       "        [[-0.8335337 ],\n",
       "         [-0.71300404],\n",
       "         [-0.77986452],\n",
       "         [-0.77552735],\n",
       "         [-0.67418434]],\n",
       "\n",
       "        [[-1.16910068],\n",
       "         [-1.1302377 ],\n",
       "         [-1.11151525],\n",
       "         [-1.10913778],\n",
       "         [-0.97327019]],\n",
       "\n",
       "        [[-0.867686  ],\n",
       "         [-0.9775851 ],\n",
       "         [-1.01680516],\n",
       "         [-1.12514172],\n",
       "         [-0.9374036 ]],\n",
       "\n",
       "        [[-0.91319117],\n",
       "         [-0.85486867],\n",
       "         [-0.79689263],\n",
       "         [-0.73315104],\n",
       "         [-0.87198972]],\n",
       "\n",
       "        [[-0.90100283],\n",
       "         [-0.92114033],\n",
       "         [-1.02185477],\n",
       "         [-0.84871805],\n",
       "         [-0.86486941]],\n",
       "\n",
       "        [[-0.93621123],\n",
       "         [-0.91950371],\n",
       "         [-0.86971872],\n",
       "         [-0.87374605],\n",
       "         [-0.94958525]],\n",
       "\n",
       "        [[-1.23916743],\n",
       "         [-1.10527364],\n",
       "         [-1.14524653],\n",
       "         [-1.149992  ],\n",
       "         [-1.28315254]],\n",
       "\n",
       "        [[-1.1161685 ],\n",
       "         [-1.07972332],\n",
       "         [-1.1348109 ],\n",
       "         [-1.05598282],\n",
       "         [-1.35181873]],\n",
       "\n",
       "        [[-1.08961971],\n",
       "         [-1.02243438],\n",
       "         [-1.11534765],\n",
       "         [-1.09073733],\n",
       "         [-1.07438782]],\n",
       "\n",
       "        [[-0.51167953],\n",
       "         [-0.7238865 ],\n",
       "         [-0.77757535],\n",
       "         [-0.87881164],\n",
       "         [-0.91596249]],\n",
       "\n",
       "        [[-0.86422332],\n",
       "         [-0.75432136],\n",
       "         [-0.82502551],\n",
       "         [-0.76243959],\n",
       "         [-0.81869767]],\n",
       "\n",
       "        [[-0.97046271],\n",
       "         [-0.9335852 ],\n",
       "         [-0.76587553],\n",
       "         [-0.76862296],\n",
       "         [-0.82908209]],\n",
       "\n",
       "        [[-0.94499817],\n",
       "         [-0.85290566],\n",
       "         [-0.85389605],\n",
       "         [-0.86573315],\n",
       "         [-0.72030671]],\n",
       "\n",
       "        [[-0.92305878],\n",
       "         [-0.91513922],\n",
       "         [-0.82247075],\n",
       "         [-0.82807512],\n",
       "         [-0.68326757]],\n",
       "\n",
       "        [[-0.87597447],\n",
       "         [-0.79194332],\n",
       "         [-0.90853638],\n",
       "         [-0.60041789],\n",
       "         [-0.55282205]],\n",
       "\n",
       "        [[-1.1210355 ],\n",
       "         [-1.03845465],\n",
       "         [-1.06361556],\n",
       "         [-1.17259745],\n",
       "         [-1.28374372]],\n",
       "\n",
       "        [[-1.03388904],\n",
       "         [-1.24732427],\n",
       "         [-1.10487579],\n",
       "         [-1.28140199],\n",
       "         [-1.28020926]],\n",
       "\n",
       "        [[-0.69933888],\n",
       "         [-0.63491454],\n",
       "         [-0.75764787],\n",
       "         [-0.90301076],\n",
       "         [-0.8920131 ]],\n",
       "\n",
       "        [[-0.95741949],\n",
       "         [-0.95285456],\n",
       "         [-0.8402441 ],\n",
       "         [-0.77761998],\n",
       "         [-0.78766634]],\n",
       "\n",
       "        [[-0.81654804],\n",
       "         [-0.86459248],\n",
       "         [-0.7830593 ],\n",
       "         [-0.84197823],\n",
       "         [-1.03075584]],\n",
       "\n",
       "        [[-1.01784109],\n",
       "         [-0.94228649],\n",
       "         [-0.9637223 ],\n",
       "         [-1.12033937],\n",
       "         [-0.98544514]],\n",
       "\n",
       "        [[-0.85354457],\n",
       "         [-1.01599284],\n",
       "         [-0.92465332],\n",
       "         [-0.92827578],\n",
       "         [-0.89399259]],\n",
       "\n",
       "        [[-0.87563628],\n",
       "         [-0.8697048 ],\n",
       "         [-0.77697152],\n",
       "         [-0.82709404],\n",
       "         [-0.86974732]],\n",
       "\n",
       "        [[-0.6875535 ],\n",
       "         [-0.73375828],\n",
       "         [-0.66615977],\n",
       "         [-0.66272497],\n",
       "         [-0.75899196]],\n",
       "\n",
       "        [[-0.85024511],\n",
       "         [-0.88140641],\n",
       "         [-0.83030454],\n",
       "         [-0.84346497],\n",
       "         [-0.87135678]],\n",
       "\n",
       "        [[-0.84539216],\n",
       "         [-0.85608652],\n",
       "         [-0.95341249],\n",
       "         [-0.95432555],\n",
       "         [-0.89340753]],\n",
       "\n",
       "        [[-1.29642572],\n",
       "         [-1.06455931],\n",
       "         [-1.08681023],\n",
       "         [-0.91658729],\n",
       "         [-0.8693267 ]],\n",
       "\n",
       "        [[-0.93559047],\n",
       "         [-0.86715842],\n",
       "         [-1.09960327],\n",
       "         [-1.20589291],\n",
       "         [-1.20695556]],\n",
       "\n",
       "        [[-1.0700215 ],\n",
       "         [-1.00480823],\n",
       "         [-1.0606739 ],\n",
       "         [-1.01504186],\n",
       "         [-1.02191622]],\n",
       "\n",
       "        [[-0.89979547],\n",
       "         [-1.05132901],\n",
       "         [-0.95977319],\n",
       "         [-1.00354475],\n",
       "         [-0.86559982]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1.7609531 ],\n",
       "         [-1.70947652],\n",
       "         [-1.45426169],\n",
       "         [-1.30297408],\n",
       "         [-1.05137947]],\n",
       "\n",
       "        [[-1.53095232],\n",
       "         [-1.3035732 ],\n",
       "         [-0.95293351],\n",
       "         [-1.30393792],\n",
       "         [-1.19464448]],\n",
       "\n",
       "        [[-0.49054619],\n",
       "         [-0.3859702 ],\n",
       "         [-0.45525626],\n",
       "         [-0.42108582],\n",
       "         [-0.55282466]],\n",
       "\n",
       "        [[-0.87348834],\n",
       "         [-0.92687503],\n",
       "         [-0.82310628],\n",
       "         [-0.94430777],\n",
       "         [-1.19249275]],\n",
       "\n",
       "        [[-1.44225092],\n",
       "         [-1.39678332],\n",
       "         [-1.26183112],\n",
       "         [-1.04571504],\n",
       "         [-0.82918066]],\n",
       "\n",
       "        [[-0.72677448],\n",
       "         [-0.90734664],\n",
       "         [-1.08261998],\n",
       "         [-1.20004651],\n",
       "         [-1.09914864]],\n",
       "\n",
       "        [[-1.39393049],\n",
       "         [-1.44384667],\n",
       "         [-1.30435787],\n",
       "         [-1.23660723],\n",
       "         [-0.97944169]],\n",
       "\n",
       "        [[-0.63428626],\n",
       "         [-0.69598645],\n",
       "         [-0.78099493],\n",
       "         [-0.70654519],\n",
       "         [-0.76841452]],\n",
       "\n",
       "        [[-1.21923233],\n",
       "         [-1.41287307],\n",
       "         [-1.43154543],\n",
       "         [-1.12788723],\n",
       "         [-1.02287944]],\n",
       "\n",
       "        [[-1.50088037],\n",
       "         [-1.40875456],\n",
       "         [-1.50151153],\n",
       "         [-1.2926847 ],\n",
       "         [-1.08473019]],\n",
       "\n",
       "        [[-0.90852469],\n",
       "         [-0.97004856],\n",
       "         [-1.11190528],\n",
       "         [-1.10971714],\n",
       "         [-1.2470141 ]],\n",
       "\n",
       "        [[-0.52636852],\n",
       "         [-0.46495362],\n",
       "         [-0.40846008],\n",
       "         [-0.55626671],\n",
       "         [-0.90450869]],\n",
       "\n",
       "        [[-1.16580738],\n",
       "         [-1.41625806],\n",
       "         [-1.36127875],\n",
       "         [-1.04400882],\n",
       "         [-0.76393127]],\n",
       "\n",
       "        [[-0.68899364],\n",
       "         [-0.9054443 ],\n",
       "         [-0.92701545],\n",
       "         [-0.86859734],\n",
       "         [-0.79772185]],\n",
       "\n",
       "        [[-0.82752073],\n",
       "         [-0.61419355],\n",
       "         [-0.6864462 ],\n",
       "         [-0.81128404],\n",
       "         [-0.72355851]],\n",
       "\n",
       "        [[-1.18465514],\n",
       "         [-1.17647846],\n",
       "         [-1.01737157],\n",
       "         [-0.85716885],\n",
       "         [-0.91680605]],\n",
       "\n",
       "        [[-0.96911518],\n",
       "         [-1.19898667],\n",
       "         [-1.15466677],\n",
       "         [-0.88673111],\n",
       "         [-0.98329667]],\n",
       "\n",
       "        [[-0.96595128],\n",
       "         [-0.56966912],\n",
       "         [-0.5663827 ],\n",
       "         [-0.67654589],\n",
       "         [-0.75581582]],\n",
       "\n",
       "        [[-0.98442826],\n",
       "         [-0.92248688],\n",
       "         [-0.87440865],\n",
       "         [-1.31168941],\n",
       "         [-1.30028873]],\n",
       "\n",
       "        [[-1.15500851],\n",
       "         [-1.26629295],\n",
       "         [-1.117054  ],\n",
       "         [-1.25895605],\n",
       "         [-1.19717312]],\n",
       "\n",
       "        [[-0.463178  ],\n",
       "         [-0.6790194 ],\n",
       "         [-0.87637654],\n",
       "         [-0.67636099],\n",
       "         [-0.86869918]],\n",
       "\n",
       "        [[-0.912633  ],\n",
       "         [-1.03185586],\n",
       "         [-0.85462331],\n",
       "         [-0.84053901],\n",
       "         [-0.63400747]],\n",
       "\n",
       "        [[-1.19840428],\n",
       "         [-1.03111324],\n",
       "         [-1.30622103],\n",
       "         [-1.11994855],\n",
       "         [-1.072183  ]],\n",
       "\n",
       "        [[-1.09140494],\n",
       "         [-1.00753988],\n",
       "         [-0.89771919],\n",
       "         [-0.90374829],\n",
       "         [-0.81032531]],\n",
       "\n",
       "        [[-0.51175287],\n",
       "         [-0.59046067],\n",
       "         [-0.49183915],\n",
       "         [-0.64445668],\n",
       "         [-0.80897428]],\n",
       "\n",
       "        [[-1.49318311],\n",
       "         [-1.42258799],\n",
       "         [-1.31620415],\n",
       "         [-1.25415841],\n",
       "         [-1.20751826]],\n",
       "\n",
       "        [[-0.755176  ],\n",
       "         [-0.59401213],\n",
       "         [-0.87718734],\n",
       "         [-0.84760157],\n",
       "         [-0.8066049 ]],\n",
       "\n",
       "        [[-1.01991083],\n",
       "         [-1.16746064],\n",
       "         [-0.9304    ],\n",
       "         [-0.83913567],\n",
       "         [-0.73712137]],\n",
       "\n",
       "        [[-1.13200723],\n",
       "         [-1.12157327],\n",
       "         [-1.03990657],\n",
       "         [-0.93934209],\n",
       "         [-0.96933448]],\n",
       "\n",
       "        [[-1.38408796],\n",
       "         [-1.18630348],\n",
       "         [-1.12702597],\n",
       "         [-0.98718622],\n",
       "         [-1.02160662]],\n",
       "\n",
       "        [[-0.89365758],\n",
       "         [-0.93278236],\n",
       "         [-1.07665684],\n",
       "         [-1.05206985],\n",
       "         [-0.81991994]],\n",
       "\n",
       "        [[-0.83558163],\n",
       "         [-0.9019832 ],\n",
       "         [-0.88690409],\n",
       "         [-0.90657589],\n",
       "         [-1.04761977]]],\n",
       "\n",
       "\n",
       "       [[[-1.30297408],\n",
       "         [-1.05137947],\n",
       "         [-1.03958248],\n",
       "         [-1.32905766],\n",
       "         [-1.13837166]],\n",
       "\n",
       "        [[-1.30393792],\n",
       "         [-1.19464448],\n",
       "         [-1.3048773 ],\n",
       "         [-1.14709931],\n",
       "         [-1.02415777]],\n",
       "\n",
       "        [[-0.42108582],\n",
       "         [-0.55282466],\n",
       "         [-0.87870995],\n",
       "         [-0.83694795],\n",
       "         [-0.87734876]],\n",
       "\n",
       "        [[-0.94430777],\n",
       "         [-1.19249275],\n",
       "         [-0.77864236],\n",
       "         [-0.51928877],\n",
       "         [-0.64406663]],\n",
       "\n",
       "        [[-1.04571504],\n",
       "         [-0.82918066],\n",
       "         [-1.22465469],\n",
       "         [-1.1767269 ],\n",
       "         [-1.21122556]],\n",
       "\n",
       "        [[-1.20004651],\n",
       "         [-1.09914864],\n",
       "         [-0.84005316],\n",
       "         [-0.8139863 ],\n",
       "         [-0.70338839]],\n",
       "\n",
       "        [[-1.23660723],\n",
       "         [-0.97944169],\n",
       "         [-0.8380694 ],\n",
       "         [-0.91107691],\n",
       "         [-1.05175668]],\n",
       "\n",
       "        [[-0.70654519],\n",
       "         [-0.76841452],\n",
       "         [-0.67545376],\n",
       "         [-1.04074631],\n",
       "         [-0.90349413]],\n",
       "\n",
       "        [[-1.12788723],\n",
       "         [-1.02287944],\n",
       "         [-1.092663  ],\n",
       "         [-1.25486502],\n",
       "         [-1.17891113]],\n",
       "\n",
       "        [[-1.2926847 ],\n",
       "         [-1.08473019],\n",
       "         [-0.99863625],\n",
       "         [-0.95248724],\n",
       "         [-1.09419931]],\n",
       "\n",
       "        [[-1.10971714],\n",
       "         [-1.2470141 ],\n",
       "         [-1.2213605 ],\n",
       "         [-1.32285129],\n",
       "         [-1.24269283]],\n",
       "\n",
       "        [[-0.55626671],\n",
       "         [-0.90450869],\n",
       "         [-0.92372337],\n",
       "         [-1.03072795],\n",
       "         [-0.80404142]],\n",
       "\n",
       "        [[-1.04400882],\n",
       "         [-0.76393127],\n",
       "         [-0.90302372],\n",
       "         [-0.80001004],\n",
       "         [-0.78976188]],\n",
       "\n",
       "        [[-0.86859734],\n",
       "         [-0.79772185],\n",
       "         [-0.89775509],\n",
       "         [-0.88489912],\n",
       "         [-0.8692502 ]],\n",
       "\n",
       "        [[-0.81128404],\n",
       "         [-0.72355851],\n",
       "         [-0.69161284],\n",
       "         [-0.7462586 ],\n",
       "         [-0.91258672]],\n",
       "\n",
       "        [[-0.85716885],\n",
       "         [-0.91680605],\n",
       "         [-0.733649  ],\n",
       "         [-0.64992044],\n",
       "         [-0.65884519]],\n",
       "\n",
       "        [[-0.88673111],\n",
       "         [-0.98329667],\n",
       "         [-1.12191242],\n",
       "         [-1.34670356],\n",
       "         [-1.27929835]],\n",
       "\n",
       "        [[-0.67654589],\n",
       "         [-0.75581582],\n",
       "         [-0.61656918],\n",
       "         [-0.45210341],\n",
       "         [-0.53911991]],\n",
       "\n",
       "        [[-1.31168941],\n",
       "         [-1.30028873],\n",
       "         [-1.14778234],\n",
       "         [-1.01043775],\n",
       "         [-0.93191376]],\n",
       "\n",
       "        [[-1.25895605],\n",
       "         [-1.19717312],\n",
       "         [-1.16529707],\n",
       "         [-1.36505914],\n",
       "         [-1.2337955 ]],\n",
       "\n",
       "        [[-0.67636099],\n",
       "         [-0.86869918],\n",
       "         [-0.8736377 ],\n",
       "         [-0.9809631 ],\n",
       "         [-0.86579363]],\n",
       "\n",
       "        [[-0.84053901],\n",
       "         [-0.63400747],\n",
       "         [-0.74713844],\n",
       "         [-0.79318301],\n",
       "         [-0.87217144]],\n",
       "\n",
       "        [[-1.11994855],\n",
       "         [-1.072183  ],\n",
       "         [-0.96969498],\n",
       "         [-0.88685652],\n",
       "         [-0.88771047]],\n",
       "\n",
       "        [[-0.90374829],\n",
       "         [-0.81032531],\n",
       "         [-0.9094369 ],\n",
       "         [-1.18122979],\n",
       "         [-1.08007256]],\n",
       "\n",
       "        [[-0.64445668],\n",
       "         [-0.80897428],\n",
       "         [-0.86112492],\n",
       "         [-0.78712782],\n",
       "         [-0.70002908]],\n",
       "\n",
       "        [[-1.25415841],\n",
       "         [-1.20751826],\n",
       "         [-1.08008613],\n",
       "         [-1.0449586 ],\n",
       "         [-1.11208614]],\n",
       "\n",
       "        [[-0.84760157],\n",
       "         [-0.8066049 ],\n",
       "         [-0.87398244],\n",
       "         [-0.86288049],\n",
       "         [-0.89161455]],\n",
       "\n",
       "        [[-0.83913567],\n",
       "         [-0.73712137],\n",
       "         [-0.82825395],\n",
       "         [-0.93986052],\n",
       "         [-0.78534585]],\n",
       "\n",
       "        [[-0.93934209],\n",
       "         [-0.96933448],\n",
       "         [-0.84044497],\n",
       "         [-0.73943757],\n",
       "         [-0.77420072]],\n",
       "\n",
       "        [[-0.98718622],\n",
       "         [-1.02160662],\n",
       "         [-0.96804594],\n",
       "         [-1.04476719],\n",
       "         [-1.14267752]],\n",
       "\n",
       "        [[-1.05206985],\n",
       "         [-0.81991994],\n",
       "         [-0.84484277],\n",
       "         [-0.84217903],\n",
       "         [-0.92736944]],\n",
       "\n",
       "        [[-0.90657589],\n",
       "         [-1.04761977],\n",
       "         [-0.99133642],\n",
       "         [-1.10586628],\n",
       "         [-1.13925761]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 5, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 32, 5, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 32, 5, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_epochs = 100 #2000\\n#learning_rate = 0.001\\nbatch_size = 32 #250 \\nn_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\\nrate_dropout = [0.8, 0.4, 0.2, 0.1]\\nweight_decay = 1e-4\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "n_epochs = 100 #2000\n",
    "#learning_rate = 0.001\n",
    "batch_size = 32 #250 \n",
    "n_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\n",
    "rate_dropout = [0.8, 0.4, 0.2, 0.1]\n",
    "weight_decay = 1e-4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Build the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 5, 4)          104       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 5, 4)          516       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 2, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 2, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 2, 20)         740       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 1, 20)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 1, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 322       \n",
      "=================================================================\n",
      "Total params: 1,682\n",
      "Trainable params: 1,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, DepthwiseConv2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import optimizers, regularizers\n",
    "import keras.backend as K\n",
    "#K.set_image_data_format('channels_first')\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "# Convolution2D(filtrosConv1, tamaño_filtro1, padding=\"same\", input_shape=(longitud, altura,3), activation = \"relu\")\n",
    "    # - filtrosConv1 número de filtros que aplicaremos tras la primera convolución, normalmente este tamaño va a aumentando\n",
    "    # tras convoluciones para que aumente la dimensión de profundidad (qué cosas hay en mi imagen)\n",
    "    # - tamaño_filtro1 tamaño espacial del kernel (de los filtros)\n",
    "    # - padding = si es same es que es igual que la imagen, vamos crea una imagen del mismo tamaño con el filtro, si es \n",
    "    # valid es que no hay padding y crea una imagen más pequeña que la imagen (creo)\n",
    "    # - input_shape = longitud y altura, tamaño que usará para convolucionar al entrenar\n",
    "    \n",
    "# CAPA PARA FILTRADO TEMPORAL \n",
    "model.add(Conv2D(filters = 4, kernel_size=(1,25), padding=\"same\", activation=\"sigmoid\",input_shape=(32, 5, 1 ), kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l1(weight_decay)))\n",
    "# CAPA PARA FILTRADO ESPACIAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(32,1), padding=\"same\", activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l1(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "## Siguientes capas convolucionales: \n",
    "model.add(Conv2D(20, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l1(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\"\"\"\n",
    "\n",
    "model.add(Flatten())\n",
    "\"\"\"\n",
    "model.add(Dense(20, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Dropout(0.5))\n",
    "\"\"\"\n",
    "model.add(Dense(y_train.shape[1], activation=\"softmax\"))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)        \n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x14edaba0a00>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14edbc38550>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x14ee1cc9ee0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x14ee1cc9f10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x14ee1cedb50>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x14ee1ce2e20>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x14ee1e3f670>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x14ee1e3f5e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x14ee1e371f0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "conv2d_1\n",
      "max_pooling2d\n",
      "dropout\n",
      "conv2d_2\n",
      "max_pooling2d_1\n",
      "dropout_1\n",
      "flatten\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers: print (l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the parameters of a layer can bee accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25, 1, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[0].get_weights()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.24068019, -0.07674633,  0.4790727 , -0.07130321]],\n",
       "\n",
       "        [[ 0.21091655,  0.21842629,  0.18383981, -0.32557943]],\n",
       "\n",
       "        [[ 0.19866416,  0.617227  ,  0.07104418,  0.06461999]],\n",
       "\n",
       "        [[ 0.10253877,  0.33204854, -0.40873712, -0.13785602]],\n",
       "\n",
       "        [[ 0.4736011 , -0.04306291,  0.4280621 , -0.11919595]],\n",
       "\n",
       "        [[-0.17049536,  0.61446166,  0.03604019, -0.22190933]],\n",
       "\n",
       "        [[-0.16453922, -0.34366703,  0.14005844, -0.07996979]],\n",
       "\n",
       "        [[ 0.47391772,  0.06733344, -0.18894207,  0.15723056]],\n",
       "\n",
       "        [[ 0.1361043 ,  0.2771354 ,  0.08519099, -0.14571227]],\n",
       "\n",
       "        [[ 0.04043397, -0.11972906, -0.16630217,  0.11223119]],\n",
       "\n",
       "        [[ 0.04957186, -0.4817722 , -0.04309487, -0.32336688]],\n",
       "\n",
       "        [[-0.16339909,  0.25472045, -0.26331317, -0.4971105 ]],\n",
       "\n",
       "        [[-0.5418059 ,  0.00466701, -0.28919783, -0.27049708]],\n",
       "\n",
       "        [[-0.22365358,  0.17499048,  0.02625321,  0.0563293 ]],\n",
       "\n",
       "        [[ 0.32587492,  0.4596388 ,  0.30991048,  0.04951527]],\n",
       "\n",
       "        [[-0.5610868 ,  0.05948032,  0.10499021, -0.13891266]],\n",
       "\n",
       "        [[ 0.14581203, -0.02868117, -0.27971515, -0.33959404]],\n",
       "\n",
       "        [[ 0.11080077, -0.17915565, -0.1718768 ,  0.50350475]],\n",
       "\n",
       "        [[ 0.03200133,  0.28005323,  0.00833313, -0.03305693]],\n",
       "\n",
       "        [[-0.05658321, -0.3867967 ,  0.00107718, -0.22838241]],\n",
       "\n",
       "        [[ 0.06526667, -0.12725416,  0.51283383, -0.16950944]],\n",
       "\n",
       "        [[ 0.08465242, -0.22117484,  0.3733913 , -0.52479196]],\n",
       "\n",
       "        [[ 0.22912903,  0.14762366, -0.0522743 ,  0.6281608 ]],\n",
       "\n",
       "        [[ 0.02876166,  0.06976303,  0.6016004 , -0.17031917]],\n",
       "\n",
       "        [[ 0.39827856,  0.43794444,  0.38410783, -0.04569134]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases # Bias de la primera capa: 500 bias inicializados a 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train the model with M-BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 - 5s - loss: 0.7603 - accuracy: 0.4808 - val_loss: 0.6819 - val_accuracy: 0.6154\n",
      "Epoch 2/100\n",
      "4/4 - 0s - loss: 0.7292 - accuracy: 0.5769 - val_loss: 0.6811 - val_accuracy: 0.6154\n",
      "Epoch 3/100\n",
      "4/4 - 0s - loss: 0.7087 - accuracy: 0.6058 - val_loss: 0.6841 - val_accuracy: 0.6154\n",
      "Epoch 4/100\n",
      "4/4 - 0s - loss: 0.7094 - accuracy: 0.6250 - val_loss: 0.6888 - val_accuracy: 0.6154\n",
      "Epoch 5/100\n",
      "4/4 - 0s - loss: 0.6958 - accuracy: 0.6154 - val_loss: 0.6879 - val_accuracy: 0.6154\n",
      "Epoch 6/100\n",
      "4/4 - 0s - loss: 0.6841 - accuracy: 0.6346 - val_loss: 0.6872 - val_accuracy: 0.6154\n",
      "Epoch 7/100\n",
      "4/4 - 0s - loss: 0.6865 - accuracy: 0.6058 - val_loss: 0.6865 - val_accuracy: 0.6154\n",
      "Epoch 8/100\n",
      "4/4 - 0s - loss: 0.6997 - accuracy: 0.5962 - val_loss: 0.6869 - val_accuracy: 0.6154\n",
      "Epoch 9/100\n",
      "4/4 - 0s - loss: 0.7010 - accuracy: 0.6154 - val_loss: 0.6870 - val_accuracy: 0.6154\n",
      "Epoch 10/100\n",
      "4/4 - 0s - loss: 0.7006 - accuracy: 0.6154 - val_loss: 0.6868 - val_accuracy: 0.6154\n",
      "Epoch 11/100\n",
      "4/4 - 0s - loss: 0.6861 - accuracy: 0.6154 - val_loss: 0.6865 - val_accuracy: 0.6154\n",
      "Epoch 12/100\n",
      "4/4 - 0s - loss: 0.6963 - accuracy: 0.6154 - val_loss: 0.6855 - val_accuracy: 0.6154\n",
      "Epoch 13/100\n",
      "4/4 - 0s - loss: 0.6922 - accuracy: 0.6154 - val_loss: 0.6855 - val_accuracy: 0.6154\n",
      "Epoch 14/100\n",
      "4/4 - 0s - loss: 0.6947 - accuracy: 0.6058 - val_loss: 0.6858 - val_accuracy: 0.6154\n",
      "Epoch 15/100\n",
      "4/4 - 0s - loss: 0.6799 - accuracy: 0.6154 - val_loss: 0.6856 - val_accuracy: 0.6154\n",
      "Epoch 16/100\n",
      "4/4 - 0s - loss: 0.6917 - accuracy: 0.6154 - val_loss: 0.6860 - val_accuracy: 0.6154\n",
      "Epoch 17/100\n",
      "4/4 - 0s - loss: 0.6817 - accuracy: 0.6154 - val_loss: 0.6866 - val_accuracy: 0.6154\n",
      "Epoch 18/100\n",
      "4/4 - 0s - loss: 0.6838 - accuracy: 0.6154 - val_loss: 0.6846 - val_accuracy: 0.6154\n",
      "Epoch 19/100\n",
      "4/4 - 0s - loss: 0.6995 - accuracy: 0.6154 - val_loss: 0.6844 - val_accuracy: 0.6154\n",
      "Epoch 20/100\n",
      "4/4 - 0s - loss: 0.6922 - accuracy: 0.6154 - val_loss: 0.6857 - val_accuracy: 0.6154\n",
      "Epoch 21/100\n",
      "4/4 - 0s - loss: 0.6825 - accuracy: 0.6250 - val_loss: 0.6842 - val_accuracy: 0.6154\n",
      "Epoch 22/100\n",
      "4/4 - 0s - loss: 0.6736 - accuracy: 0.6154 - val_loss: 0.6826 - val_accuracy: 0.6154\n",
      "Epoch 23/100\n",
      "4/4 - 0s - loss: 0.6726 - accuracy: 0.6250 - val_loss: 0.6822 - val_accuracy: 0.6154\n",
      "Epoch 24/100\n",
      "4/4 - 0s - loss: 0.6855 - accuracy: 0.6058 - val_loss: 0.6825 - val_accuracy: 0.6154\n",
      "Epoch 25/100\n",
      "4/4 - 0s - loss: 0.6825 - accuracy: 0.6058 - val_loss: 0.6816 - val_accuracy: 0.6154\n",
      "Epoch 26/100\n",
      "4/4 - 0s - loss: 0.6746 - accuracy: 0.6250 - val_loss: 0.6811 - val_accuracy: 0.6154\n",
      "Epoch 27/100\n",
      "4/4 - 0s - loss: 0.6828 - accuracy: 0.6154 - val_loss: 0.6810 - val_accuracy: 0.6154\n",
      "Epoch 28/100\n",
      "4/4 - 0s - loss: 0.6883 - accuracy: 0.6154 - val_loss: 0.6814 - val_accuracy: 0.6154\n",
      "Epoch 29/100\n",
      "4/4 - 0s - loss: 0.6898 - accuracy: 0.6154 - val_loss: 0.6816 - val_accuracy: 0.6154\n",
      "Epoch 30/100\n",
      "4/4 - 0s - loss: 0.6781 - accuracy: 0.6154 - val_loss: 0.6801 - val_accuracy: 0.6154\n",
      "Epoch 31/100\n",
      "4/4 - 0s - loss: 0.6903 - accuracy: 0.6154 - val_loss: 0.6817 - val_accuracy: 0.6154\n",
      "Epoch 32/100\n",
      "4/4 - 0s - loss: 0.6825 - accuracy: 0.6154 - val_loss: 0.6818 - val_accuracy: 0.6154\n",
      "Epoch 33/100\n",
      "4/4 - 0s - loss: 0.6789 - accuracy: 0.6250 - val_loss: 0.6788 - val_accuracy: 0.6154\n",
      "Epoch 34/100\n",
      "4/4 - 0s - loss: 0.6813 - accuracy: 0.6154 - val_loss: 0.6772 - val_accuracy: 0.6154\n",
      "Epoch 35/100\n",
      "4/4 - 0s - loss: 0.6837 - accuracy: 0.6154 - val_loss: 0.6771 - val_accuracy: 0.6154\n",
      "Epoch 36/100\n",
      "4/4 - 0s - loss: 0.6757 - accuracy: 0.6154 - val_loss: 0.6766 - val_accuracy: 0.6154\n",
      "Epoch 37/100\n",
      "4/4 - 0s - loss: 0.6815 - accuracy: 0.6154 - val_loss: 0.6777 - val_accuracy: 0.6154\n",
      "Epoch 38/100\n",
      "4/4 - 0s - loss: 0.6888 - accuracy: 0.6154 - val_loss: 0.6793 - val_accuracy: 0.6154\n",
      "Epoch 39/100\n",
      "4/4 - 0s - loss: 0.6567 - accuracy: 0.6154 - val_loss: 0.6795 - val_accuracy: 0.6154\n",
      "Epoch 40/100\n",
      "4/4 - 0s - loss: 0.6821 - accuracy: 0.6154 - val_loss: 0.6790 - val_accuracy: 0.6154\n",
      "Epoch 41/100\n",
      "4/4 - 0s - loss: 0.6806 - accuracy: 0.6250 - val_loss: 0.6798 - val_accuracy: 0.6154\n",
      "Epoch 42/100\n",
      "4/4 - 0s - loss: 0.6909 - accuracy: 0.5962 - val_loss: 0.6803 - val_accuracy: 0.6154\n",
      "Epoch 43/100\n",
      "4/4 - 0s - loss: 0.6684 - accuracy: 0.6154 - val_loss: 0.6787 - val_accuracy: 0.6154\n",
      "Epoch 44/100\n",
      "4/4 - 0s - loss: 0.6732 - accuracy: 0.6154 - val_loss: 0.6778 - val_accuracy: 0.6154\n",
      "Epoch 45/100\n",
      "4/4 - 0s - loss: 0.6777 - accuracy: 0.6154 - val_loss: 0.6754 - val_accuracy: 0.6154\n",
      "Epoch 46/100\n",
      "4/4 - 0s - loss: 0.6672 - accuracy: 0.6154 - val_loss: 0.6738 - val_accuracy: 0.6154\n",
      "Epoch 47/100\n",
      "4/4 - 0s - loss: 0.6671 - accuracy: 0.6250 - val_loss: 0.6735 - val_accuracy: 0.6154\n",
      "Epoch 48/100\n",
      "4/4 - 0s - loss: 0.6829 - accuracy: 0.6154 - val_loss: 0.6729 - val_accuracy: 0.6154\n",
      "Epoch 49/100\n",
      "4/4 - 0s - loss: 0.6753 - accuracy: 0.6154 - val_loss: 0.6738 - val_accuracy: 0.6154\n",
      "Epoch 50/100\n",
      "4/4 - 0s - loss: 0.6697 - accuracy: 0.6154 - val_loss: 0.6765 - val_accuracy: 0.6154\n",
      "Epoch 51/100\n",
      "4/4 - 0s - loss: 0.6745 - accuracy: 0.6250 - val_loss: 0.6769 - val_accuracy: 0.6154\n",
      "Epoch 52/100\n",
      "4/4 - 0s - loss: 0.6768 - accuracy: 0.6154 - val_loss: 0.6769 - val_accuracy: 0.6154\n",
      "Epoch 53/100\n",
      "4/4 - 0s - loss: 0.6803 - accuracy: 0.6154 - val_loss: 0.6757 - val_accuracy: 0.6154\n",
      "Epoch 54/100\n",
      "4/4 - 0s - loss: 0.6809 - accuracy: 0.6154 - val_loss: 0.6731 - val_accuracy: 0.6154\n",
      "Epoch 55/100\n",
      "4/4 - 0s - loss: 0.6815 - accuracy: 0.6250 - val_loss: 0.6722 - val_accuracy: 0.6154\n",
      "Epoch 56/100\n",
      "4/4 - 0s - loss: 0.6740 - accuracy: 0.6154 - val_loss: 0.6738 - val_accuracy: 0.6154\n",
      "Epoch 57/100\n",
      "4/4 - 0s - loss: 0.6570 - accuracy: 0.6154 - val_loss: 0.6715 - val_accuracy: 0.6154\n",
      "Epoch 58/100\n",
      "4/4 - 0s - loss: 0.6594 - accuracy: 0.6250 - val_loss: 0.6693 - val_accuracy: 0.6154\n",
      "Epoch 59/100\n",
      "4/4 - 0s - loss: 0.6593 - accuracy: 0.6154 - val_loss: 0.6693 - val_accuracy: 0.6154\n",
      "Epoch 60/100\n",
      "4/4 - 0s - loss: 0.6573 - accuracy: 0.6154 - val_loss: 0.6711 - val_accuracy: 0.6154\n",
      "Epoch 61/100\n",
      "4/4 - 0s - loss: 0.6618 - accuracy: 0.6058 - val_loss: 0.6696 - val_accuracy: 0.6154\n",
      "Epoch 62/100\n",
      "4/4 - 0s - loss: 0.6593 - accuracy: 0.6442 - val_loss: 0.6697 - val_accuracy: 0.6154\n",
      "Epoch 63/100\n",
      "4/4 - 0s - loss: 0.6674 - accuracy: 0.6154 - val_loss: 0.6708 - val_accuracy: 0.6154\n",
      "Epoch 64/100\n",
      "4/4 - 0s - loss: 0.6611 - accuracy: 0.6250 - val_loss: 0.6695 - val_accuracy: 0.6154\n",
      "Epoch 65/100\n",
      "4/4 - 0s - loss: 0.6716 - accuracy: 0.6058 - val_loss: 0.6701 - val_accuracy: 0.6154\n",
      "Epoch 66/100\n",
      "4/4 - 0s - loss: 0.6604 - accuracy: 0.6058 - val_loss: 0.6674 - val_accuracy: 0.6154\n",
      "Epoch 67/100\n",
      "4/4 - 0s - loss: 0.6760 - accuracy: 0.6154 - val_loss: 0.6657 - val_accuracy: 0.6154\n",
      "Epoch 68/100\n",
      "4/4 - 0s - loss: 0.6545 - accuracy: 0.6538 - val_loss: 0.6637 - val_accuracy: 0.6154\n",
      "Epoch 69/100\n",
      "4/4 - 0s - loss: 0.6469 - accuracy: 0.6250 - val_loss: 0.6622 - val_accuracy: 0.6154\n",
      "Epoch 70/100\n",
      "4/4 - 0s - loss: 0.6499 - accuracy: 0.6250 - val_loss: 0.6615 - val_accuracy: 0.6154\n",
      "Epoch 71/100\n",
      "4/4 - 0s - loss: 0.6676 - accuracy: 0.6154 - val_loss: 0.6644 - val_accuracy: 0.6154\n",
      "Epoch 72/100\n",
      "4/4 - 0s - loss: 0.6611 - accuracy: 0.6250 - val_loss: 0.6697 - val_accuracy: 0.6154\n",
      "Epoch 73/100\n",
      "4/4 - 0s - loss: 0.6447 - accuracy: 0.6635 - val_loss: 0.6721 - val_accuracy: 0.6154\n",
      "Epoch 74/100\n",
      "4/4 - 0s - loss: 0.6607 - accuracy: 0.6442 - val_loss: 0.6724 - val_accuracy: 0.6154\n",
      "Epoch 75/100\n",
      "4/4 - 0s - loss: 0.6511 - accuracy: 0.7115 - val_loss: 0.6692 - val_accuracy: 0.6154\n",
      "Epoch 76/100\n",
      "4/4 - 0s - loss: 0.6684 - accuracy: 0.6346 - val_loss: 0.6675 - val_accuracy: 0.6154\n",
      "Epoch 77/100\n",
      "4/4 - 0s - loss: 0.6555 - accuracy: 0.6250 - val_loss: 0.6661 - val_accuracy: 0.6154\n",
      "Epoch 78/100\n",
      "4/4 - 0s - loss: 0.6480 - accuracy: 0.6923 - val_loss: 0.6675 - val_accuracy: 0.6154\n",
      "Epoch 79/100\n",
      "4/4 - 0s - loss: 0.6476 - accuracy: 0.6250 - val_loss: 0.6665 - val_accuracy: 0.6154\n",
      "Epoch 80/100\n",
      "4/4 - 0s - loss: 0.6451 - accuracy: 0.7019 - val_loss: 0.6649 - val_accuracy: 0.6154\n",
      "Epoch 81/100\n",
      "4/4 - 0s - loss: 0.6532 - accuracy: 0.6635 - val_loss: 0.6644 - val_accuracy: 0.6154\n",
      "Epoch 82/100\n",
      "4/4 - 0s - loss: 0.6553 - accuracy: 0.6442 - val_loss: 0.6654 - val_accuracy: 0.6154\n",
      "Epoch 83/100\n",
      "4/4 - 0s - loss: 0.6594 - accuracy: 0.6442 - val_loss: 0.6609 - val_accuracy: 0.6154\n",
      "Epoch 84/100\n",
      "4/4 - 0s - loss: 0.6504 - accuracy: 0.6346 - val_loss: 0.6616 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "4/4 - 0s - loss: 0.6348 - accuracy: 0.6442 - val_loss: 0.6640 - val_accuracy: 0.6154\n",
      "Epoch 86/100\n",
      "4/4 - 0s - loss: 0.6398 - accuracy: 0.6346 - val_loss: 0.6690 - val_accuracy: 0.6154\n",
      "Epoch 87/100\n",
      "4/4 - 0s - loss: 0.6455 - accuracy: 0.6250 - val_loss: 0.6679 - val_accuracy: 0.6154\n",
      "Epoch 88/100\n",
      "4/4 - 0s - loss: 0.6372 - accuracy: 0.6538 - val_loss: 0.6645 - val_accuracy: 0.6154\n",
      "Epoch 89/100\n",
      "4/4 - 0s - loss: 0.6302 - accuracy: 0.6442 - val_loss: 0.6643 - val_accuracy: 0.6154\n",
      "Epoch 90/100\n",
      "4/4 - 0s - loss: 0.6207 - accuracy: 0.6250 - val_loss: 0.6643 - val_accuracy: 0.6154\n",
      "Epoch 91/100\n",
      "4/4 - 0s - loss: 0.6196 - accuracy: 0.6346 - val_loss: 0.6630 - val_accuracy: 0.6154\n",
      "Epoch 92/100\n",
      "4/4 - 0s - loss: 0.6390 - accuracy: 0.6250 - val_loss: 0.6618 - val_accuracy: 0.6154\n",
      "Epoch 93/100\n",
      "4/4 - 0s - loss: 0.6339 - accuracy: 0.6346 - val_loss: 0.6631 - val_accuracy: 0.6154\n",
      "Epoch 94/100\n",
      "4/4 - 0s - loss: 0.6214 - accuracy: 0.6731 - val_loss: 0.6634 - val_accuracy: 0.6154\n",
      "Epoch 95/100\n",
      "4/4 - 0s - loss: 0.6190 - accuracy: 0.7019 - val_loss: 0.6617 - val_accuracy: 0.6154\n",
      "Epoch 96/100\n",
      "4/4 - 0s - loss: 0.6111 - accuracy: 0.7404 - val_loss: 0.6611 - val_accuracy: 0.6154\n",
      "Epoch 97/100\n",
      "4/4 - 0s - loss: 0.6487 - accuracy: 0.6827 - val_loss: 0.6608 - val_accuracy: 0.6154\n",
      "Epoch 98/100\n",
      "4/4 - 0s - loss: 0.6154 - accuracy: 0.7692 - val_loss: 0.6650 - val_accuracy: 0.6154\n",
      "Epoch 99/100\n",
      "4/4 - 0s - loss: 0.6106 - accuracy: 0.7019 - val_loss: 0.6533 - val_accuracy: 0.6154\n",
      "Epoch 100/100\n",
      "4/4 - 0s - loss: 0.5964 - accuracy: 0.7115 - val_loss: 0.6493 - val_accuracy: 0.6154\n",
      "22.592390775680542\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#history = model.fit(X_train, y_train, batch_size=32, steps_per_epoch=len(y_train)/32, epochs=100, verbose=2, validation_data=(X_dev, y_dev),callbacks=[tensorboard])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=2, validation_data=(X_dev, y_dev))\n",
    "print (time.time() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=pd.DataFrame(history.history)\n",
    "results.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel (\"Epochs\")\n",
    "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
    "plt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "# categorical_accuracy es el training accuracy\n",
    "# val_categorical_accuracy es el validation accuracy\n",
    "# loss es el training loss\n",
    "# val_loss es el validation loss\n",
    "\n",
    "# Overfitting:\n",
    "# Por un lado la Accuracy de los datos de entrenamiento aumenta con las epochs,\n",
    "# mientras que la Accuracy de los datos de validación disminuye o se mantiene constante a lo largo de las epochs. \n",
    "# La Loss de los datos de validación alcanza su mínimo después de pocos epochs y luego empieza a subir, \n",
    "# mientras que la Loss de los datos de entrenamiento disminuye linealmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 2, 'epochs': 100, 'steps': 4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.596408</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.649262</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "99  0.596408  0.711538  0.649262      0.615385"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set:  0.7115384340286255\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the training set: \", results.values[-1:][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the development test set:  0.6153846383094788\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the development test set: \", results.values[-1:][0][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how the model predicts using the development test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43, 0.57],\n",
       "       [0.41, 0.59],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.42, 0.58],\n",
       "       [0.42, 0.58],\n",
       "       [0.43, 0.57],\n",
       "       [0.41, 0.59],\n",
       "       [0.34, 0.66],\n",
       "       [0.41, 0.59],\n",
       "       [0.36, 0.64],\n",
       "       [0.37, 0.63],\n",
       "       [0.39, 0.61],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.37, 0.63],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.38, 0.62],\n",
       "       [0.33, 0.67],\n",
       "       [0.34, 0.66],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.3 , 0.7 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions=model.predict(X_dev).round(2) \n",
    "dev_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_rounded_predictions=np.round(dev_predictions)\n",
    "indices = np.argmax(dev_predictions,1)\n",
    "for row, index in zip(dev_rounded_predictions, indices): row[index]=1\n",
    "dev_rounded_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True  True  True  True  True  True  True False\n",
      " False False False False  True  True  True  True  True  True  True  True\n",
      " False False]\n"
     ]
    }
   ],
   "source": [
    "dev_correct_predictions = np.equal(np.argmax(dev_rounded_predictions,1),np.argmax(y_dev,1))\n",
    "print (dev_correct_predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 10, True: 16})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter (dev_correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model if it is better than others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "model.save('./Modelos/CNN_model3_ce.h5') # Change the name in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnew_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\\n\\nimport numpy as np\\n\\n# Verify state\\nnew_predictions = new_model.predict(X_dev)\\nnp.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\\n\\n# Note that the optimizer state is also preserved:\\n# you can resume training where you left off.\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract\n",
    "\"\"\"\n",
    "new_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Verify state\n",
    "new_predictions = new_model.predict(X_dev)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is also preserved:\n",
    "# you can resume training where you left off.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Final Test\n",
    "\n",
    "#### 10.1 - Load the final test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom collections import Counter\\ndef predictWithModel(model, X_test, y_test, task1, task2, task3=\"\"):\\n    model.evaluate(X_test, y_test)\\n    test_predictions = model.predict(X_test)\\n    test_rounded_predictions=np.round(test_predictions)\\n    indices = np.argmax(test_predictions,1)\\n    for row, index in zip(test_rounded_predictions, indices): row[index]=1\\n    print(test_rounded_predictions[:20])\\n    \\n    # ACCURACY:\\n    test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(y_test,1))\\n    print()\\n    print(test_correct_predictions)\\n    print(type(test_correct_predictions))\\n    final_test_prediction_results=Counter(test_correct_predictions)\\n    \\n    success = np.mean(test_rounded_predictions == y_test)*100\\n    \\n    return final_test_prediction_results, success\\n    '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from collections import Counter\n",
    "def predictWithModel(model, X_test, y_test, task1, task2, task3=\"\"):\n",
    "    model.evaluate(X_test, y_test)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_rounded_predictions=np.round(test_predictions)\n",
    "    indices = np.argmax(test_predictions,1)\n",
    "    for row, index in zip(test_rounded_predictions, indices): row[index]=1\n",
    "    print(test_rounded_predictions[:20])\n",
    "    \n",
    "    # ACCURACY:\n",
    "    test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(y_test,1))\n",
    "    print()\n",
    "    print(test_correct_predictions)\n",
    "    print(type(test_correct_predictions))\n",
    "    final_test_prediction_results=Counter(test_correct_predictions)\n",
    "    \n",
    "    success = np.mean(test_rounded_predictions == y_test)*100\n",
    "    \n",
    "    return final_test_prediction_results, success\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nusers = [\"0091\"]\\nfor u in users:   \\n    print(\"USER:\", u)\\n    #X_test, y_test = readRegisterAndReturnXy(u, total_records, 122, 123, 127)\\n    accuracy, success = predictWithModel(model, X_test, y_test, 402,404)\\n    print(u, accuracy, success)\\n    print()\\n    '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "users = [\"0091\"]\n",
    "for u in users:   \n",
    "    print(\"USER:\", u)\n",
    "    #X_test, y_test = readRegisterAndReturnXy(u, total_records, 122, 123, 127)\n",
    "    accuracy, success = predictWithModel(model, X_test, y_test, 402,404)\n",
    "    print(u, accuracy, success)\n",
    "    print()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
