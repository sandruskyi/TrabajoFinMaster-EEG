{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4: Clasificación con CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con la arquitectura anterior: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primero\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambios realizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevos resultados: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "    \n",
    "    TRAIN                   DEV\n",
    "    loss       accuracy     val_loss    val_accuracy\n",
    "    0.001835\t1.0\t        4.204031\t0.438776\n",
    "    \n",
    "Por tanto: \n",
    "\n",
    "    E = 1 - Accuracy\n",
    "    Etrain = 1 - 1.0\t = 0\n",
    "    Etest = 1 - 0.438776 = 0.561224\n",
    "    \n",
    "    Bias = Etrain - Ehuman = 0\n",
    "    Variance = Etest - Etrain = 0.561224 \n",
    "\n",
    "El bias es muy bajo pero la varianza es muy alta (56%). Para ello habrá que o regularizar, o cambiar la arquitectura (menos neuronas => Mejor varianza, más capas => mayor abstracción), o añadir más datos (cosa que no es posible). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Signal libraries\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROutput:\n",
    "    def __init__(self, task, data):\n",
    "        self.task = task\n",
    "        self.data = data\n",
    "        \n",
    "class OutTaskData: \n",
    "    def __init__(self, task, data): \n",
    "        self.task = task\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "# Primero leemos los registros\n",
    "def read_outputs(rec):\n",
    "    '''read_outputs(\"userS0091f1.mat\")'''\n",
    "    mat = sio.loadmat(rec)\n",
    "    mdata = mat['session']\n",
    "    val = mdata[0,0]\n",
    "    #output = ROutput(np.array(val[\"task\"]), np.array(val[\"data\"]))\n",
    "    output = ROutput(np.array(val[\"task_EEG\"]), np.array(val[\"data_EEG\"]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Perceptron\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "task1 = 402 # SE PUEDE CAMBIAR\n",
    "task2 = 404 # SE PUEDE CAMBIAR\n",
    "task_OneHotEnconding = {402: [1.,0.], 404: [0.,1.]}\n",
    "user = 'W29' # SE PUEDE CAMBIAR\n",
    "day = '0401'\n",
    "folder_day = 'W29-01_04_2021'\n",
    "total_records = 22 # CAMBIAR SI HAY MAS REGISTROS\n",
    "fm = 200\n",
    "electrodes_names_selected = ['F3', 'FZ', 'FC1','FCZ','C1','CZ','CP1','CPZ', 'FC5', 'FC3','C5','C3','CP5','CP3','P3',\n",
    "                             'PZ','F4','FC2','FC4','FC6','C2','C4','CP2','CP4','C6','CP6','P4','HR' ,'HL', 'VU', 'VD']\n",
    "number_channels = len(electrodes_names_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 22\n"
     ]
    }
   ],
   "source": [
    "# Lectura de registros\n",
    "lTaskData = []\n",
    "\n",
    "total_records_used = 0\n",
    "for i_rec in range(1,total_records+1):\n",
    "    i_rec_record = i_rec\n",
    "    if i_rec_record <10:\n",
    "        i_rec_record = \"0\"+str(i_rec_record)\n",
    "    if i_rec % 2 != 0: # Registros impares primero: USUARIO SIN MOVIMIENTO SOLO PENSANDO\n",
    "        record = \"./RegistrosSinProcesar/\"+folder_day+\"/W29_2021\"+day+\"_openloop_\"+str(i_rec_record)+\".mat\"\n",
    "        output = read_outputs(record) # output.task será y, output.data será x\n",
    "\n",
    "        outT = (output.task == task1) | (output.task == task2)\n",
    "\n",
    "        outData = output.data[0:np.shape(output.data)[0], outT[0,:]]\n",
    "        outTask = output.task[0, outT[0,:]]\n",
    "        outTD = OutTaskData(outTask, outData)\n",
    "        lTaskData.append(outTD)\n",
    "        total_records_used+=1\n",
    "\n",
    "print(total_records_used, total_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8, 31, 5600)\n",
      "y_train: (8, 5600)\n",
      "X_dev: (2, 31, 5600)\n",
      "y_dev: (2, 5600)\n",
      "X_test: (1, 31, 5600)\n",
      "y_test: (1, 5600)\n",
      "WINDOWING & ONE HOT ENCODER:\n",
      "X_train: (392, 31, 300, 1)\n",
      "y_train: (392, 2)\n",
      "X_dev: (98, 31, 300, 1)\n",
      "y_dev: (98, 2)\n",
      "X_test: (49, 31, 300, 1)\n",
      "y_test: (49, 2)\n"
     ]
    }
   ],
   "source": [
    "# Vamos a coger 2 registros para el entrenamiento, 1 para el conjunto dev set, 1 para el test set\n",
    "X_train, y_train, X_dev, y_dev, X_test, y_test = [],[],[],[],[],[] \n",
    "for j in range(0,total_records_used-3): # Cogemos 8 registros para entrenamiento\n",
    "    X_train.append(lTaskData[j].data)\n",
    "    y_train.append(lTaskData[j].task)\n",
    "\n",
    "for j in range(total_records_used-3,total_records_used-1): # Cogemos 2 registros para el dev set\n",
    "    X_dev.append(lTaskData[j].data)\n",
    "    y_dev.append(lTaskData[j].task)\n",
    "for j in range(total_records_used-1,total_records_used): # Cogemos 1 registros para el test set\n",
    "    X_test.append(lTaskData[j].data)\n",
    "    y_test.append(lTaskData[j].task)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "#y_train = np.ravel(np.array(y_train))\n",
    "y_train = np.array(y_train)\n",
    "X_dev = np.array(X_dev)\n",
    "#y_dev = np.ravel(np.array(y_dev))\n",
    "y_dev = np.array(y_dev)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "#y_test = np.ravel(np.array(y_test))\n",
    "\n",
    "print (\"X_train:\",X_train.shape)\n",
    "print (\"y_train:\",y_train.shape)\n",
    "print (\"X_dev:\",X_dev.shape)\n",
    "print (\"y_dev:\",y_dev.shape)\n",
    "print (\"X_test:\",X_test.shape)\n",
    "print (\"y_test:\",y_test.shape)\n",
    "\n",
    "\n",
    "# VENTANEO Y ONE HOT ENCODING \n",
    "window = 300\n",
    "samples_advance = 100\n",
    "\n",
    "# Ventaneo X_train\n",
    "\n",
    "X_train_l = []\n",
    "y_train_l = []\n",
    "for num_X_train in range(np.shape(X_train)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_train)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_train)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_train[num_X_train,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_train[num_X_train, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_train_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_train_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_train_l = np.array(X_train_l)\n",
    "y_train_l = np.array(y_train_l)\n",
    "\n",
    "\n",
    "# Ventaneo X_dev\n",
    "X_dev_l = []\n",
    "y_dev_l = []\n",
    "for num_X_dev in range(np.shape(X_dev)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_dev)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_dev)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_dev[num_X_dev,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_dev[num_X_dev, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_dev_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_dev_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_dev_l = np.array(X_dev_l)\n",
    "y_dev_l = np.array(y_dev_l)\n",
    "\n",
    "# Ventaneo X_test\n",
    "X_test_l = []\n",
    "y_test_l = []\n",
    "for num_X_test in range(np.shape(X_test)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_test)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_test)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_test[num_X_test,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_test[num_X_test, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_test_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_test_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_test_l = np.array(X_test_l)\n",
    "y_test_l = np.array(y_test_l)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_l = X_train_l.reshape((np.shape(X_train_l)[0],np.shape(X_train_l)[1],np.shape(X_train_l)[2], 1))\n",
    "X_dev_l = X_dev_l.reshape((np.shape(X_dev_l)[0],np.shape(X_dev_l)[1],np.shape(X_dev_l)[2], 1))\n",
    "X_test_l = X_test_l.reshape((np.shape(X_test_l)[0],np.shape(X_test_l)[1],np.shape(X_test_l)[2], 1))\n",
    "\n",
    "\n",
    "print(\"WINDOWING & ONE HOT ENCODER:\")\n",
    "print (\"X_train:\",X_train_l.shape)\n",
    "print (\"y_train:\",y_train_l.shape)\n",
    "print (\"X_dev:\",X_dev_l.shape)\n",
    "print (\"y_dev:\",y_dev_l.shape)\n",
    "print (\"X_test:\",X_test_l.shape)\n",
    "print (\"y_test:\",y_test_l.shape)\n",
    "\n",
    "X_train = X_train_l\n",
    "y_train = y_train_l\n",
    "X_dev = X_dev_l\n",
    "y_dev = y_dev_l\n",
    "X_test = X_test_l\n",
    "y_test = y_test_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = X_train.shape[1]\n",
    "OUTPUTS = y_train.shape[1]\n",
    "NUM_TRAINING_EXAMPLES = int(round(X_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int(round(y_train.shape[0]/1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data is displayed to test correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -8.09402561],\n",
       "         [ -9.94211674],\n",
       "         [ -7.67301702],\n",
       "         ...,\n",
       "         [  3.9353075 ],\n",
       "         [  5.40302658],\n",
       "         [  7.70658255]],\n",
       "\n",
       "        [[ -5.0390377 ],\n",
       "         [ -6.66358757],\n",
       "         [ -4.47667217],\n",
       "         ...,\n",
       "         [  2.1584661 ],\n",
       "         [  3.46315312],\n",
       "         [  6.43767405]],\n",
       "\n",
       "        [[-10.60903263],\n",
       "         [-12.09577656],\n",
       "         [-10.72430229],\n",
       "         ...,\n",
       "         [  2.3000679 ],\n",
       "         [  3.46812749],\n",
       "         [  6.45359421]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  1.61085725],\n",
       "         [  1.76080692],\n",
       "         [ -0.56686342],\n",
       "         ...,\n",
       "         [ -0.50050861],\n",
       "         [  3.40154266],\n",
       "         [  3.74983001]],\n",
       "\n",
       "        [[  1.47814846],\n",
       "         [  0.68146783],\n",
       "         [  1.03147733],\n",
       "         ...,\n",
       "         [  4.97134638],\n",
       "         [  4.92773724],\n",
       "         [  3.80344081]],\n",
       "\n",
       "        [[  5.40894794],\n",
       "         [  0.86323416],\n",
       "         [ -1.62228251],\n",
       "         ...,\n",
       "         [ -0.30909678],\n",
       "         [  0.05893415],\n",
       "         [  5.40368414]]],\n",
       "\n",
       "\n",
       "       [[[  0.95847905],\n",
       "         [ -4.44262743],\n",
       "         [ -3.83154249],\n",
       "         ...,\n",
       "         [ -8.26578903],\n",
       "         [ -1.67391038],\n",
       "         [ 10.06772804]],\n",
       "\n",
       "        [[  7.78987312],\n",
       "         [  1.9427551 ],\n",
       "         [  1.12500751],\n",
       "         ...,\n",
       "         [ -4.09685278],\n",
       "         [ -0.2537449 ],\n",
       "         [ 10.06615829]],\n",
       "\n",
       "        [[  9.49413872],\n",
       "         [  3.17877674],\n",
       "         [  0.88871896],\n",
       "         ...,\n",
       "         [ -1.56858706],\n",
       "         [  1.65985727],\n",
       "         [ 11.23039818]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  1.39937258],\n",
       "         [ -0.89466304],\n",
       "         [ -0.87535387],\n",
       "         ...,\n",
       "         [ -1.879228  ],\n",
       "         [  1.1248163 ],\n",
       "         [ 11.80609322]],\n",
       "\n",
       "        [[ -6.12129068],\n",
       "         [-12.81042862],\n",
       "         [ -9.9220171 ],\n",
       "         ...,\n",
       "         [ -3.50849438],\n",
       "         [  2.47708893],\n",
       "         [ 12.98461628]],\n",
       "\n",
       "        [[ -1.85709   ],\n",
       "         [ -1.13775074],\n",
       "         [  1.18251276],\n",
       "         ...,\n",
       "         [  2.6194973 ],\n",
       "         [  5.75357866],\n",
       "         [ 10.4064436 ]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-43.6853981 ],\n",
       "         [-49.84642792],\n",
       "         [-42.8303833 ],\n",
       "         ...,\n",
       "         [-31.06373405],\n",
       "         [-28.10698128],\n",
       "         [-27.32731438]],\n",
       "\n",
       "        [[ -1.35212481],\n",
       "         [ -7.82445431],\n",
       "         [ -0.83776265],\n",
       "         ...,\n",
       "         [ -5.16151333],\n",
       "         [ -0.52796578],\n",
       "         [  0.42776355]],\n",
       "\n",
       "        [[ -7.07759523],\n",
       "         [-13.66497612],\n",
       "         [ -6.8888979 ],\n",
       "         ...,\n",
       "         [-12.12047195],\n",
       "         [ -9.29841518],\n",
       "         [ -7.64439344]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -1.41719162],\n",
       "         [ -8.32554913],\n",
       "         [ -0.87606043],\n",
       "         ...,\n",
       "         [ -7.44441748],\n",
       "         [ -7.2287488 ],\n",
       "         [ -5.33666945]],\n",
       "\n",
       "        [[-76.46214294],\n",
       "         [-83.27526093],\n",
       "         [-76.93689728],\n",
       "         ...,\n",
       "         [-19.95397949],\n",
       "         [-19.38440323],\n",
       "         [-19.66468811]],\n",
       "\n",
       "        [[ -2.16663432],\n",
       "         [-10.39913177],\n",
       "         [ -2.16957879],\n",
       "         ...,\n",
       "         [ -8.38955307],\n",
       "         [ -8.60554028],\n",
       "         [ -1.97400618]]],\n",
       "\n",
       "\n",
       "       [[[-54.24480438],\n",
       "         [-55.76259613],\n",
       "         [-56.89716721],\n",
       "         ...,\n",
       "         [-16.79919052],\n",
       "         [-16.91117477],\n",
       "         [-16.76407051]],\n",
       "\n",
       "        [[-12.63129616],\n",
       "         [-12.89976692],\n",
       "         [-12.67405033],\n",
       "         ...,\n",
       "         [ -9.00664425],\n",
       "         [ -9.59034348],\n",
       "         [ -9.60505772]],\n",
       "\n",
       "        [[-22.35799789],\n",
       "         [-23.78342438],\n",
       "         [-23.35025978],\n",
       "         ...,\n",
       "         [-10.64000797],\n",
       "         [-12.04390812],\n",
       "         [-11.9746933 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -2.06412339],\n",
       "         [ -5.4450717 ],\n",
       "         [ -6.98235655],\n",
       "         ...,\n",
       "         [  3.18147063],\n",
       "         [  0.14948435],\n",
       "         [  0.2379002 ]],\n",
       "\n",
       "        [[-61.8571434 ],\n",
       "         [-66.57529449],\n",
       "         [-66.42589569],\n",
       "         ...,\n",
       "         [ -0.29729298],\n",
       "         [  0.87306768],\n",
       "         [ -1.55782568]],\n",
       "\n",
       "        [[ -5.90384912],\n",
       "         [-11.75942421],\n",
       "         [ -8.96345806],\n",
       "         ...,\n",
       "         [  1.10633934],\n",
       "         [ -1.91123796],\n",
       "         [ -2.66354895]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 300, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 31, 300, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 31, 300, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_epochs = 100 #2000\\n#learning_rate = 0.001\\nbatch_size = 32 #250 \\nn_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\\nrate_dropout = [0.8, 0.4, 0.2, 0.1]\\nweight_decay = 1e-4\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "n_epochs = 100 #2000\n",
    "#learning_rate = 0.001\n",
    "batch_size = 32 #250 \n",
    "n_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\n",
    "rate_dropout = [0.8, 0.4, 0.2, 0.1]\n",
    "weight_decay = 1e-4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Build the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 31, 300, 4)        104       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 300, 4)        500       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 150, 4)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 18002     \n",
      "=================================================================\n",
      "Total params: 18,606\n",
      "Trainable params: 18,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, DepthwiseConv2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import optimizers, regularizers\n",
    "import keras.backend as K\n",
    "#K.set_image_data_format('channels_first')\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "# Convolution2D(filtrosConv1, tamaño_filtro1, padding=\"same\", input_shape=(longitud, altura,3), activation = \"relu\")\n",
    "    # - filtrosConv1 número de filtros que aplicaremos tras la primera convolución, normalmente este tamaño va a aumentando\n",
    "    # tras convoluciones para que aumente la dimensión de profundidad (qué cosas hay en mi imagen)\n",
    "    # - tamaño_filtro1 tamaño espacial del kernel (de los filtros)\n",
    "    # - padding = si es same es que es igual que la imagen, vamos crea una imagen del mismo tamaño con el filtro, si es \n",
    "    # valid es que no hay padding y crea una imagen más pequeña que la imagen (creo)\n",
    "    # - input_shape = longitud y altura, tamaño que usará para convolucionar al entrenar\n",
    "    \n",
    "# CAPA PARA FILTRADO TEMPORAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(1,25), padding=\"same\", activation=\"relu\",input_shape=(31, 300,1 ), kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "# CAPA PARA FILTRADO ESPACIAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(31,1), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\"\"\"\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## Siguientes capas convolucionales: \n",
    "model.add(Conv2D(20, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(40, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Conv2D(80, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model.add(Conv2D(160, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\"\"\"\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y_train.shape[1], activation=\"softmax\"))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)        \n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x276d20a7220>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x276d1176040>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x276d10c8a00>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x276d13338e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x276d132a9d0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "conv2d_1\n",
      "max_pooling2d\n",
      "flatten\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers: print (l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the parameters of a layer can bee accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25, 1, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[0].get_weights()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 4.50243987e-02,  4.58692312e-02,  2.09918082e-01,\n",
       "          -1.23317331e-01]],\n",
       "\n",
       "        [[ 1.47867605e-01,  1.20574787e-01,  3.04542333e-01,\n",
       "          -1.15116313e-01]],\n",
       "\n",
       "        [[-5.17974377e-01,  3.99521887e-02,  1.12314612e-01,\n",
       "          -5.95382936e-02]],\n",
       "\n",
       "        [[-3.48448604e-01, -5.34528315e-01,  1.81690022e-01,\n",
       "           2.67774552e-01]],\n",
       "\n",
       "        [[ 1.14118448e-02,  3.02221306e-04, -6.33053422e-01,\n",
       "           1.03928903e-02]],\n",
       "\n",
       "        [[ 4.05220777e-01,  1.25764146e-01,  1.27826212e-02,\n",
       "           2.02214614e-01]],\n",
       "\n",
       "        [[ 1.77932084e-01,  2.25548550e-01, -9.38821509e-02,\n",
       "          -4.16223645e-01]],\n",
       "\n",
       "        [[-9.65219515e-04, -2.84350932e-01, -4.35686409e-01,\n",
       "          -1.02792002e-01]],\n",
       "\n",
       "        [[ 6.29089400e-02,  2.71328300e-01,  1.51945636e-01,\n",
       "           3.35011810e-01]],\n",
       "\n",
       "        [[ 5.03230393e-01,  2.42323786e-01, -2.97274739e-02,\n",
       "          -1.15462780e-01]],\n",
       "\n",
       "        [[-4.18076515e-02, -4.35901284e-01,  7.49409497e-02,\n",
       "          -2.21664473e-01]],\n",
       "\n",
       "        [[ 3.47690359e-02,  3.89780067e-02,  2.68532038e-01,\n",
       "          -1.28989364e-03]],\n",
       "\n",
       "        [[-1.88722908e-01,  2.15905786e-01,  2.23269477e-01,\n",
       "           4.44169849e-01]],\n",
       "\n",
       "        [[-3.76408070e-01,  4.39287007e-01, -7.69921616e-02,\n",
       "           6.01397529e-02]],\n",
       "\n",
       "        [[-2.94046193e-01, -4.92400629e-03, -4.82061803e-01,\n",
       "          -5.27127497e-02]],\n",
       "\n",
       "        [[-1.29310535e-02, -3.04735065e-01,  1.34612277e-01,\n",
       "           1.99608773e-01]],\n",
       "\n",
       "        [[-6.17892683e-01, -4.57379997e-01, -2.53257722e-01,\n",
       "          -2.68594593e-01]],\n",
       "\n",
       "        [[ 2.26862952e-01, -3.71601224e-01,  3.54921013e-01,\n",
       "          -2.23393872e-01]],\n",
       "\n",
       "        [[ 2.13285908e-02, -2.09787995e-01, -7.49517456e-02,\n",
       "           9.19750035e-02]],\n",
       "\n",
       "        [[-2.78454095e-01, -7.43006095e-02, -2.75895745e-01,\n",
       "           4.88958247e-02]],\n",
       "\n",
       "        [[ 6.71605393e-02, -4.20009315e-01,  3.65874738e-01,\n",
       "           4.71960813e-01]],\n",
       "\n",
       "        [[ 2.53633946e-01, -3.68499190e-01, -3.92646790e-02,\n",
       "          -2.95608908e-01]],\n",
       "\n",
       "        [[-2.14658692e-01,  4.28538471e-01, -2.55485117e-01,\n",
       "           4.69607025e-01]],\n",
       "\n",
       "        [[ 2.00387657e-01,  2.98576385e-01,  2.57180542e-01,\n",
       "          -1.57439590e-01]],\n",
       "\n",
       "        [[-5.11518046e-02,  4.60587114e-01,  2.92234004e-01,\n",
       "          -9.88441333e-02]]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases # Bias de la primera capa: 500 bias inicializados a 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train the model with M-BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 - 4s - loss: 9.1976 - accuracy: 0.4872 - val_loss: 6.9167 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "13/13 - 2s - loss: 1.8380 - accuracy: 0.6429 - val_loss: 3.1988 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "13/13 - 2s - loss: 1.0317 - accuracy: 0.7015 - val_loss: 2.6825 - val_accuracy: 0.4592\n",
      "Epoch 4/100\n",
      "13/13 - 2s - loss: 0.4796 - accuracy: 0.8163 - val_loss: 2.7037 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "13/13 - 2s - loss: 0.2355 - accuracy: 0.9056 - val_loss: 2.6330 - val_accuracy: 0.4898\n",
      "Epoch 6/100\n",
      "13/13 - 2s - loss: 0.1233 - accuracy: 0.9566 - val_loss: 2.7575 - val_accuracy: 0.4694\n",
      "Epoch 7/100\n",
      "13/13 - 2s - loss: 0.0691 - accuracy: 0.9923 - val_loss: 2.8905 - val_accuracy: 0.4490\n",
      "Epoch 8/100\n",
      "13/13 - 2s - loss: 0.0388 - accuracy: 1.0000 - val_loss: 2.9971 - val_accuracy: 0.4388\n",
      "Epoch 9/100\n",
      "13/13 - 2s - loss: 0.0313 - accuracy: 1.0000 - val_loss: 3.0090 - val_accuracy: 0.4490\n",
      "Epoch 10/100\n",
      "13/13 - 2s - loss: 0.0241 - accuracy: 1.0000 - val_loss: 3.0331 - val_accuracy: 0.4592\n",
      "Epoch 11/100\n",
      "13/13 - 2s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 3.0709 - val_accuracy: 0.4286\n",
      "Epoch 12/100\n",
      "13/13 - 2s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 3.1116 - val_accuracy: 0.4490\n",
      "Epoch 13/100\n",
      "13/13 - 3s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 3.1387 - val_accuracy: 0.4592\n",
      "Epoch 14/100\n",
      "13/13 - 3s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 3.1920 - val_accuracy: 0.4388\n",
      "Epoch 15/100\n",
      "13/13 - 2s - loss: 0.0116 - accuracy: 1.0000 - val_loss: 3.2009 - val_accuracy: 0.4490\n",
      "Epoch 16/100\n",
      "13/13 - 2s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.2309 - val_accuracy: 0.4592\n",
      "Epoch 17/100\n",
      "13/13 - 2s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 3.2565 - val_accuracy: 0.4490\n",
      "Epoch 18/100\n",
      "13/13 - 2s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 3.2822 - val_accuracy: 0.4592\n",
      "Epoch 19/100\n",
      "13/13 - 2s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 3.3083 - val_accuracy: 0.4592\n",
      "Epoch 20/100\n",
      "13/13 - 3s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.3339 - val_accuracy: 0.4388\n",
      "Epoch 21/100\n",
      "13/13 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.3578 - val_accuracy: 0.4388\n",
      "Epoch 22/100\n",
      "13/13 - 2s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.3781 - val_accuracy: 0.4388\n",
      "Epoch 23/100\n",
      "13/13 - 2s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.4011 - val_accuracy: 0.4490\n",
      "Epoch 24/100\n",
      "13/13 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.4248 - val_accuracy: 0.4388\n",
      "Epoch 25/100\n",
      "13/13 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 3.4412 - val_accuracy: 0.4388\n",
      "Epoch 26/100\n",
      "13/13 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.4515 - val_accuracy: 0.4388\n",
      "Epoch 27/100\n",
      "13/13 - 3s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 3.4724 - val_accuracy: 0.4388\n",
      "Epoch 28/100\n",
      "13/13 - 3s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.4901 - val_accuracy: 0.4388\n",
      "Epoch 29/100\n",
      "13/13 - 3s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.5073 - val_accuracy: 0.4388\n",
      "Epoch 30/100\n",
      "13/13 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.5227 - val_accuracy: 0.4388\n",
      "Epoch 31/100\n",
      "13/13 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.5433 - val_accuracy: 0.4388\n",
      "Epoch 32/100\n",
      "13/13 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.5599 - val_accuracy: 0.4388\n",
      "Epoch 33/100\n",
      "13/13 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.5794 - val_accuracy: 0.4388\n",
      "Epoch 34/100\n",
      "13/13 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.5906 - val_accuracy: 0.4388\n",
      "Epoch 35/100\n",
      "13/13 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.6022 - val_accuracy: 0.4388\n",
      "Epoch 36/100\n",
      "13/13 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.6200 - val_accuracy: 0.4388\n",
      "Epoch 37/100\n",
      "13/13 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.6357 - val_accuracy: 0.4388\n",
      "Epoch 38/100\n",
      "13/13 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.6482 - val_accuracy: 0.4388\n",
      "Epoch 39/100\n",
      "13/13 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.6610 - val_accuracy: 0.4388\n",
      "Epoch 40/100\n",
      "13/13 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.6754 - val_accuracy: 0.4388\n",
      "Epoch 41/100\n",
      "13/13 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.6827 - val_accuracy: 0.4388\n",
      "Epoch 42/100\n",
      "13/13 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.6988 - val_accuracy: 0.4388\n",
      "Epoch 43/100\n",
      "13/13 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.7141 - val_accuracy: 0.4286\n",
      "Epoch 44/100\n",
      "13/13 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.7214 - val_accuracy: 0.4490\n",
      "Epoch 45/100\n",
      "13/13 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.7355 - val_accuracy: 0.4388\n",
      "Epoch 46/100\n",
      "13/13 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.7497 - val_accuracy: 0.4388\n",
      "Epoch 47/100\n",
      "13/13 - 3s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.7620 - val_accuracy: 0.4388\n",
      "Epoch 48/100\n",
      "13/13 - 3s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.7792 - val_accuracy: 0.4388\n",
      "Epoch 49/100\n",
      "13/13 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.7865 - val_accuracy: 0.4388\n",
      "Epoch 50/100\n",
      "13/13 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.7971 - val_accuracy: 0.4388\n",
      "Epoch 51/100\n",
      "13/13 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.8134 - val_accuracy: 0.4388\n",
      "Epoch 52/100\n",
      "13/13 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.8193 - val_accuracy: 0.4388\n",
      "Epoch 53/100\n",
      "13/13 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.8329 - val_accuracy: 0.4388\n",
      "Epoch 54/100\n",
      "13/13 - 3s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.8450 - val_accuracy: 0.4388\n",
      "Epoch 55/100\n",
      "13/13 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.8563 - val_accuracy: 0.4388\n",
      "Epoch 56/100\n",
      "13/13 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.8648 - val_accuracy: 0.4388\n",
      "Epoch 57/100\n",
      "13/13 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.8759 - val_accuracy: 0.4388\n",
      "Epoch 58/100\n",
      "13/13 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.8868 - val_accuracy: 0.4388\n",
      "Epoch 59/100\n",
      "13/13 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.8959 - val_accuracy: 0.4388\n",
      "Epoch 60/100\n",
      "13/13 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.9070 - val_accuracy: 0.4286\n",
      "Epoch 61/100\n",
      "13/13 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.9142 - val_accuracy: 0.4388\n",
      "Epoch 62/100\n",
      "13/13 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.9241 - val_accuracy: 0.4286\n",
      "Epoch 63/100\n",
      "13/13 - 3s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.9345 - val_accuracy: 0.4286\n",
      "Epoch 64/100\n",
      "13/13 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.9440 - val_accuracy: 0.4286\n",
      "Epoch 65/100\n",
      "13/13 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.9523 - val_accuracy: 0.4286\n",
      "Epoch 66/100\n",
      "13/13 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.9597 - val_accuracy: 0.4286\n",
      "Epoch 67/100\n",
      "13/13 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.9692 - val_accuracy: 0.4286\n",
      "Epoch 68/100\n",
      "13/13 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.9780 - val_accuracy: 0.4388\n",
      "Epoch 69/100\n",
      "13/13 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.9848 - val_accuracy: 0.4286\n",
      "Epoch 70/100\n",
      "13/13 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.9932 - val_accuracy: 0.4286\n",
      "Epoch 71/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.0033 - val_accuracy: 0.4286\n",
      "Epoch 72/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.0118 - val_accuracy: 0.4388\n",
      "Epoch 73/100\n",
      "13/13 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.0208 - val_accuracy: 0.4388\n",
      "Epoch 74/100\n",
      "13/13 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.0297 - val_accuracy: 0.4388\n",
      "Epoch 75/100\n",
      "13/13 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.0361 - val_accuracy: 0.4388\n",
      "Epoch 76/100\n",
      "13/13 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.0433 - val_accuracy: 0.4388\n",
      "Epoch 77/100\n",
      "13/13 - 3s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.0539 - val_accuracy: 0.4388\n",
      "Epoch 78/100\n",
      "13/13 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.0602 - val_accuracy: 0.4388\n",
      "Epoch 79/100\n",
      "13/13 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.0684 - val_accuracy: 0.4388\n",
      "Epoch 80/100\n",
      "13/13 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.0758 - val_accuracy: 0.4388\n",
      "Epoch 81/100\n",
      "13/13 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.0831 - val_accuracy: 0.4388\n",
      "Epoch 82/100\n",
      "13/13 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.0905 - val_accuracy: 0.4388\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.0971 - val_accuracy: 0.4388\n",
      "Epoch 84/100\n",
      "13/13 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.1040 - val_accuracy: 0.4388\n",
      "Epoch 85/100\n",
      "13/13 - 3s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.1107 - val_accuracy: 0.4388\n",
      "Epoch 86/100\n",
      "13/13 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.1173 - val_accuracy: 0.4388\n",
      "Epoch 87/100\n",
      "13/13 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1242 - val_accuracy: 0.4388\n",
      "Epoch 88/100\n",
      "13/13 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1307 - val_accuracy: 0.4388\n",
      "Epoch 89/100\n",
      "13/13 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1381 - val_accuracy: 0.4388\n",
      "Epoch 90/100\n",
      "13/13 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1460 - val_accuracy: 0.4694\n",
      "Epoch 91/100\n",
      "13/13 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1525 - val_accuracy: 0.4388\n",
      "Epoch 92/100\n",
      "13/13 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1586 - val_accuracy: 0.4388\n",
      "Epoch 93/100\n",
      "13/13 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1649 - val_accuracy: 0.4388\n",
      "Epoch 94/100\n",
      "13/13 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.4388\n",
      "Epoch 95/100\n",
      "13/13 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1756 - val_accuracy: 0.4490\n",
      "Epoch 96/100\n",
      "13/13 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1818 - val_accuracy: 0.4388\n",
      "Epoch 97/100\n",
      "13/13 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1874 - val_accuracy: 0.4388\n",
      "Epoch 98/100\n",
      "13/13 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.1938 - val_accuracy: 0.4388\n",
      "Epoch 99/100\n",
      "13/13 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.1986 - val_accuracy: 0.4388\n",
      "Epoch 100/100\n",
      "13/13 - 3s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.2040 - val_accuracy: 0.4388\n",
      "247.90123653411865\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#history = model.fit(X_train, y_train, batch_size=32, steps_per_epoch=len(y_train)/32, epochs=100, verbose=2, validation_data=(X_dev, y_dev),callbacks=[tensorboard])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=2, validation_data=(X_dev, y_dev))\n",
    "print (time.time() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=pd.DataFrame(history.history)\n",
    "results.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel (\"Epochs\")\n",
    "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
    "plt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "# categorical_accuracy es el training accuracy\n",
    "# val_categorical_accuracy es el validation accuracy\n",
    "# loss es el training loss\n",
    "# val_loss es el validation loss\n",
    "\n",
    "# Overfitting:\n",
    "# Por un lado la Accuracy de los datos de entrenamiento aumenta con las epochs,\n",
    "# mientras que la Accuracy de los datos de validación disminuye o se mantiene constante a lo largo de las epochs. \n",
    "# La Loss de los datos de validación alcanza su mínimo después de pocos epochs y luego empieza a subir, \n",
    "# mientras que la Loss de los datos de entrenamiento disminuye linealmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 2, 'epochs': 100, 'steps': 13}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.001835</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.204031</td>\n",
       "      <td>0.438776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "99  0.001835       1.0  4.204031      0.438776"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set:  1.0\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the training set: \", results.values[-1:][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the development test set:  0.43877550959587097\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the development test set: \", results.values[-1:][0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how the model predicts using the development test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_predictions=model.predict(X_dev).round(2) \n",
    "dev_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_rounded_predictions=np.round(dev_predictions)\n",
    "indices = np.argmax(dev_predictions,1)\n",
    "for row, index in zip(dev_rounded_predictions, indices): row[index]=1\n",
    "dev_rounded_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_correct_predictions = np.equal(np.argmax(dev_rounded_predictions,1),np.argmax(y_dev,1))\n",
    "print (dev_correct_predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter (dev_correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model if it is better than others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "model.save('./Modelos/CNN_model3.h5') # Change the name in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract\n",
    "\"\"\"\n",
    "new_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Verify state\n",
    "new_predictions = new_model.predict(X_dev)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is also preserved:\n",
    "# you can resume training where you left off.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Final Test\n",
    "\n",
    "#### 10.1 - Load the final test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "total_records = 4 # CAMBIAR SI HAY MAS REGISTROS\n",
    "\n",
    "task1 = 122 # SE PUEDE CAMBIAR\n",
    "task2 = 123 # SE PUEDE CAMBIAR\n",
    "task3 = 127 # SE PUEDE CAMBIAR\n",
    "users = [\"0091\"] # SE PUEDE CAMBIAR\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def readRegisterAndReturnXy(user, total_records, task1, task2, task3 = \"\"):\n",
    "    lTaskData = []\n",
    "    for i_rec in range(1,total_records+1):\n",
    "            record = \"userS\"+user+\"f\"+str(i_rec)+\".mat\"\n",
    "            output = read_outputs(record) # output.task será y, output.data será x\n",
    "\n",
    "            if task3 != \"\":\n",
    "                outT = (output.task == task1) | (output.task == task2) | (output.task == task3) \n",
    "            else: \n",
    "                outT = (output.task == task1) | (output.task == task2)\n",
    "            outData = output.data[outT[:,0],0:np.shape(output.data)[1]]\n",
    "\n",
    "            outTask = output.task[outT[:,0]]\n",
    "            outTD = OutTaskData(outTask, outData)\n",
    "            lTaskData.append(outTD)\n",
    "\n",
    "    X_test, y_test = [],[]\n",
    "    for j in range(0,total_records):\n",
    "        X_test.extend(lTaskData[j].data)\n",
    "        y_test.extend(lTaskData[j].task)\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.ravel(np.array(y_test))\n",
    "\n",
    "    print (\"X_test:\",X_test.shape)\n",
    "    print (\"y_test:\",y_test.shape)\n",
    "\n",
    "    # ONE HOT ENCODER\n",
    "    encoder = make_pipeline(StandardScaler(), OneHotEncoder(categories=\"auto\", sparse=False)) # Function that one-hot encodes integers))\n",
    "    y_test = encoder.fit_transform (y_test.reshape(-1,1)) # y_one_hot\n",
    "\n",
    "    print(\"ONE HOT ENCODER:\")\n",
    "    print (\"X_test:\",X_test.shape)\n",
    "    print (\"y_test:\",y_test.shape)\n",
    "    \n",
    "    return X_test, y_test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "n_final_test = n_instances-n_train-n_dev\n",
    "\n",
    "x_final_test = attributes.values[n_train+n_dev:n_instances]\n",
    "t_final_test = label.values[n_train+n_dev:n_instances]\n",
    "\n",
    "print (\"x_test:\",x_final_test.shape)\n",
    "print (\"t_test:\",t_final_test.shape)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def predictWithModel(model, X_test, y_test, task1, task2, task3=\"\"):\n",
    "    model.evaluate(X_test, y_test)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_rounded_predictions=np.round(test_predictions)\n",
    "    indices = np.argmax(test_predictions,1)\n",
    "    for row, index in zip(test_rounded_predictions, indices): row[index]=1\n",
    "    print(test_rounded_predictions[:20])\n",
    "    \n",
    "    # ACCURACY:\n",
    "    test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(y_test,1))\n",
    "    print()\n",
    "    print(test_correct_predictions)\n",
    "    print(type(test_correct_predictions))\n",
    "    final_test_prediction_results=Counter(test_correct_predictions)\n",
    "    \n",
    "    success = np.mean(test_rounded_predictions == y_test)*100\n",
    "    \n",
    "    return final_test_prediction_results, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\"0091\"]\n",
    "for u in users:   \n",
    "    print(\"USER:\", u)\n",
    "    #X_test, y_test = readRegisterAndReturnXy(u, total_records, 122, 123, 127)\n",
    "    accuracy, success = predictWithModel(model, X_test, y_test, 402,404)\n",
    "    print(u, accuracy, success)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(x_final_test, t_final_test) # Un 77 es un accuracy bajo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs computed by the neural network for the final testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test_predictions=model.predict(x_final_test)\n",
    "test_rounded_predictions=np.round(test_predictions)\n",
    "indices = np.argmax(test_predictions,1)\n",
    "for row, index in zip(test_rounded_predictions, indices): row[index]=1\n",
    "test_rounded_predictions[:20]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_final_test[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 30 predictions. True means that the neural network correctly classifies the input vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(t_final_test,1))\n",
    "# test_correct_predictions[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from collections import Counter\n",
    "final_test_prediction_results=Counter(test_correct_predictions)\n",
    "final_test_prediction_results\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test_prediction_results[True]/sum(final_test_prediction_results.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
