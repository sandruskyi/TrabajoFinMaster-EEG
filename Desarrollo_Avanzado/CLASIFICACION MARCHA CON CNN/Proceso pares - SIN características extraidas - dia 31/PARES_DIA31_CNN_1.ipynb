{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4: Clasificación con CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con la arquitectura anterior: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primero\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambios realizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevos resultados: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "    \n",
    "    TRAIN                   DEV\n",
    "    loss       accuracy     val_loss    val_accuracy\n",
    "    0.002318\t1.0\t        3.151356\t0.602041\n",
    "    \n",
    "Por tanto: \n",
    "\n",
    "    E = 1 - Accuracy\n",
    "    Etrain = 1 - 1.0\t = 0\n",
    "    Etest = 1 - 0.602041 = 0.397959\n",
    "    \n",
    "    Bias = Etrain - Ehuman = 0\n",
    "    Variance = Etest - Etrain = 0.397959\n",
    "\n",
    "El bias es muy bajo pero la varianza es muy alta (40%). Para ello habrá que o regularizar, o cambiar la arquitectura (menos neuronas => Mejor varianza, más capas => mayor abstracción), o añadir más datos (cosa que no es posible). \n",
    "\n",
    "Los resultados son horrorosos porque se observa overfitting desde el inicio. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Signal libraries\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROutput:\n",
    "    def __init__(self, task, data):\n",
    "        self.task = task\n",
    "        self.data = data\n",
    "        \n",
    "class OutTaskData: \n",
    "    def __init__(self, task, data): \n",
    "        self.task = task\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "# Primero leemos los registros\n",
    "def read_outputs(rec):\n",
    "    '''read_outputs(\"userS0091f1.mat\")'''\n",
    "    mat = sio.loadmat(rec)\n",
    "    mdata = mat['session']\n",
    "    val = mdata[0,0]\n",
    "    #output = ROutput(np.array(val[\"task\"]), np.array(val[\"data\"]))\n",
    "    output = ROutput(np.array(val[\"task_EEG\"]), np.array(val[\"data_EEG\"]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Perceptron\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "task1 = 402 # SE PUEDE CAMBIAR\n",
    "task2 = 404 # SE PUEDE CAMBIAR\n",
    "task_OneHotEnconding = {402: [1.,0.], 404: [0.,1.]}\n",
    "user = 'W29' # SE PUEDE CAMBIAR\n",
    "day = '0331'\n",
    "folder_day = 'W29-31_03_2021'\n",
    "total_records = 22 # CAMBIAR SI HAY MAS REGISTROS\n",
    "fm = 200\n",
    "electrodes_names_selected = ['F3', 'FZ', 'FC1','FCZ','C1','CZ','CP1','CPZ', 'FC5', 'FC3','C5','C3','CP5','CP3','P3',\n",
    "                             'PZ','F4','FC2','FC4','FC6','C2','C4','CP2','CP4','C6','CP6','P4','HR' ,'HL', 'VU', 'VD']\n",
    "number_channels = len(electrodes_names_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 22\n"
     ]
    }
   ],
   "source": [
    "# Lectura de registros\n",
    "lTaskData = []\n",
    "\n",
    "total_records_used = 0\n",
    "for i_rec in range(1,total_records+1):\n",
    "    i_rec_record = i_rec\n",
    "    if i_rec_record <10:\n",
    "        i_rec_record = \"0\"+str(i_rec_record)\n",
    "    if i_rec % 2 == 0: # Registros impares primero: USUARIO SIN MOVIMIENTO SOLO PENSANDO\n",
    "        record = \"./RegistrosSinProcesar/\"+folder_day+\"/W29_2021\"+day+\"_openloop_\"+str(i_rec_record)+\".mat\"\n",
    "        output = read_outputs(record) # output.task será y, output.data será x\n",
    "\n",
    "        outT = (output.task == task1) | (output.task == task2)\n",
    "\n",
    "        outData = output.data[0:np.shape(output.data)[0], outT[0,:]]\n",
    "        outTask = output.task[0, outT[0,:]]\n",
    "        outTD = OutTaskData(outTask, outData)\n",
    "        lTaskData.append(outTD)\n",
    "        total_records_used+=1\n",
    "\n",
    "print(total_records_used, total_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8, 31, 5600)\n",
      "y_train: (8, 5600)\n",
      "X_dev: (2, 31, 5600)\n",
      "y_dev: (2, 5600)\n",
      "X_test: (1, 31, 5600)\n",
      "y_test: (1, 5600)\n",
      "WINDOWING & ONE HOT ENCODER:\n",
      "X_train: (392, 31, 300, 1)\n",
      "y_train: (392, 2)\n",
      "X_dev: (98, 31, 300, 1)\n",
      "y_dev: (98, 2)\n",
      "X_test: (49, 31, 300, 1)\n",
      "y_test: (49, 2)\n"
     ]
    }
   ],
   "source": [
    "# Vamos a coger 2 registros para el entrenamiento, 1 para el conjunto dev set, 1 para el test set\n",
    "X_train, y_train, X_dev, y_dev, X_test, y_test = [],[],[],[],[],[] \n",
    "for j in range(0,total_records_used-3): # Cogemos 8 registros para entrenamiento\n",
    "    X_train.append(lTaskData[j].data)\n",
    "    y_train.append(lTaskData[j].task)\n",
    "\n",
    "for j in range(total_records_used-3,total_records_used-1): # Cogemos 2 registros para el dev set\n",
    "    X_dev.append(lTaskData[j].data)\n",
    "    y_dev.append(lTaskData[j].task)\n",
    "for j in range(total_records_used-1,total_records_used): # Cogemos 1 registros para el test set\n",
    "    X_test.append(lTaskData[j].data)\n",
    "    y_test.append(lTaskData[j].task)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "#y_train = np.ravel(np.array(y_train))\n",
    "y_train = np.array(y_train)\n",
    "X_dev = np.array(X_dev)\n",
    "#y_dev = np.ravel(np.array(y_dev))\n",
    "y_dev = np.array(y_dev)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "#y_test = np.ravel(np.array(y_test))\n",
    "\n",
    "print (\"X_train:\",X_train.shape)\n",
    "print (\"y_train:\",y_train.shape)\n",
    "print (\"X_dev:\",X_dev.shape)\n",
    "print (\"y_dev:\",y_dev.shape)\n",
    "print (\"X_test:\",X_test.shape)\n",
    "print (\"y_test:\",y_test.shape)\n",
    "\n",
    "\n",
    "# VENTANEO Y ONE HOT ENCODING \n",
    "window = 300\n",
    "samples_advance = 100\n",
    "\n",
    "# Ventaneo X_train\n",
    "\n",
    "X_train_l = []\n",
    "y_train_l = []\n",
    "for num_X_train in range(np.shape(X_train)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_train)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_train)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_train[num_X_train,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_train[num_X_train, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_train_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_train_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_train_l = np.array(X_train_l)\n",
    "y_train_l = np.array(y_train_l)\n",
    "\n",
    "\n",
    "# Ventaneo X_dev\n",
    "X_dev_l = []\n",
    "y_dev_l = []\n",
    "for num_X_dev in range(np.shape(X_dev)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_dev)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_dev)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_dev[num_X_dev,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_dev[num_X_dev, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_dev_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_dev_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_dev_l = np.array(X_dev_l)\n",
    "y_dev_l = np.array(y_dev_l)\n",
    "\n",
    "# Ventaneo X_test\n",
    "X_test_l = []\n",
    "y_test_l = []\n",
    "for num_X_test in range(np.shape(X_test)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_test)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_test)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_test[num_X_test,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_test[num_X_test, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_test_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_test_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_test_l = np.array(X_test_l)\n",
    "y_test_l = np.array(y_test_l)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_l = X_train_l.reshape((np.shape(X_train_l)[0],np.shape(X_train_l)[1],np.shape(X_train_l)[2], 1))\n",
    "X_dev_l = X_dev_l.reshape((np.shape(X_dev_l)[0],np.shape(X_dev_l)[1],np.shape(X_dev_l)[2], 1))\n",
    "X_test_l = X_test_l.reshape((np.shape(X_test_l)[0],np.shape(X_test_l)[1],np.shape(X_test_l)[2], 1))\n",
    "\n",
    "\n",
    "print(\"WINDOWING & ONE HOT ENCODER:\")\n",
    "print (\"X_train:\",X_train_l.shape)\n",
    "print (\"y_train:\",y_train_l.shape)\n",
    "print (\"X_dev:\",X_dev_l.shape)\n",
    "print (\"y_dev:\",y_dev_l.shape)\n",
    "print (\"X_test:\",X_test_l.shape)\n",
    "print (\"y_test:\",y_test_l.shape)\n",
    "\n",
    "X_train = X_train_l\n",
    "y_train = y_train_l\n",
    "X_dev = X_dev_l\n",
    "y_dev = y_dev_l\n",
    "X_test = X_test_l\n",
    "y_test = y_test_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = X_train.shape[1]\n",
    "OUTPUTS = y_train.shape[1]\n",
    "NUM_TRAINING_EXAMPLES = int(round(X_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int(round(y_train.shape[0]/1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data is displayed to test correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 2.82092514e+01],\n",
       "         [ 2.89351730e+01],\n",
       "         [ 2.57947884e+01],\n",
       "         ...,\n",
       "         [-2.64894371e+01],\n",
       "         [-2.27690105e+01],\n",
       "         [-1.97064209e+01]],\n",
       "\n",
       "        [[-2.00550008e+00],\n",
       "         [-3.06276011e+00],\n",
       "         [-5.69424820e+00],\n",
       "         ...,\n",
       "         [-3.42017794e+00],\n",
       "         [-3.77322406e-01],\n",
       "         [ 2.55768967e+00]],\n",
       "\n",
       "        [[ 1.53868520e+00],\n",
       "         [ 1.35626411e+00],\n",
       "         [-1.41677797e+00],\n",
       "         ...,\n",
       "         [-1.09292917e+01],\n",
       "         [-6.08051348e+00],\n",
       "         [-3.19313884e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-9.77449512e+00],\n",
       "         [-1.90407543e+01],\n",
       "         [-1.55003605e+01],\n",
       "         ...,\n",
       "         [ 1.81032715e+01],\n",
       "         [ 1.82797623e+01],\n",
       "         [ 1.87076321e+01]],\n",
       "\n",
       "        [[ 8.44592438e+01],\n",
       "         [ 8.19998398e+01],\n",
       "         [ 8.21672974e+01],\n",
       "         ...,\n",
       "         [-9.96625671e+01],\n",
       "         [-1.03578308e+02],\n",
       "         [-1.05138092e+02]],\n",
       "\n",
       "        [[-5.82478905e+00],\n",
       "         [ 8.06580424e-01],\n",
       "         [-3.93068552e+00],\n",
       "         ...,\n",
       "         [ 7.50815868e+00],\n",
       "         [ 4.11500645e+00],\n",
       "         [ 5.31409681e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 6.64770269e+00],\n",
       "         [ 2.22319269e+00],\n",
       "         [ 2.45259075e+01],\n",
       "         ...,\n",
       "         [-1.37443104e+01],\n",
       "         [-1.44646568e+01],\n",
       "         [-1.44783669e+01]],\n",
       "\n",
       "        [[-1.24282722e+01],\n",
       "         [-1.84865456e+01],\n",
       "         [ 1.01721561e+00],\n",
       "         ...,\n",
       "         [-2.49326050e-01],\n",
       "         [-1.92921050e-02],\n",
       "         [ 4.22278307e-02]],\n",
       "\n",
       "        [[-8.99646378e+00],\n",
       "         [-1.50082550e+01],\n",
       "         [ 5.92787409e+00],\n",
       "         ...,\n",
       "         [ 1.18794911e-01],\n",
       "         [-7.23795146e-02],\n",
       "         [-4.71746564e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.02365170e+01],\n",
       "         [-2.85552311e+01],\n",
       "         [-2.43620586e+01],\n",
       "         ...,\n",
       "         [-1.82955647e+01],\n",
       "         [-1.38664331e+01],\n",
       "         [-7.76209402e+00]],\n",
       "\n",
       "        [[ 1.53313782e+02],\n",
       "         [ 1.51532837e+02],\n",
       "         [ 1.55554031e+02],\n",
       "         ...,\n",
       "         [-1.55364334e+02],\n",
       "         [-1.55210938e+02],\n",
       "         [-1.57247406e+02]],\n",
       "\n",
       "        [[ 6.83019447e+00],\n",
       "         [ 1.04988194e+01],\n",
       "         [ 2.22001820e+01],\n",
       "         ...,\n",
       "         [-2.50185490e+00],\n",
       "         [-8.66393089e-01],\n",
       "         [-2.77501673e-01]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-32.50832748],\n",
       "         [-45.54853439],\n",
       "         [-52.7408905 ],\n",
       "         ...,\n",
       "         [-32.6632843 ],\n",
       "         [-26.30834198],\n",
       "         [-11.45257568]],\n",
       "\n",
       "        [[ 12.60225773],\n",
       "         [ -1.62979472],\n",
       "         [-12.85349846],\n",
       "         ...,\n",
       "         [ -8.99156857],\n",
       "         [ -3.84633279],\n",
       "         [ 12.50936127]],\n",
       "\n",
       "        [[ 15.38480377],\n",
       "         [  1.04007053],\n",
       "         [ -8.48399734],\n",
       "         ...,\n",
       "         [ -9.67211819],\n",
       "         [ -4.2298665 ],\n",
       "         [ 11.37576675]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -6.98024368],\n",
       "         [-17.87797356],\n",
       "         [-25.05665016],\n",
       "         ...,\n",
       "         [ 12.1260376 ],\n",
       "         [ 27.41692734],\n",
       "         [ 48.25946808]],\n",
       "\n",
       "        [[-51.67138672],\n",
       "         [-65.68618011],\n",
       "         [-74.85217285],\n",
       "         ...,\n",
       "         [-39.00770187],\n",
       "         [-25.55912209],\n",
       "         [ -9.8506813 ]],\n",
       "\n",
       "        [[ -2.56852221],\n",
       "         [ -8.74023533],\n",
       "         [-12.07119179],\n",
       "         ...,\n",
       "         [-15.49972057],\n",
       "         [-16.47405052],\n",
       "         [-11.01752949]]],\n",
       "\n",
       "\n",
       "       [[[-59.62939072],\n",
       "         [-53.84295273],\n",
       "         [-42.41113663],\n",
       "         ...,\n",
       "         [-18.33662987],\n",
       "         [-26.2751236 ],\n",
       "         [-28.30541229]],\n",
       "\n",
       "        [[-31.63087654],\n",
       "         [-26.25337219],\n",
       "         [-15.13665771],\n",
       "         ...,\n",
       "         [ -9.28710461],\n",
       "         [-16.8656292 ],\n",
       "         [-18.57706642]],\n",
       "\n",
       "        [[-27.11886024],\n",
       "         [-21.86961555],\n",
       "         [ -9.68200111],\n",
       "         ...,\n",
       "         [ -4.87048006],\n",
       "         [-11.99184227],\n",
       "         [-12.33061981]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-13.95550156],\n",
       "         [ -6.70044661],\n",
       "         [ -4.33677244],\n",
       "         ...,\n",
       "         [ 21.10912132],\n",
       "         [ 24.06651115],\n",
       "         [ 28.20629311]],\n",
       "\n",
       "        [[-81.39221191],\n",
       "         [-71.79236603],\n",
       "         [-64.57866669],\n",
       "         ...,\n",
       "         [-32.30601501],\n",
       "         [-31.56279564],\n",
       "         [-25.44491577]],\n",
       "\n",
       "        [[  3.18074155],\n",
       "         [ 12.22233105],\n",
       "         [ 13.24007988],\n",
       "         ...,\n",
       "         [ -2.52598143],\n",
       "         [ -2.70844793],\n",
       "         [  9.41244507]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 300, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 31, 300, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 31, 300, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_epochs = 100 #2000\\n#learning_rate = 0.001\\nbatch_size = 32 #250 \\nn_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\\nrate_dropout = [0.8, 0.4, 0.2, 0.1]\\nweight_decay = 1e-4\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "n_epochs = 100 #2000\n",
    "#learning_rate = 0.001\n",
    "batch_size = 32 #250 \n",
    "n_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\n",
    "rate_dropout = [0.8, 0.4, 0.2, 0.1]\n",
    "weight_decay = 1e-4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Build the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 31, 300, 4)        104       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 300, 4)        500       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 150, 4)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 18002     \n",
      "=================================================================\n",
      "Total params: 18,606\n",
      "Trainable params: 18,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, DepthwiseConv2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import optimizers, regularizers\n",
    "import keras.backend as K\n",
    "#K.set_image_data_format('channels_first')\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "# Convolution2D(filtrosConv1, tamaño_filtro1, padding=\"same\", input_shape=(longitud, altura,3), activation = \"relu\")\n",
    "    # - filtrosConv1 número de filtros que aplicaremos tras la primera convolución, normalmente este tamaño va a aumentando\n",
    "    # tras convoluciones para que aumente la dimensión de profundidad (qué cosas hay en mi imagen)\n",
    "    # - tamaño_filtro1 tamaño espacial del kernel (de los filtros)\n",
    "    # - padding = si es same es que es igual que la imagen, vamos crea una imagen del mismo tamaño con el filtro, si es \n",
    "    # valid es que no hay padding y crea una imagen más pequeña que la imagen (creo)\n",
    "    # - input_shape = longitud y altura, tamaño que usará para convolucionar al entrenar\n",
    "    \n",
    "# CAPA PARA FILTRADO TEMPORAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(1,25), padding=\"same\", activation=\"relu\",input_shape=(31, 300,1 ), kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "# CAPA PARA FILTRADO ESPACIAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(31,1), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\"\"\"\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## Siguientes capas convolucionales: \n",
    "model.add(Conv2D(20, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(40, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Conv2D(80, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model.add(Conv2D(160, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\"\"\"\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y_train.shape[1], activation=\"softmax\"))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)        \n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d3f9ccb6d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1d3f8ef83a0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1d3f98c9d30>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x1d3f8ef81c0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1d3f98c9d60>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "conv2d_1\n",
      "max_pooling2d\n",
      "flatten\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers: print (l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the parameters of a layer can bee accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25, 1, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[0].get_weights()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.3561954 , -0.19498627,  0.5820949 , -0.49205947]],\n",
       "\n",
       "        [[ 0.2027963 ,  0.09828874,  0.49828318,  0.15717305]],\n",
       "\n",
       "        [[-0.16385305, -0.31102735, -0.14364925, -0.46723926]],\n",
       "\n",
       "        [[ 0.21695153, -0.43669087,  0.32012895, -0.4237992 ]],\n",
       "\n",
       "        [[-0.33661568, -0.3554622 , -0.13381077,  0.395259  ]],\n",
       "\n",
       "        [[ 0.20705132, -0.1277326 , -0.50328267,  0.39004084]],\n",
       "\n",
       "        [[-0.02907873,  0.63224745, -0.12453976, -0.02331808]],\n",
       "\n",
       "        [[-0.23823287, -0.08550348,  0.00131406, -0.08897194]],\n",
       "\n",
       "        [[-0.40498924, -0.36767682, -0.12272361,  0.03615614]],\n",
       "\n",
       "        [[-0.4602445 , -0.1695589 ,  0.41396672,  0.04761192]],\n",
       "\n",
       "        [[ 0.54823965,  0.35805225, -0.33990383, -0.02559604]],\n",
       "\n",
       "        [[-0.37238294, -0.08721535, -0.37998742, -0.36067882]],\n",
       "\n",
       "        [[-0.03691128,  0.24232402,  0.06585947,  0.27016914]],\n",
       "\n",
       "        [[ 0.5391448 , -0.0440843 ,  0.04378559,  0.24107142]],\n",
       "\n",
       "        [[-0.44801205, -0.10449081, -0.09743047, -0.19799632]],\n",
       "\n",
       "        [[-0.0090286 , -0.2327084 , -0.03665314,  0.0598692 ]],\n",
       "\n",
       "        [[ 0.41694638,  0.4784466 , -0.01522888, -0.22036688]],\n",
       "\n",
       "        [[-0.01935468,  0.20001279, -0.43509212, -0.06684447]],\n",
       "\n",
       "        [[-0.5492368 ,  0.30766392,  0.4943095 ,  0.04953584]],\n",
       "\n",
       "        [[ 0.46353918, -0.5967376 ,  0.19202104, -0.18392746]],\n",
       "\n",
       "        [[ 0.25066382, -0.14742593, -0.22614613,  0.21228473]],\n",
       "\n",
       "        [[ 0.38203904, -0.26403987, -0.39289558,  0.46720704]],\n",
       "\n",
       "        [[ 0.3163422 ,  0.45365557,  0.02829741, -0.29566094]],\n",
       "\n",
       "        [[-0.17923352, -0.01064281, -0.4096079 , -0.25030124]],\n",
       "\n",
       "        [[ 0.05944443, -0.01239443, -0.21863261, -0.07349885]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases # Bias de la primera capa: 500 bias inicializados a 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train the model with M-BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 - 3s - loss: 65.2023 - accuracy: 0.4668 - val_loss: 23.4137 - val_accuracy: 0.4694\n",
      "Epoch 2/100\n",
      "13/13 - 2s - loss: 20.8485 - accuracy: 0.5230 - val_loss: 3.6344 - val_accuracy: 0.4796\n",
      "Epoch 3/100\n",
      "13/13 - 2s - loss: 4.8488 - accuracy: 0.6224 - val_loss: 4.3275 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "13/13 - 2s - loss: 2.8551 - accuracy: 0.7092 - val_loss: 3.4740 - val_accuracy: 0.5204\n",
      "Epoch 5/100\n",
      "13/13 - 2s - loss: 1.4000 - accuracy: 0.7806 - val_loss: 3.2856 - val_accuracy: 0.5306\n",
      "Epoch 6/100\n",
      "13/13 - 2s - loss: 0.7551 - accuracy: 0.8265 - val_loss: 3.1306 - val_accuracy: 0.5306\n",
      "Epoch 7/100\n",
      "13/13 - 2s - loss: 0.3992 - accuracy: 0.8903 - val_loss: 3.1290 - val_accuracy: 0.5306\n",
      "Epoch 8/100\n",
      "13/13 - 2s - loss: 0.2178 - accuracy: 0.9337 - val_loss: 3.1342 - val_accuracy: 0.5612\n",
      "Epoch 9/100\n",
      "13/13 - 2s - loss: 0.1328 - accuracy: 0.9592 - val_loss: 3.1166 - val_accuracy: 0.5510\n",
      "Epoch 10/100\n",
      "13/13 - 2s - loss: 0.0820 - accuracy: 0.9821 - val_loss: 3.0991 - val_accuracy: 0.5612\n",
      "Epoch 11/100\n",
      "13/13 - 2s - loss: 0.0564 - accuracy: 0.9872 - val_loss: 3.0804 - val_accuracy: 0.5612\n",
      "Epoch 12/100\n",
      "13/13 - 2s - loss: 0.0408 - accuracy: 0.9974 - val_loss: 3.0721 - val_accuracy: 0.5510\n",
      "Epoch 13/100\n",
      "13/13 - 2s - loss: 0.0324 - accuracy: 0.9974 - val_loss: 3.0607 - val_accuracy: 0.5510\n",
      "Epoch 14/100\n",
      "13/13 - 2s - loss: 0.0263 - accuracy: 0.9974 - val_loss: 3.0542 - val_accuracy: 0.5510\n",
      "Epoch 15/100\n",
      "13/13 - 3s - loss: 0.0217 - accuracy: 0.9974 - val_loss: 3.0440 - val_accuracy: 0.5510\n",
      "Epoch 16/100\n",
      "13/13 - 3s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 3.0381 - val_accuracy: 0.5612\n",
      "Epoch 17/100\n",
      "13/13 - 2s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 3.0352 - val_accuracy: 0.5612\n",
      "Epoch 18/100\n",
      "13/13 - 2s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 3.0394 - val_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "13/13 - 3s - loss: 0.0125 - accuracy: 1.0000 - val_loss: 3.0383 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "13/13 - 2s - loss: 0.0115 - accuracy: 1.0000 - val_loss: 3.0375 - val_accuracy: 0.5918\n",
      "Epoch 21/100\n",
      "13/13 - 3s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.0358 - val_accuracy: 0.5816\n",
      "Epoch 22/100\n",
      "13/13 - 2s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.0357 - val_accuracy: 0.5816\n",
      "Epoch 23/100\n",
      "13/13 - 2s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 3.0374 - val_accuracy: 0.5918\n",
      "Epoch 24/100\n",
      "13/13 - 2s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 3.0367 - val_accuracy: 0.5816\n",
      "Epoch 25/100\n",
      "13/13 - 3s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 3.0352 - val_accuracy: 0.5816\n",
      "Epoch 26/100\n",
      "13/13 - 3s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 3.0370 - val_accuracy: 0.5918\n",
      "Epoch 27/100\n",
      "13/13 - 3s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.0366 - val_accuracy: 0.5918\n",
      "Epoch 28/100\n",
      "13/13 - 4s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0373 - val_accuracy: 0.5918\n",
      "Epoch 29/100\n",
      "13/13 - 3s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.0397 - val_accuracy: 0.5816\n",
      "Epoch 30/100\n",
      "13/13 - 3s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 3.0400 - val_accuracy: 0.5816\n",
      "Epoch 31/100\n",
      "13/13 - 3s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.0419 - val_accuracy: 0.5816\n",
      "Epoch 32/100\n",
      "13/13 - 3s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.0439 - val_accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "13/13 - 3s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.0465 - val_accuracy: 0.5816\n",
      "Epoch 34/100\n",
      "13/13 - 3s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 3.0494 - val_accuracy: 0.5714\n",
      "Epoch 35/100\n",
      "13/13 - 4s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 3.0513 - val_accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "13/13 - 3s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 3.0533 - val_accuracy: 0.5714\n",
      "Epoch 37/100\n",
      "13/13 - 4s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 3.0547 - val_accuracy: 0.5816\n",
      "Epoch 38/100\n",
      "13/13 - 5s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.0559 - val_accuracy: 0.5816\n",
      "Epoch 39/100\n",
      "13/13 - 5s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.0561 - val_accuracy: 0.5714\n",
      "Epoch 40/100\n",
      "13/13 - 5s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.0572 - val_accuracy: 0.5816\n",
      "Epoch 41/100\n",
      "13/13 - 5s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 3.0579 - val_accuracy: 0.5714\n",
      "Epoch 42/100\n",
      "13/13 - 5s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.0596 - val_accuracy: 0.5816\n",
      "Epoch 43/100\n",
      "13/13 - 4s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.0619 - val_accuracy: 0.5714\n",
      "Epoch 44/100\n",
      "13/13 - 5s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.0649 - val_accuracy: 0.5918\n",
      "Epoch 45/100\n",
      "13/13 - 5s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.0665 - val_accuracy: 0.5816\n",
      "Epoch 46/100\n",
      "13/13 - 5s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.0677 - val_accuracy: 0.5816\n",
      "Epoch 47/100\n",
      "13/13 - 5s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.0693 - val_accuracy: 0.5816\n",
      "Epoch 48/100\n",
      "13/13 - 5s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.0707 - val_accuracy: 0.5816\n",
      "Epoch 49/100\n",
      "13/13 - 5s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.0723 - val_accuracy: 0.5816\n",
      "Epoch 50/100\n",
      "13/13 - 5s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.0741 - val_accuracy: 0.5918\n",
      "Epoch 51/100\n",
      "13/13 - 5s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.0748 - val_accuracy: 0.5816\n",
      "Epoch 52/100\n",
      "13/13 - 5s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.0763 - val_accuracy: 0.5816\n",
      "Epoch 53/100\n",
      "13/13 - 5s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.0781 - val_accuracy: 0.5918\n",
      "Epoch 54/100\n",
      "13/13 - 5s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.0793 - val_accuracy: 0.5918\n",
      "Epoch 55/100\n",
      "13/13 - 5s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.0812 - val_accuracy: 0.5918\n",
      "Epoch 56/100\n",
      "13/13 - 5s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.0829 - val_accuracy: 0.5918\n",
      "Epoch 57/100\n",
      "13/13 - 5s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.0845 - val_accuracy: 0.5918\n",
      "Epoch 58/100\n",
      "13/13 - 5s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.0865 - val_accuracy: 0.5918\n",
      "Epoch 59/100\n",
      "13/13 - 5s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.0880 - val_accuracy: 0.5918\n",
      "Epoch 60/100\n",
      "13/13 - 5s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.0900 - val_accuracy: 0.5816\n",
      "Epoch 61/100\n",
      "13/13 - 5s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.0922 - val_accuracy: 0.5918\n",
      "Epoch 62/100\n",
      "13/13 - 5s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.0943 - val_accuracy: 0.5918\n",
      "Epoch 63/100\n",
      "13/13 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0958 - val_accuracy: 0.5918\n",
      "Epoch 64/100\n",
      "13/13 - 5s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0976 - val_accuracy: 0.5918\n",
      "Epoch 65/100\n",
      "13/13 - 6s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0994 - val_accuracy: 0.5918\n",
      "Epoch 66/100\n",
      "13/13 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.1010 - val_accuracy: 0.5816\n",
      "Epoch 67/100\n",
      "13/13 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.1024 - val_accuracy: 0.5918\n",
      "Epoch 68/100\n",
      "13/13 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.1040 - val_accuracy: 0.5918\n",
      "Epoch 69/100\n",
      "13/13 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.1049 - val_accuracy: 0.5918\n",
      "Epoch 70/100\n",
      "13/13 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.1072 - val_accuracy: 0.5918\n",
      "Epoch 71/100\n",
      "13/13 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.1090 - val_accuracy: 0.5918\n",
      "Epoch 72/100\n",
      "13/13 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.1106 - val_accuracy: 0.5918\n",
      "Epoch 73/100\n",
      "13/13 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.1123 - val_accuracy: 0.5918\n",
      "Epoch 74/100\n",
      "13/13 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.1142 - val_accuracy: 0.5918\n",
      "Epoch 75/100\n",
      "13/13 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.1152 - val_accuracy: 0.5918\n",
      "Epoch 76/100\n",
      "13/13 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.1159 - val_accuracy: 0.5918\n",
      "Epoch 77/100\n",
      "13/13 - 8s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.1172 - val_accuracy: 0.5918\n",
      "Epoch 78/100\n",
      "13/13 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.1190 - val_accuracy: 0.5918\n",
      "Epoch 79/100\n",
      "13/13 - 8s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.1207 - val_accuracy: 0.5918\n",
      "Epoch 80/100\n",
      "13/13 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.1224 - val_accuracy: 0.5918\n",
      "Epoch 81/100\n",
      "13/13 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.1240 - val_accuracy: 0.5918\n",
      "Epoch 82/100\n",
      "13/13 - 8s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.1259 - val_accuracy: 0.5918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "13/13 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.1274 - val_accuracy: 0.5918\n",
      "Epoch 84/100\n",
      "13/13 - 8s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.1289 - val_accuracy: 0.5918\n",
      "Epoch 85/100\n",
      "13/13 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.1300 - val_accuracy: 0.5918\n",
      "Epoch 86/100\n",
      "13/13 - 8s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.1318 - val_accuracy: 0.5918\n",
      "Epoch 87/100\n",
      "13/13 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.1327 - val_accuracy: 0.6020\n",
      "Epoch 88/100\n",
      "13/13 - 8s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.1343 - val_accuracy: 0.6020\n",
      "Epoch 89/100\n",
      "13/13 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.1355 - val_accuracy: 0.6020\n",
      "Epoch 90/100\n",
      "13/13 - 8s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.1370 - val_accuracy: 0.6020\n",
      "Epoch 91/100\n",
      "13/13 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.1385 - val_accuracy: 0.6020\n",
      "Epoch 92/100\n",
      "13/13 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.1404 - val_accuracy: 0.6020\n",
      "Epoch 93/100\n",
      "13/13 - 8s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.1422 - val_accuracy: 0.6020\n",
      "Epoch 94/100\n",
      "13/13 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.1432 - val_accuracy: 0.6020\n",
      "Epoch 95/100\n",
      "13/13 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.1447 - val_accuracy: 0.6020\n",
      "Epoch 96/100\n",
      "13/13 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.1458 - val_accuracy: 0.6020\n",
      "Epoch 97/100\n",
      "13/13 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.1475 - val_accuracy: 0.6020\n",
      "Epoch 98/100\n",
      "13/13 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.1486 - val_accuracy: 0.6020\n",
      "Epoch 99/100\n",
      "13/13 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.1497 - val_accuracy: 0.6020\n",
      "Epoch 100/100\n",
      "13/13 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.1514 - val_accuracy: 0.6020\n",
      "491.7406425476074\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#history = model.fit(X_train, y_train, batch_size=32, steps_per_epoch=len(y_train)/32, epochs=100, verbose=2, validation_data=(X_dev, y_dev),callbacks=[tensorboard])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=2, validation_data=(X_dev, y_dev))\n",
    "print (time.time() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAFBCAYAAACb7b3CAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABEl0lEQVR4nO3deXxU1d3H8c9vluwhrAZZFFTUyqpGXLAYNwQ3XCtWrdKqL7uotU+t1bbWPvXp02prl6daS61VWi21KtW2gAoaEMW6b4gigsomOyRhyfp7/phJCJBlkszNJMP3/Xrxmrnn3nvmNwf0N+fec88xd0dERETSSyjVAYiIiEjyKcGLiIikISV4ERGRNKQELyIikoaU4EVERNKQEryIiEgaCizBm9lAM3vOzBaZ2UIzu76RY8zMfmNmS8zsbTM7osG+8Wb2QXzfd4OKU0REJB0F2YOvBv7L3T8HHAN83cwO2+2YCcCQ+J+rgd8BmFkYuDu+/zDg4kbOFRERkSYEluDdfbW7vx5/XwYsAvrvdthEYKrHvAR0N7N9gdHAEndf6u6VwLT4sSIiIpKADrkHb2aDgMOB/+y2qz+wvMH2inhZU+UiIiKSgEjQH2BmecBjwDfdvXT33Y2c4s2UN1b/1cQu75OdnX3kwIED2xHtrmprawmFWvcbqKoWVpbX0ifbyI029jX2Pm1pR9mT2jE51I7JoXZMjva24+LFi9e7e5/G9gWa4M0sSiy5P+TujzdyyAqgYUYeAKwCMpoo34O7TwGmABQVFfmrr76ahMhjSkpKKC4ubtU5H60r5+RfzOVXF43inMN10QHa1o6yJ7Vjcqgdk0PtmBztbUcz+6SpfUGOojfgj8Aid7+ricOeBL4UH01/DLDF3VcDrwBDzGywmWUAk+LHdnrR+C+xqpraFEciIiJ7syB78GOAy4B3zOzNeNktwH4A7n4vMAM4HVgCbAMmx/dVm9k3gKeAMHC/uy8MMNakiUZil+Wra7VKn4iIpE5gCd7d59P4vfSGxzjw9Sb2zSD2A6BLiagHLyIinUDgg+z2NtFw7DdNVY168CLSdVVVVbFixQp27NjR6P6CggIWLVrUwVGln0TbMSsriwEDBhCNRhOuWwk+yaLhWA++Wj14EenCVqxYQX5+PoMGDSI2pGpXZWVl5OfnpyCy9JJIO7o7GzZsYMWKFQwePDjhuvWMQ5JF6nvwSvAi0nXt2LGDXr16NZrcpWOZGb169WryakpTlOCTbOcoel2iF5GuTcm982jL34USfJKFQkY4ZFTXqgcvItIeeXl5qQ6hS1OCD0AkZFSrBy8iIimkBB+AaDhEpe7Bi4gkhbtz4403MmzYMIYPH87f/vY3AFavXs3YsWMZNWoUw4YN4/nnn6empoYrrrii/thf/vKXKY4+dTSKPgDRsHrwIiLJ8vjjj/Pmm2/y1ltvsX79eo466ijGjh3Lww8/zGmnncb3vvc9ampq2LZtG2+++SYrV67k3XffBWDz5s2pDT6FlOADEAmHdA9eRNLGj/65kPdW7bpWWE1NDeFwuM11HtavGz88a2hCx86fP5+LL76YcDhMYWEhJ5xwAq+88gpHHXUUX/7yl6mqquKcc85h1KhRHHDAASxdupRrr72WM844g3HjxrU5xq5Ol+gDEA0ZldXqwYuIJENs0tM9jR07lnnz5tG/f38uu+wypk6dSo8ePXjrrbcoLi7m7rvv5sorr+zgaDsP9eADoB68iKSTxnraHTnRzdixY/n973/P5ZdfzsaNG5k3bx533nknn3zyCf379+eqq65i69atvP7665x++ulkZGRw/vnnc+CBB3LFFVd0SIydkRJ8AHQPXkQkec4991wWLFjAyJEjMTPuuOMO+vbty4MPPsidd95JNBolLy+PqVOnsnLlSiZPnkxtvJP1v//7vymOPnWU4AOgUfQiIu1XXl4OxCZ5ufPOO7nzzjt32X/55Zdz+eWX73He66+/3iHxdXa6Bx+ASNg0F72IiKSUEnwAouGQ1oMXEZGUUoIPQDQU0mIzIiKSUkrwAYiETYvNiIhISinBByAaDukevIiIpJQSfACi6sGLiEiKKcEHIKJ78CIikmJK8AGIRjSKXkSkq6iurk51CIFQgg9ANGTqwYuIJME555zDkUceydChQ5kyZQoAs2bN4ogjjmDkyJGcfPLJQGxSnMmTJzN8+HBGjBjBY489BkBeXl59XY8++mj91LVXXHEF3/rWtzjxxBO56aabePnllznuuOM4/PDDOe644/jggw+A2KI63/72t+vr/b//+z/mzJnDueeeW1/vM888w3nnndcRzdEqmskuALFR9ErwIiLtdf/999OzZ0+2b9/OUUcdxcSJE7nqqquYN28egwcPZuPGjQD8+Mc/pqCggHfeeQeATZs2tVj34sWLmT17NuFwmNLSUubNm0ckEmH27NnccsstPPbYY0yZMoVly5bxxhtvEIlE2LhxIz169ODrX/8669ato0+fPvzpT39i8uTJgbZDWyjBByASDmkuehFJHzO/C5+9s0tRdk01hNuRQvoOhwk/bfGw3/zmN0yfPh2A5cuXM2XKFMaOHcvgwYMB6NmzJwCzZ89m2rRp9ef16NGjxbovvPDC+iVvt2zZwuWXX86HH36ImVFVVVVf7zXXXEMkEtnl8y677DL+8pe/MHnyZBYsWMDUqVMT/eYdRgk+ABlhDbITEWmvkpISZs+ezYIFC8jJyaG4uJiRI0fWXz5vyN0xsz3KG5bt2LFjl325ubn173/wgx9w4oknMn36dD7++GOKi4ubrXfy5MmcddZZZGVlceGFF9b/AOhMAovIzO4HzgTWuvuwRvbfCFzSII7PAX3cfaOZfQyUATVAtbsXBRVnECIh0yA7EUkfjfS0t3fAcrFbtmyhR48e5OTk8P777/PSSy9RUVHB3LlzWbZsWf0l+p49ezJu3Dh++9vf8qtf/QqIXaLv0aMHhYWFLFq0iEMOOYTp06c3GfOWLVvo378/AA888EB9+bhx47j33nspLi6uv0Tfs2dP+vXrR79+/bj99tt55plnAm2HtgpykN0DwPimdrr7ne4+yt1HATcDc919Y4NDTozv71LJHWKX6NWDFxFpn/Hjx1NdXc2IESP4wQ9+wDHHHEOfPn2YMmUK5513HiNHjuSiiy4C4Pvf/z6bNm1i2LBhjBw5kueeew6An/70p5x55pmcdNJJ7Lvvvk1+1ne+8x1uvvlmxowZQ01NTX35lVdeyX777ceIESMYOXIkDz/8cP2+Sy65hIEDB3LYYYcF1ALtE1gP3t3nmdmgBA+/GPhrULF0tIz4RDdNXdoREZGWZWZmMnPmzEb3TZgwYZftvLw8HnzwwT2Ou+CCC7jgggv2KG/YSwc49thjWbx4cf32j3/8YwAikQh33XUXd9111x51zJ8/n6uuuqrF75EqKX9MzsxyiPX0H2tQ7MDTZvaamV2dmsjaLhKONWuNLtOLiKSlI488krfffptLL7001aE0ydyDS0LxHvy/GrsH3+CYi4BL3f2sBmX93H2Vme0DPANc6+7zmjj/auBqgMLCwiMbjqJsr/Ly8l2eoUzUv5ZW8ujiKn5/ag6ZYfXg29qOsiu1Y3KoHRNTUFDAQQcd1OT+mpqa+hHo0natacclS5awZcuWXcpOPPHE15q6ld0Zhv1NYrfL8+6+Kv661symA6OBRhO8u08BpgAUFRV53cjHZCgpKaEt9S0JL4XFizh2zPF0y4omLZ6uqq3tKLtSOyaH2jExixYtanYQXVkHDLLbG7SmHbOysjj88MMTrjull+jNrAA4AXiiQVmumeXXvQfGAe+mJsK2iYRivXY9Cy8iIqkS5GNyfwWKgd5mtgL4IRAFcPd744edCzzt7lsbnFoITI8PTosAD7v7rKDiDELdPXiNpBcRkVQJchT9xQkc8wCxx+kali0FRgYTVcfIUIIXEZEUS/ko+nQUCesSvYiIpJYSfADqLtFX16oHLyLSEZp7MuLjjz9m2LAmH+ZKW0rwAYjGB9lVVqsHLyIiqaEEH4CoevAiIu1y0003cc8999Rv33bbbfzoRz/i5JNP5ogjjmD48OE88cQTzdTQuB07dtSvG3/44YfXT2m7cOFCRo8ezahRoxgxYgQffvghW7du5YwzzmDkyJEMGzaMv/3tb0n7fh2hMzwHn3bq7sFX6R68iKSBn738M97f+P4uZe2d6ObQnody0+ibmtw/adIkvvnNb/K1r30NgEceeYRZs2Zxww030K1bN9avX88xxxzD2Wef3aopwe+++24A3nnnHd5//33GjRvH4sWLuffee7n++uu55JJLqKyspKamhhkzZtCvXz/+/e9/A+wxyUxnpx58AKIaRS8i0i6HH344a9euZdWqVbz11lv06NGDfffdl1tuuYURI0ZwyimnsHLlStasWdOqeufPn89ll10GwKGHHsr+++/P4sWLOfbYY/nJT37Cz372Mz755BOys7MZPnw4s2fP5qabbuL555+noKAgiK8aGPXgA1B/iV49eBFJA431tDtiJrsLLriARx99lM8++4xJkybx0EMPsW7dOl577TWi0SiDBg3aY433ljQ1PfsXv/hFjj76aP79739z2mmncd9993HSSSfx2muvMWPGDG6++WbGjRvHrbfemoyv1iGU4ANQf4le9+BFRNps0qRJXHXVVaxfv565c+fyyCOPsM8++xCNRnnuuef45JNPWl3n2LFjeeihhzjppJNYvHgxn376KYcccghLly7lgAMO4LrrrmPp0qW8/fbbHHroofTs2ZNLL72UvLy8PVag6+yU4AMQDcUv0VcrwYuItNXQoUMpKyujf//+7LvvvlxyySWcddZZFBUVMWrUKA499NBW1/m1r32Na665huHDhxOJRHjggQfIzMzkb3/7G3/5y1+IRqP07duXW2+9lVdeeYUbb7yRUChENBrld7/7XQDfMjhK8AGIRuIT3Wi5WBGRdnnnnXfq3/fu3ZsFCxY0elx5eXmTdQwaNIh3340taZKVldVoT/zmm2/m5ptv3qXstNNO47TTTmtD1J2DBtkFIBLSIDsREUkt9eADENVUtSIiHe6dd96pHyFfJzMzk//85z8piii1lOADoMfkREQ63vDhw3nzzTdTHUanoUv0Adg5il49eBERSQ0l+ADUjaKvVg9eRERSRAk+ADunqlWCFxGR1FCCD8DOe/C6RC8iIqmhBB8ATVUrItKxmlsPfm+lBB+AcMgw0yV6EZG9TXV1dapDqKfH5AISDYc0F72IpIXPfvITKhbtulxsdU0NG9uxXGzm5w6l7y23NLn/pptuYv/9969fLva2227DzJg3bx6bNm2iqqqK22+/nYkTJ7b4WeXl5UycOLHR86ZOncrPf/5zzIwRI0bw5z//mTVr1nDNNdewdOlSAH73u9/Rr18/zjzzzPoZ8X7+859TXl7ObbfdRnFxMccddxwvvPACZ599NgcffDC33347lZWV9OrVi4ceeojCwkLKy8u59tprefXVVzEzfvjDH/LZZ5+xZMkSfvnLXwLwhz/8gUWLFnHXXXe1uW3rKMEHJBoyXaIXEWmjZK4Hn5WVxfTp0/c477333uN//ud/eOGFF+jduzcbN24E4LrrruOEE05g+vTp1NTUUF5ezqZNm5r9jM2bNzN37lwANm3axEsvvYSZcd9993HHHXfwi1/8gh//+McUFBTUT7+7adMmKioqGDNmDHfccQfRaJQ//elP/P73v29v8wFK8IGJhEN6TE5E0kJjPe2gl4ttuB78unXr6teDv+GGG5g3bx6hUKh+Pfi+ffs2W5e7c8stt+xx3rPPPssFF1xA7969AejZsycAzz77LFOnTgUgHA5TUFDQYoK/6KKL6t+vWLGCiy66iNWrV1NZWcngwYMBmD17NtOmTas/rkePHpSVlXHSSSfxr3/9i8997nNUVVUxfPjw1jdYI5TgAxINh6hUD15EpM2StR58U+e5e4u9/zqRSITaBrddd//c3Nzc+vfXXnst3/rWtzj77LMpKSnhtttuA2jy86688kp+8pOfcOihhzJ58uSE4kmEBtkFJBo29eBFRNph0qRJTJs2jUcffZQLLriALVu2tGk9+KbOO/nkk3nkkUfYsGEDQP0l+pNPPrl+adiamhpKS0spLCxk7dq1bNiwgYqKCv71r381+3n9+/cH4MEHH6wvHzduHL/97W/rt+uuChx99NEsX76chx9+mIsvvjjR5mmREnxAImHTcrEiIu3Q2Hrwr776KkVFRTz00EMJrwff1HlDhw7le9/7HieccAIjR47kW9/6FgC//vWvee655xg+fDhHHnkkCxcuJBqNcuutt3L00Udz5plnNvvZt912GxdeeCGf//zn6y//A3z/+99n06ZNDBs2jJEjR/Lcc8/V7/vCF77AmDFj6NGjR1uaqlGBXaI3s/uBM4G17j6skf3FwBPAsnjR4+7+3/F944FfA2HgPnf/aVBxBiV2iV49eBGR9kjGevDNnXf55Zdz+eWX71JWWFjIE088scex1113Hdddd90e5SUlJbtsT5w4sdHR/Xl5ebv06CE2lgFg/vz53HDDDU1+h7YIsgf/ADC+hWOed/dR8T91yT0M3A1MAA4DLjazwwKMMxDRkAbZiYhI8zZv3szBBx9MdnY2J598clLrDqwH7+7zzGxQG04dDSxx96UAZjYNmAi8l8TwAhcJ6zE5EZGO1BXXg+/evTuLFy8OpO5Uj6I/1szeAlYB33b3hUB/YHmDY1YAR6ciuPaI6BK9iEiH0nrwu0plgn8d2N/dy83sdOAfwBCgsWcWmuwKm9nVwNUQu2+y+72Q9igvL29zfdvLt1O5dc97M3uj9rSj7KR2TA61Y2IKCgooLS1t8jGympqa+vvH0naJtqO7s2PHjlb9201Zgnf30gbvZ5jZPWbWm1iPfWCDQwcQ6+E3Vc8UYApAUVGRFxcXJy3GkpIS2lrf7xe/RHVtLcXFxyUtnq6qPe0oO6kdk0PtmJhly5bVT7XaWJIPeqKbvUUi7ejubNiwge7du3P44YcnXHfKEryZ9QXWuLub2WhiA/42AJuBIWY2GFgJTAK+mKo42yoSNrZX6R68iHRNAwYMYMWKFaxbt67R/Tt27CArK6uDo0o/ibZjVlYWAwYMaFXdQT4m91egGOhtZiuAHwJRAHe/F7gA+KqZVQPbgUnu7kC1mX0DeIrYY3L3x+/NdykZ4ZBWkxORLisajdZPsdqYkpKSVvUmpXFBtmOrEryZ9QAGuvvbLR3r7s1Ox+PuvwV+28S+GcCM1sTW2WgUvYiIpFKLz8GbWYmZdTOznsBbwJ/MrP3r2KW5iJaLFRGRFEpkopuC+IC484A/ufuRwCnBhtX16RK9iIikUiIJPmJm+wJfAJqeXV92EdF68CIikkKJJPj/JjbgbYm7v2JmBwAfBhtW1xcJh6hSghcRkRRpcZCdu/8d+HuD7aXA+UEGlQ4ywqZL9CIikjKJDLK7Iz7ILmpmc8xsvZld2hHBdWWRsBabERGR1EnkEv24+CC7M4nNMncwcGOgUaWBSNio0nrwIiKSIokk+Gj89XTgr+6+McB40oaWixURkVRKJMH/08zeB4qAOWbWB9gRbFhdXzQcotZRkhcRkZRoMcG7+3eBY4Eid68CthJbn12akZsZBmB7VU2KIxERkb1Ri6PozSwKXAaMja8oNBe4N+C4urycjFjTbqusIT8r2sLRIiIiyZXIXPS/I3Yf/p749mXxsiuDCiod1PXgt1ZUpzgSERHZGyWS4I9y95ENtp81s7eCCihdNOzBi4iIdLREBtnVmNmBdRvxmeyUtVqQm6EevIiIpE4iPfgbgefMbClgwP7A5ECjSgM5merBi4hI6iQyVe0cMxsCHEIswb9PbNIbaUZ9D75SPXgREel4iVyix90r3P1td3/L3SuAXwYcV5dX34OvUA9eREQ6XkIJvhGW1CjSUE5UPXgREUmdtiZ4TbLegpz4Y3K6By8iIqnQ5D14M3uHxhO5AYWBRZQmMsIhIiHTKHoREUmJ5gbZaSBdO5gZORlh9eBFRCQlmkzw7v5JRwaSjnIzI+rBi4hISrT1HrwkQD14ERFJFSX4AOVmRjSKXkREUkIJPkA5GWE9By8iIimRyHKxjY2m3wK8Ctzu7huaOO9+YgP11rr7sEb2XwLcFN8sB77q7m/F930MlBGb877a3YsS+jadTG5GhM9Kd6Q6DBER2QslMhf9TGKJ9uH49qT4aynwAHBWE+c9APwWmNrE/mXACe6+ycwmAFOAoxvsP9Hd1ycQX6eVkxnRPXgREUmJRBL8GHcf02D7HTN7wd3HmNmlTZ3k7vPMbFAz+19ssPkSMCCBWLqU3IywRtGLiEhKJHIPPs/M6nvWZjYayItvJit7fYXYlYI6DjxtZq+Z2dVJ+owOl5OhHryIiKSGuTc/66yZHQXcTyypG7FL818B3gPOcPdHmjl3EPCvxu7BNzjmROAe4Pi6+/lm1s/dV5nZPsAzwLXuPq+J868GrgYoLCw8ctq0ac1+n9YoLy8nLy+v5QOb8NiHlfzroyruPy0Hs713+v72tqPEqB2TQ+2YHGrH5GhvO5544omvNTVOLZHlYl8BhptZAbEfBJsb7G4yuSfCzEYA9wETGg7Wc/dV8de1ZjYdGA00muDdfQqx+/cUFRV5cXFxe0LaRUlJCe2pbxEf8c+P3ueYMWPJji8fuzdqbztKjNoxOdSOyaF2TI4g27HFS/RmVmBmdwFzgNlm9ot4sm8XM9sPeBy4zN0XNyjPNbP8uvfAOODd9n5eKuRmakU5ERFJjUQG2d1PLMF+Ib59GfAn4LzmTjKzvwLFQG8zWwH8EIgCuPu9wK1AL+Ce+OXrusfhCoHp8bII8LC7z2rVt+okcjIarAmvK1kiItKBEknwB7r7+Q22f2Rmb7Z0krtf3ML+K4ErGylfCoxMIK5OLzdDPXgREUmNREbRbzez4+s2zGwMsD24kNJHTma8B68ELyIiHSyRHvw1wNQG9903AZcHF1L6qO/Ba7paERHpYImMon8LGGlm3eLbpWb2TeDtgGPr8urvwasHLyIiHSzhxWbcvdTdS+Ob3woonrRSP4pePXgREelgbV1Nbu+dtaUV1IMXEZFUaWuCb376OwF29uA1Xa2IiHS0Ju/Bm1kZjSdyA7IDiyiNZEXCmMFWJXgREelgTSZ4d8/vyEDSUShk5ETDbNOKciIi0sHaeoleEpSTGVEPXkREOpwSfMByM8IaZCciIh1OCT5gORkRPSYnIiIdTgk+YLmZ6sGLiEjHS2S52PPM7EMz22JmpWZWZmalLZ0nMTkZugcvIiIdL5Ee/B3A2e5e4O7d3D3f3bsFHVi6yM3UKHoREel4iST4Ne6+KPBI0lRORkQT3YiISIdLZDW5V83sb8A/gIq6Qnd/PKig0kluRljrwYuISIdLJMF3A7YB4xqUOaAEn4CczAjbNIpeREQ6WCLLxU7uiEDSVW5GmMqaWiqra8mI6KEFERHpGC0meDPLAr4CDAWy6srd/csBxpU26laU215ZowQvIiIdJpGM82egL3AaMBcYAJQFGVQ6qV8TXvfhRUSkAyWS4A9y9x8AW939QeAMYHiwYaUPrQkvIiKpkEiCr4q/bjazYUABMCiwiNJMfQ9eA+1ERKQDJTKKfoqZ9QB+ADwJ5AG3BhpVGqnrwesSvYiIdKRERtHfF387Fzgg2HDST27dJXr14EVEpAMlMhd9oZn90cxmxrcPM7OvBB9aesjRIDsREUmBRO7BPwA8BfSLby8GvtnSSWZ2v5mtNbN3m9hvZvYbM1tiZm+b2REN9o03sw/i+76bQIydVn0PXtPViohIB0okwfd290eAWgB3rwYSyVYPAOOb2T8BGBL/czXwOwAzCwN3x/cfBlxsZocl8HmdUn0PXgvOiIhIB0okwW81s17EpqfFzI4BtrR0krvPAzY2c8hEYKrHvAR0N7N9gdHAEndf6u6VwLT4sV1STjSW4NWDFxGRjpTIKPpvERs9f6CZvQD0AS5Iwmf3B5Y32F4RL2us/OgkfF5KRMIhMiKh4O/Bb90AH/wbtqxo3XnVFbBtPWxdD1vXwfbNSQ9t9Pbt8HZ20uvd26gdk0PtmBxqxzYa+20Y9cUO+ahERtG/bmYnAIcABnzg7lUtnJYIa+zjmilvvBKzq4ld4qewsJCSkpIkhBZTXl6elPoyrJYPl31KScma9gfVQLRyC702vMI+a+fTY9NbWOwuSqvUWoSqaAGVGd2oihZQHdkXt+ROqVudXUVZJJrUOvdGasfkUDsmh9qxbdZ89BkbN5fUbycrzzSmyQRvZuc1setgM0vGcrErgIENtgcAq4CMJsob5e5TgCkARUVFXlxc3M6wdiopKSEZ9RW89Czde/ekuHhU2ytxh0VPwicLYO17sO59KI//YOi+P4y5DoadB31HgDX2G6lxISAz/icoyWrHvZ3aMTnUjsmhdmybwt22g2zH5nrwjwJvxv/Arj3rZCwX+yTwDTObRuwS/BZ3X21m64AhZjYYWAlMAjrmekZAcjPD7XsOvqIMnrwWFk6HaA70OQQOOgX6HAqDxkC/I1qV1EVEJP01l+DPBy4CRgBPAH919yWJVmxmfwWKgd5mtgL4IRAFcPd7gRnA6cASYuvNT47vqzazbxB7NC8M3O/uC1v3tTqXnIxI2+/Br1kIj3wJNi6DU26D466HkFalExGR5jWZ4N19OjDdzHKJjWL/RXw0/ffcfW5LFbv7xS3sd+DrTeybQewHQFrIzQy3bRT9Gw/Bv/8Lsgrg8n/GeusiIiIJSGQU/Q5ij8WVAvvRYE14SUxORoQN5dsSP6G2Bp7+Prx0DwweC+f/EfL2CS5AERFJO80NsjsRuJjYc+mzgV+7+6sdFVg6yc1oRQ++ogwe/Qp8+BQc8zUYdzuEwsEGKCIiaae5Hvwc4G1gPrFB1l8ysy/V7XT36wKOLW3kZEYSWw9+83J4+KLYCPkz7oKjNOW/iIi0TXMJfnKHRZHmcjPCLa8Hv+kTuO8UqN4Bl/wdDjq5Y4ITEZG01Nwguwc7MpB0lpMRYXtVDTW1TjjUyONstTUw/Rqo2g5XPgP7fK7jgxQRkbSi5606QG58wZntVU304l/8P/j0RTj9DiV3ERFJCiX4DpBTt2RsYyvKffYOPHs7fO5sGNnsk4UiIiIJU4LvAHU9+D1G0lftgMevhpyecOavNBudiIgkTasSvJm9HlQg6ayuB7/HbHbP/jg2r/zEuyG3VwoiExGRdNXaHry6mG2QW3eJvmEPfsWrsOBuKPoKDDk1RZGJiEi6am2C/3cgUaS5nPgl+q0N78HPuxOye8Cp/52iqEREJJ21KsG7+/eDCiSd7dGD/+xdWDwLjr4GMvNSGJmIiKQrDbLrADkZu/Xg5/8SMvJg9FUpjEpERNKZEnwHyM1s0IPfuBQWPg5Fk2Oj50VERALQYoI3szPNTD8E2qG+B19ZDS/8BkIROKbRlXJFRESSIpHEPQn40MzuMDNNs9YGmZEQ4ZBhZWvgzYdg1Beh276pDktERNJYiwne3S8FDgc+Av5kZgvM7Gozyw88ujRhZuRkhBmx4iGorYYx16c6JBERSXMJXXp391LgMWAasC9wLvC6mV0bYGxppW90B0XrHoeh50LPA1IdjoiIpLlE7sGfZWbTgWeBKDDa3ScAI4FvBxxf2riaR8ms3Q7H35DqUEREZC/Q3HrwdS4Efunu8xoWuvs2M/tyMGGlmeUvc37VP3k2/2xO6js81dGIiMheIJFL9D8EXq7bMLNsMxsE4O5zAoorfVTtgCe+zoZwHx7MuSLV0YiIyF4ikQT/d6C2wXZNvEwSMfdnsH4xU3t/i43VmamORkRE9hKJJPiIu1fWbcTfZwQXUhpZ9Qa88Gs4/FKWFRy952pyIiIiAUkkwa8zs7PrNsxsIrA+uJDSRHUlPPENyO0D4/6H3IwI2ypqWj5PREQkCRIZZHcN8JCZ/ZbYcrHLgS8FGlU6ePn3sOZduHgaZHcnJ3OlevAiItJhWkzw7v4RcIyZ5QHm7mWJVm5m44FfA2HgPnf/6W77bwQuaRDL54A+7r7RzD4Gyojd869296JEPzflamvgP7+HQZ+HQyYAsRXltlXW4O6YWYoDFBGRdJdIDx4zOwMYCmTVJSd3b3YhczMLA3cDpwIrgFfM7El3f6/uGHe/E7gzfvxZwA3uvrFBNSe6e9e7HbB4FmxZDqf9pL4oJzNMTa1TUV1LVjScwuBERGRvkMhEN/cCFwHXErtEfyGwfwJ1jwaWuPvS+MC8acDEZo6/GPhrAvV2fi9PgW794ZDT64v2WBNeREQkQIkMsjvO3b8EbHL3HwHHAgMTOK8/sfv1dVbEy/ZgZjnAeGLT4dZx4Gkze83Mrk7g8zqHdR/A0hIo+jKEd14gyYsvGVu6vSpFgYmIyN4kkUv0O+Kv28ysH7ABGJzAeY3daPYmjj0LeGG3y/Nj3H2Vme0DPGNm7+8+mx5APPlfDVBYWEhJSUkCoSWmvLy81fUd9OEU+lmEBTsOoqrBuSvXxQbYzX7+JQ7qsXddom9LO8qe1I7JoXZMDrVjcgTZjokk+H+aWXdi98pfJ5ak/5DAeSvYtac/AFjVxLGT2O3yvLuvir+ujc+FPxrYI8G7+xRgCkBRUZEXFxcnEFpiSkpKaFV9O0rhxbkw/ALGjDtnl129V27hrtfms9/BQyke2jdpMXYFrW5HaZTaMTnUjsmhdkyOINux2Uv0ZhYC5rj7Znd/jNi990Pd/dYE6n4FGGJmg80sg1gSf7KRzygATgCeaFCWW7ccrZnlAuOAdxP8Tqnz9t+gshxG73lHoWdubG6gDVsr99gnIiKSbM324N291sx+Qey+O+5eAVQkUrG7V5vZN4CniD0md7+7LzSza+L7740fei7wtLtvbXB6ITA9PmI/Ajzs7rMS/1op4B4bXNf/SBhw5B676xL8RiV4ERHpAIlcon/azM4HHnf3pu6hN8rdZwAzdiu7d7ftB4AHditbSmw52q5j2VxYvxjO/X2ju7OiYfIzI6wvT+j3kYiISLskkuC/BeQC1Wa2g9jgOXf3boFG1tW89iBk94TDzmnykJ55GWwoVw9eRESCl8hMdvkdEUiXVlEOH8yEwy+BaFaTh/XKzWDDVvXgRUQkeC0meDMb21h5Y4+s7bU+mAHV22HYBc0e1isvk+Ubt3VQUCIisjdL5BL9jQ3eZxF7XO014KRAIuqK3nkUug2AgUc3e1iv3AzeXL65Y2ISEZG9WiKX6M9quG1mA4E7Aouoq9m2ET6aA8d8DULNTwzYKy+DjVsrqa11QiEtOCMiIsFJZKra3a0AhiU7kC7rvSegthqGN395HqBXbiY1tU7pDk1XKyIiwUrkHvz/sXOK2RAwCngrwJi6lncfg15DoO+IFg/tlRd7Fn59eSXdczKCjkxERPZiidyDf7XB+2rgr+7+QkDxdC2lq+Dj+VD8XUhgjfdeuZkAbCiv4KB98oKOTkRE9mKJJPhHgR3uXgOxdd7NLMfdNRx84XTAWxw9X6euB6/pakVEJGiJ3IOfA2Q32M4GZgcTThfzzqOw70jofVBChyvBi4hIR0kkwWe5e3ndRvx9TnAhdREbPoJVryfcewfoEb/vvkHT1YqISMASSfBbzeyIug0zOxLYHlxIXcS7j8Veh52X8CnRcIjuOVFNVysiIoFL5B78N4G/m1ndWu77AhcFFlFXsehJGHgMFAxo1Wm9cjO0opyIiAQukYluXjGzQ4FDiC008767790Pcm9eDp+9A6f+d6tP7ZWbqRXlREQkcIk8B/914CF3fze+3cPMLnb3ewKPrrNaHF+a/pDTW31qr7wMPlxb3vKBIiJ7oYoPP6R05ky2vfwKXlub6nCSrueXLqPb+PEd8lmJXKK/yt3vrttw901mdhWw9yb4D2ZCr4Og95BWn9orL4P/LEvPS/TuzrZXXiHcvTtZBx/c8vG1tWx/4w28qoqcoiIs0vI/x8pPPmHb629AM//hWzRCzujRRPv2bVX86aRyxUqqPv2E7KIiQhnJn1SpdutWtv7nP2Tsvz+ZBx7Y4vFeU8P211+n8tPlSY9lF+EQOUVFZAzY89ZZ7Y4dbF2wgKwFC9i8YWPbP6JHd3KPPZZQdvYe+6pWrmTbq6/i1TVtrr+ryPrg/Xa14+6qVq+mdNZMKpd8BKEQWcOHEcpJw/HcLUxpnkyJJPiQmZm7O8Segwf23mnYKsrg4+dh9NVtOr1nbiabtlVSXVNLJNxxf9FBq163jtW3/pDy554DIOOgA+k2YQLdJkzY5TivrWX7m29ROmsmZbOeonrtWgDCPXqQP24c3SZMIOeoIiwcrj+ncsUKymbNonTGTHa8917CMWUfeSTdJkwgf9ypRPfZJwnfsvPz2lo2/fnPrL3rl3hFBaH8fPJPOYVup08g95hjsGi0zXXXbttG+bx5lM6YSfncuXhF7FZT5pAhdDt9Avnjx5M5ePAusWx/4w1KZ86i7KmnqF63rt3fL1FZw4fH/u5PPomKjz6idOYsyufMoXbbNgqA1e2s33JyyC8uptvpE8g85BDK5syhbOYstr+190zymYx23IUZOUVF9Lj1i3Q79VQiffoks/a9ksXzdtMHmN0JDALuJTZl7TXAcnf/r8Cja6WioiJ/9dVXWz4wQSUlJRQXF+9a+N4T8MiX4IoZMGhMq+ucuuBjbn1iIa987xT65GcmJ9AUK50xg89+9N/Ubt9On+uvw7KzKZsxk22vvQbuuBn18/zF/71ZRga5Yz9PtwkTsIwMymbOoqykBN8Wnz+p4cyA8XOyRoyg24QJ5I39PKGsrCbjqSkvp/zZZymdOYuKxYv3rK8RmYccQrfx4+k2YTwZ+++Pu1OxeDGlM2M/RLy6uv4HSNawoVgCMxfWbNlC2ezZlM6YydaXX4bq6vp9FomQc+wxdBs/gfxTTibcrRteVcXWl16qT6AZAwfGEudppxHt25eS557j6J49KZ0xk7JnnsGysug2/jS6TZhA5pAhVC5fzuqbb2Hbq6+SV1xMwfnnUT7nWcrmzKG2rCyhdmhW/O8h3Kc33cadRv4pJ1Px0VJKZ85k+2uv7Vl/3d91ZiZ5Y8fS7fQJZA0f0a4QWlK7fTvlJSWUzpzFjoUL68vDBQXkjzuV/NPG8/qazzj2mGPa/BmVn34a+9Hy9NPUbN5cX5552OfoNn4CecUnEM7Nbc/X6BIWvPRSu9pxd6HcXMLduyetvq6i0TzTCmb2mrsXNbovgQQfAq4GTiE2yO5p4A/u3ulujnRIgp9+DXwwk63H/4XqTVsoOOvMVtX577dX8/WHX2fWNz/PoX27JS3WoHllJeUvvsjW5+fjlTsHCVatWs3WF14ga8QI+v30f8k84ICd+9aspWzObD569TUGDdq/vjxj8GDyTjyRcN6u0/XWbt9O+dx5VCz+YJfycEEBeSefQsaA/q2Ou2LJEspLSqjd1vTEi15dw7ZXXmH7G28AkHXYYdTu2EHl0qUQDpN79NFYNEr5iy9CVRXRgQPjtxTCTdZZ9dkatr70Uv3xeScW7/J9a0rLKH/2WapWrcKiUbKPOIKK99+nZssWQvn55H3+81R8vIyK9xYBkD1qFOWffkp440YsGiX3+OOp3b6dbS+/DLW1ZBx4IFWrV2OhEIU330zBeefW/wipraxk6/wX2PHuu+xcVqINQmFyjjqKnKIjd7nCAlC1Zg1lz8ymZuOGXcozBh8Q/7vu+IRX+emnlM+dR8ag/Xe5etHe/6HW8aoqtr78MpUfLSX388fvcvVib5CsdtzbBZngExlFX0us935vvLLjgf8Dvt7miLqq2hpY/BQ+ZByf3f4TKpcvJ+vQQ8gckvi9+J65sbsbGxt5Fr7y44+J9u/f6GVUd6dy2cfUlm7ZpTxj8GDCBQWt/CKNq62ooOKDD3a5v129aRNlz8ymbPZsaktLCeXkEGqYmCNh+txwA72+8uU97qFHC/eh5xe/yNv9+tEngX/Aoexsuo0/DcaflpTvA5B50EFkHpTYTINVq1ZR+tTTlD39NJFu3ej5pS+RP+5UIj17AnU98jmUzpzJ1heaX44hlJsbG0wz4XSyhh7WaI/fv3cLO955h9KZs9g6fz65Y8fSbcIEco8fU3/fvGLZMsqeeoqy2XOo7tePAd+5kfyTTiLcLfbjsHrdOkqfeYayWU+RecBgCm++mWi/frvGkpFB/kknkn/SiQm1Q1tECwvpeeklgdXfFhn77UfPyy4NrH6LRskbMwbGtP5KnkhHSOQePGY2CriY2PPvy4DHA4yp81r+MmzfSEXOEVR+PB+Az/7nJ+z3p/sTumQL0LtuRbndnoVf/4c/sO4Xd8V6q6eeEvsf/dFHU/nxx5TOnEXpzJmxHuXuIhFyxxy381Jvfn6rvlJtZSVbX3iB0pkzKZ/zLLVbt+5xTCg/n/yTT6bbhPHkHnssFsCgrc4g2q8fvSZfQa/JVzS6P1xQQPfzz6P7+YlPbtQcMyN7xAiyR4yAm77T6DGZgweTec019L7mGkpKSui+2w+lSJ8+9PziF+n5xS8mJSYRSR9NJngzOxiYRCyxbwD+RuySfnDdgM7ugxkQilL2/jYwo/dXv8r6e+6h7KmnYz3PBPTK27miXJ0Nf7yfdb+4i7xTTiaUk0PZzFlsefQxLDsb3749NvjkqKPoceklZAwcWH+e18QuLZfNnMXquTfz2a1RovvtB624x1m9Zi21ZWWECgrInzCevLFjdxkdbBmZZB8+KpCR2CIiEpzmevDvA88DZ7n7EgAzu6FDouqsFs+CQcdT9vcScoqK6P31r1H27LOs+dnPYgO/Eniko3t2lJBRP5vdxgcfZO2dd9Lt9An0u+MOLBKJPc4zfz7lz8+PjVA+bVyTI0rzi4vZ59vfZsfbb1M66ymqVq1q9Lim5Bx+BPmnnhLrmbdjhLWIiHQuzSX484n14J8zs1nANFrVN0wz65fA+sVU9D+Pig+nUvj972PhMH2//z0+ufQy1v/hD+xz/fX1h7t77HJ3I4MY+0dr2LJ+Mxun/pk1//tT8k87rT65A4Syssg/5RTyTzklodDMjOyRI8keOTI531VERLq8JhO8u08HpptZLnAOcANQaGa/A6a7+9MdE2InsXgmAGXLYpv5p54KQE5REd3OOouNf7yf7uedh+/YQenMmZTOnEXlsmWNVjUl/roGyD/1FPr//M6EJnkRERFJVCKj6LcCDwEPmVlP4ELgu8Qel2uWmY0Hfg2Egfvc/ae77S8GniA2cA/gcXf/70TO7VDusHA67DOU0qf+Q/YRRxAt3Dlxyj7f/jblc+awbOI5scexQiFyRo+m4NxzsYw9L3v/5aVPqK5xvjJ+OAVnnaVL4yIiknSt6ja6+0bg9/E/zYrPeHc3cCqwAnjFzJ50992nInve3c9s47kdY/EsWPkaFUf+gIoP/kjhzd/dZXe0cB8Kv/c9Sv/9b/JOOZlu48YR6d27yeo+zHidhatK+a/ziwMOXERE9lZBXhceDSxx96UAZjYNmAgkkqTbc25y1dbA7B9Br4MoWxmbrCN/3Lg9DmvN41O987SinIiIBCvIydD7Aw1XllgRL9vdsWb2lpnNNLOhrTw3eG9Ng3WL4KQfUPb0bLJHjiS6777tqrJXbgZlO6qp2AsWpBARkdQIsgff2Ij73YeUvw7s7+7lZnY68A9gSILnxj7E7GpiU+lSWFhISUlJW+Pdw7bSjexY8AMq84fw1sIqer/3HmXnn8/H7fyM9SurAJgxey49stJnwZmmlJeXJ/XvZW+ldkwOtWNyqB2TI8h2DDLBrwAGNtgeAOzykLa7lzZ4P8PM7jGz3omc2+C8KcQHphcVFXky50b+aOr1ZFVsIGvSgxz27GLWAqO++tU2zYne0I53P+PB915jyPAjGdY/OdPMdmaaszo51I7JoXZMDrVjcgTZjkEm+FeAIWY2GFhJ7Jn6XebTNLO+wBp3dzMbTeyWwQZgc0vnBm77ZgYsfZTSiqMovevvlM+dS9bw4e1O7rBzutoNW9NzXXgREUm9wBK8u1eb2TeAp4g96na/uy80s2vi++8FLgC+ambVwHZgUnzd+UbPDSrWPWKvrmbVV75A2Vv5eM1Kwn0q6P6FL9Dz8i8lpf66BWc2aKCdiIgEJNDZVdx9BjBjt7J7G7z/LfDbRM/tKEYNvuFTMg7rTuGNvyHnyD2Xx2yPuvnoN6oHLyIiAdH0aY2JZDJg+ou8+PxcDhg9OunVd8uKEA0b6xtZMlZERCQZ0n8Id1vl9KQys0cgVZsZPXMzdIleREQCowSfIr1yM3WJXkREAqMEnyK98jJYrwQvIiIBUYJPkV66RC8iIgFSgk+RXnm6RC8iIsFRgk+RXnkZbKusYVtldapDERGRNKQEnyK9c2PPwm/Qo3IiIhIAJfgU6Z0fm81ubZnuw4uISPIpwafI4N55AHy0rjzFkYiISDpSgk+R/XrmkBEJ8eGaslSHIiIiaUgJPkXCIePAPnl8uFY9eBERST4l+BQask8eH65RghcRkeRTgk+hgwvzWLl5O+UVelRORESSSwk+hYYU5gOwRJfpRUQkyZTgU2jIPrGR9BpoJyIiyaYEn0L1I+nVgxcRkSRTgk+hSDjEAb1zWawevIiIJJkSfIodXJivkfQiIpJ0SvApNmSf2Ej6rRpJLyIiSaQEn2IaSS8iIkFQgk+xgwtjI+l1H15ERJJJCT7F9uuZQ0Y4pB68iIgklRJ8ikXCIQ7oo5H0IiKSXErwncCQwnw9Cy8iIkkVaII3s/Fm9oGZLTGz7zay/xIzezv+50UzG9lg38dm9o6ZvWlmrwYZZ6odvE8eKzZpJL2IiCRPYAnezMLA3cAE4DDgYjM7bLfDlgEnuPsI4MfAlN32n+juo9y9KKg4O4Mh8YF2H61TL15ERJIjyB78aGCJuy9190pgGjCx4QHu/qK7b4pvvgQMCDCeTqvuUbnFmvBGRESSJMgE3x9Y3mB7RbysKV8BZjbYduBpM3vNzK4OIL5OY//4SPoP12qgnYiIJEckwLqtkTJv9ECzE4kl+OMbFI9x91Vmtg/wjJm97+7zGjn3auBqgMLCQkpKStodeJ3y8vKk1tecfbKdl977hJLsNR3yeR2pI9sxnakdk0PtmBxqx+QIsh2DTPArgIENtgcAq3Y/yMxGAPcBE9x9Q125u6+Kv641s+nELvnvkeDdfQrxe/dFRUVeXFyctC9QUlJCMutrzuGr3+CNTzd12Od1pI5sx3SmdkwOtWNyqB2TI8h2DPIS/SvAEDMbbGYZwCTgyYYHmNl+wOPAZe6+uEF5rpnl170HxgHvBhhryg2Jj6TfVqmR9CIi0n6B9eDdvdrMvgE8BYSB+919oZldE99/L3Ar0Au4x8wAquMj5guB6fGyCPCwu88KKtbOoG7K2iVryxkxoHtqgxERkS4vyEv0uPsMYMZuZfc2eH8lcGUj5y0FRu5ens6G9S8A4MWPNijBi4hIu2kmu05iQI8cRg3szhNv7jFMQUREpNWU4DuRc0b1Y9HqUs1LLyIi7aYE34mcMaIf4ZDxjzdWpjoUERHp4pTgO5E++ZmMOag3T7y5itraRqcMEBERSYgSfCdzzqh+rNy8ndc+3dTywSIiIk1Qgu9kxg3tS1Y0xBNv6jK9iIi0nRJ8J5OXGeHUw/ry77dXU1VTm+pwRESki1KC74TOGdWPTduqmLd4XapDERGRLkoJvhMae3AfeuRE+YeeiRcRkTZSgu+EouEQZ4zYl2fe+4zyCs1NLyIiracE30mdM6o/O6pqNdhORETaRAm+kzpy/x4cuX8PfvnMYrZsr0p1OCIi0sUowXdSZsaPzh7Khq2V/PKZxS2fICIi0oASfCc2rH8Blxy9H1MXfMyi1aWpDkdERLoQJfhO7tvjDqEgO8oPn1yIu6avFRGRxCjBd3LdczK48bRDeXnZRp58S4/NiYhIYpTgu4CLjhrI8P4F/GTGIj02JyIiCVGC7wLCIeNHE4eyprSC6//6BluV5EVEpAVK8F3EEfv14McTh/LcB2u58N4FrN6yPdUhiYhIJ6YE34Vcduwg/nj5UXyyYSvn3P0C767ckuqQRESkk1KC72JOPHQfHv3qcYTNuPDeBUx7+VOqteqciIjsRgm+C/rcvt34xzfGMLRfN777+DuM+9U8/vnWKmpr9RidiIjEKMF3UfvkZ/H3a47l3kuPJBIyrv3rG5z+m+d55NXlrCndkerwREQkxSKpDkDazswYP6wvpx5WyL/eXsWvZ3/Idx59G4BD++Yz9uA+HHtgL0b0L6BXXmaKoxURkY6kBJ8GwiFj4qj+nDWiH4s+K2Xe4vXMW7yOP72wjCnzlgLQv3s2IwYUMLRfNw7ok8cBfXIZ1CuXrGg4xdGLiEgQAk3wZjYe+DUQBu5z95/utt/i+08HtgFXuPvriZwrewqFjKH9Chjar4CvFh/I1opq3l6xhXdWbo6/bmHmu5/VH28G/QqyGdgzm4E9chjYM4f+3bPplZdBz9wMeuRk0D0nSl5mhNhflYiIdBWBJXgzCwN3A6cCK4BXzOxJd3+vwWETgCHxP0cDvwOOTvBcaUFuZoRjD+zFsQf2qi/bWlHNsvVb+WhdOUvXbeXjDVtZvnEbJYvXsa6sotF6zCAvM0J+ZoS8rAjZGRGyoyFyMiJkR8NkRkNkRsJkxV8zIiEyIyEywiEyIiGWLa9i/WsryIiEyAgb0XCISDhENGREwiEiYSMair+GjXAoRCRkhEIWe7W68ti5IYu9Dxn64SEi0oQge/CjgSXuvhTAzKYBE4GGSXoiMNVjq6i8ZGbdzWxfYFAC50ob5GZGGNa/gGH9C/bYt6OqhlWbt7NpWyWbtlaxcVslm7dVUr6jmtId1ZRXVFO2o4rtVbXsqKxhbdkOtlXWUFFVS0V1LRXVsfeVjT22t/CtQL5PyIgne6t/rSvbvdwaHGtG/bGxVyMUIr5vZ7lB/fF15+x83fU4qzuOXY+1BvtD9fsbP8eIxQF7lq9aVcFzW96t/1FTV173G6f+2HjddYXWSF0Nz6nbaLh/Z/3Q4JBdflA1PJbdj2ukrt1Zg8/d/dxd9u9WThPn7fzKTZwX98GKKta88unO2BuLrYlYd9+/s10aj2G3kJvUVP3Nnd/SZ7RcR/NBtVTfwrXVVL23punzE6iz5c9s6YR27U6og9ByHS2dv+sBg/vk0r97doufmwxBJvj+wPIG2yuI9dJbOqZ/gudKkmVFwxzQJ6/d9bg7lTW1VFbH/syb/wJHHnVMfVlVTS3VtbVU1TjVNU5VbS3VNU51TS1VtU5NbS01tdS/VtfWUlMbO7a64X53amu9/rXWnZpa4q87y2tqHYedx3gsRnfqj/N42e77a+uOc8droYZaahuUx87ZuV0bX/HPHZzYvrq6nJ3HO3Xnx/c3OCdWD8Cu51VWVRNZt6r+eOL76tq8YR07Y6g7bte64sXstQsUvvtOqiNID6+/muoIupxbzzyMLx8/uEM+K8gE39jvmt3/d9LUMYmcG6vA7Grg6vhmuZl9kHCELesNrE9ifXsrtWNyqB2TQ+2YHGrHNvjKz+Aruxa1tx33b2pHkAl+BTCwwfYAYPf1Tps6JiOBcwFw9ynAlPYG2xgze9Xdi4Koe2+idkwOtWNyqB2TQ+2YHEG2Y5AT3bwCDDGzwWaWAUwCntztmCeBL1nMMcAWd1+d4LkiIiLShMB68O5ebWbfAJ4i9qjb/e6+0Myuie+/F5hB7BG5JcQek5vc3LlBxSoiIpJuAn0O3t1nEEviDcvubfDega8nem4KBHLpfy+kdkwOtWNyqB2TQ+2YHIG1o/leO4xWREQkfWmxGRERkTSkBN8IMxtvZh+Y2RIz+26q4+kqzGygmT1nZovMbKGZXR8v72lmz5jZh/HXHqmOtSsws7CZvWFm/4pvqx1bKT551qNm9n783+WxasfWM7Mb4v9Nv2tmfzWzLLVjy8zsfjNba2bvNihrst3M7OZ43vnAzE5r7+crwe+mwTS5E4DDgIvN7LDURtVlVAP/5e6fA44Bvh5vu+8Cc9x9CDAnvi0tux5Y1GBb7dh6vwZmufuhwEhi7al2bAUz6w9cBxS5+zBiA58noXZMxAPA+N3KGm23+P8rJwFD4+fcE89HbaYEv6f6KXbdvRKomyZXWuDuq+sWC3L3MmL/M+1PrP0ejB/2IHBOSgLsQsxsAHAGcF+DYrVjK5hZN2As8EcAd690982oHdsiAmSbWQTIITYvidqxBe4+D9i4W3FT7TYRmObuFe6+jNjTZaPb8/lK8HtqavpcaQUzGwQcDvwHKIzPb0D8dZ8UhtZV/Ar4DtBwYn+1Y+scAKwD/hS/1XGfmeWidmwVd18J/Bz4FFhNbL6Sp1E7tlVT7Zb03KMEv6eEp8mVxplZHvAY8E13L011PF2NmZ0JrHX311IdSxcXAY4AfufuhwNb0WXkVovfI54IDAb6Ablmdmlqo0pLSc89SvB7SmSKXWmCmUWJJfeH3P3xePGa+CqBxF/Xpiq+LmIMcLaZfUzsFtFJZvYX1I6ttQJY4e7/iW8/Sizhqx1b5xRgmbuvc/cq4HHgONSObdVUuyU99yjB70nT5LaRxdZe/COwyN3varDrSeDy+PvLgSc6OrauxN1vdvcB7j6I2L+/Z939UtSOreLunwHLzeyQeNHJxJacVju2zqfAMWaWE/9v/GRi42vUjm3TVLs9CUwys0wzGwwMAV5uzwdpoptGmNnpxO6B1k2T+z+pjahrMLPjgeeBd9h57/gWYvfhHwH2I/Y/iwvdffeBJ9IIMysGvu3uZ5pZL9SOrWJmo4gNVMwAlhKbDjuE2rFVzOxHwEXEnpR5A7gSyEPt2Cwz+ytQTGzFuDXAD4F/0ES7mdn3gC8Ta+dvuvvMdn2+EryIiEj60SV6ERGRNKQELyIikoaU4EVERNKQEryIiEgaUoIXERFJQ0rwIns5M6sxszcb/EnabG9mNqjhSloi0nEiqQ5ARFJuu7uPSnUQIpJc6sGLSKPM7GMz+5mZvRz/c1C8fH8zm2Nmb8df94uXF5rZdDN7K/7nuHhVYTP7Q3w98afNLDt+/HVm9l68nmkp+poiaUsJXkSyd7tEf1GDfaXuPhr4LbHZHYm/n+ruI4CHgN/Ey38DzHX3kcTmfF8YLx8C3O3uQ4HNwPnx8u8Ch8fruSaYryay99JMdiJ7OTMrd/e8Rso/Bk5y96XxRYQ+c/deZrYe2Nfdq+Llq929t5mtAwa4e0WDOgYBz7j7kPj2TUDU3W83s1lAObGpO//h7uUBf1WRvYp68CLSHG/ifVPHNKaiwfsado79OQO4GzgSeM3MNCZIJImU4EWkORc1eF0Qf/8isVXuAC4B5sffzwG+CmBmYTPr1lSlZhYCBrr7c8B3gO7EFi8RkSTRL2YRyTazNxtsz3L3ukflMs3sP8Q6AxfHy64D7jezG4F1xFZoA7gemGJmXyHWU/8qsLqJzwwDfzGzAsCAX7r75iR9HxFB9+BFpAnxe/BF7r4+1bGISOvpEr2IiEgaUg9eREQkDakHLyIikoaU4EVERNKQEryIiEgaUoIXERFJQ0rwIiIiaUgJXkREJA39P8i20PVsllFiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=pd.DataFrame(history.history)\n",
    "results.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel (\"Epochs\")\n",
    "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
    "plt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "# categorical_accuracy es el training accuracy\n",
    "# val_categorical_accuracy es el validation accuracy\n",
    "# loss es el training loss\n",
    "# val_loss es el validation loss\n",
    "\n",
    "# Overfitting:\n",
    "# Por un lado la Accuracy de los datos de entrenamiento aumenta con las epochs,\n",
    "# mientras que la Accuracy de los datos de validación disminuye o se mantiene constante a lo largo de las epochs. \n",
    "# La Loss de los datos de validación alcanza su mínimo después de pocos epochs y luego empieza a subir, \n",
    "# mientras que la Loss de los datos de entrenamiento disminuye linealmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 2, 'epochs': 100, 'steps': 13}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.002318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.151356</td>\n",
       "      <td>0.602041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "99  0.002318       1.0  3.151356      0.602041"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set:  1.0\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the training set: \", results.values[-1:][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the development test set:  0.6020408272743225\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the development test set: \", results.values[-1:][0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how the model predicts using the development test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.89, 0.11],\n",
       "       [1.  , 0.  ],\n",
       "       [0.57, 0.43],\n",
       "       [0.01, 0.99],\n",
       "       [0.22, 0.78],\n",
       "       [0.78, 0.22],\n",
       "       [1.  , 0.  ],\n",
       "       [0.99, 0.01],\n",
       "       [1.  , 0.  ],\n",
       "       [0.02, 0.98],\n",
       "       [0.81, 0.19],\n",
       "       [0.  , 1.  ],\n",
       "       [0.25, 0.75],\n",
       "       [0.23, 0.77],\n",
       "       [0.88, 0.12],\n",
       "       [0.28, 0.72],\n",
       "       [1.  , 0.  ],\n",
       "       [0.03, 0.97]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions=model.predict(X_dev).round(2) \n",
    "dev_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_rounded_predictions=np.round(dev_predictions)\n",
    "indices = np.argmax(dev_predictions,1)\n",
    "for row, index in zip(dev_rounded_predictions, indices): row[index]=1\n",
    "dev_rounded_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True False False  True  True  True  True False\n",
      " False  True  True  True False  True False  True  True False  True False\n",
      " False False  True False False False]\n"
     ]
    }
   ],
   "source": [
    "dev_correct_predictions = np.equal(np.argmax(dev_rounded_predictions,1),np.argmax(y_dev,1))\n",
    "print (dev_correct_predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 59, False: 39})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter (dev_correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model if it is better than others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "model.save('./Modelos/CNN_model1_PARES_DIA31.h5') # Change the name in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnew_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\\n\\nimport numpy as np\\n\\n# Verify state\\nnew_predictions = new_model.predict(X_dev)\\nnp.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\\n\\n# Note that the optimizer state is also preserved:\\n# you can resume training where you left off.\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract\n",
    "\"\"\"\n",
    "new_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Verify state\n",
    "new_predictions = new_model.predict(X_dev)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is also preserved:\n",
    "# you can resume training where you left off.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Final Test\n",
    "\n",
    "#### 10.1 - Load the final test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "def predictWithModel(model, X_test, y_test, task1, task2, task3=\"\"):\n",
    "    model.evaluate(X_test, y_test)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_rounded_predictions=np.round(test_predictions)\n",
    "    indices = np.argmax(test_predictions,1)\n",
    "    for row, index in zip(test_rounded_predictions, indices): row[index]=1\n",
    "    print(test_rounded_predictions[:20])\n",
    "    \n",
    "    # ACCURACY:\n",
    "    test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(y_test,1))\n",
    "    print()\n",
    "    print(test_correct_predictions)\n",
    "    print(type(test_correct_predictions))\n",
    "    final_test_prediction_results=Counter(test_correct_predictions)\n",
    "    \n",
    "    success = np.mean(test_rounded_predictions == y_test)*100\n",
    "    \n",
    "    return final_test_prediction_results, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 83ms/step - loss: 5.3045 - accuracy: 0.4286\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "[ True False  True False False  True  True False False False False  True\n",
      " False  True  True  True False False False  True  True  True  True  True\n",
      " False  True False False False False False  True  True  True False False\n",
      " False False False False  True False False False  True  True False False\n",
      "  True]\n",
      "<class 'numpy.ndarray'>\n",
      "Counter({False: 28, True: 21}) 42.857142857142854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#X_test, y_test = readRegisterAndReturnXy(u, total_records, 122, 123, 127)\n",
    "accuracy, success = predictWithModel(model, X_test, y_test, 402,404)\n",
    "print(accuracy, success)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
