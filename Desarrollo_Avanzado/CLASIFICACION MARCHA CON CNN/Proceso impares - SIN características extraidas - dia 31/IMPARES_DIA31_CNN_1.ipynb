{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4: Clasificación con CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con la arquitectura anterior: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primero\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambios realizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevos resultados: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "    \n",
    "    TRAIN                   DEV\n",
    "    loss       accuracy     val_loss    val_accuracy\n",
    "    0.001832\t1.0\t        2.326018\t0.602041\n",
    "    \n",
    "Por tanto: \n",
    "\n",
    "    E = 1 - Accuracy\n",
    "    Etrain = 1 - 1.0\t = 0\n",
    "    Etest = 1 - 0.602041 = 0.397959\n",
    "    \n",
    "    Bias = Etrain - Ehuman = 0\n",
    "    Variance = Etest - Etrain = 0.397959\n",
    "\n",
    "El bias es muy bajo pero la varianza es muy alta (40%). Para ello habrá que o regularizar, o cambiar la arquitectura (menos neuronas => Mejor varianza, más capas => mayor abstracción), o añadir más datos (cosa que no es posible). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Signal libraries\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROutput:\n",
    "    def __init__(self, task, data):\n",
    "        self.task = task\n",
    "        self.data = data\n",
    "        \n",
    "class OutTaskData: \n",
    "    def __init__(self, task, data): \n",
    "        self.task = task\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "# Primero leemos los registros\n",
    "def read_outputs(rec):\n",
    "    '''read_outputs(\"userS0091f1.mat\")'''\n",
    "    mat = sio.loadmat(rec)\n",
    "    mdata = mat['session']\n",
    "    val = mdata[0,0]\n",
    "    #output = ROutput(np.array(val[\"task\"]), np.array(val[\"data\"]))\n",
    "    output = ROutput(np.array(val[\"task_EEG\"]), np.array(val[\"data_EEG\"]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Perceptron\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "task1 = 402 # SE PUEDE CAMBIAR\n",
    "task2 = 404 # SE PUEDE CAMBIAR\n",
    "task_OneHotEnconding = {402: [1.,0.], 404: [0.,1.]}\n",
    "user = 'W29' # SE PUEDE CAMBIAR\n",
    "day = '0331'\n",
    "folder_day = 'W29-31_03_2021'\n",
    "total_records = 22 # CAMBIAR SI HAY MAS REGISTROS\n",
    "fm = 200\n",
    "electrodes_names_selected = ['F3', 'FZ', 'FC1','FCZ','C1','CZ','CP1','CPZ', 'FC5', 'FC3','C5','C3','CP5','CP3','P3',\n",
    "                             'PZ','F4','FC2','FC4','FC6','C2','C4','CP2','CP4','C6','CP6','P4','HR' ,'HL', 'VU', 'VD']\n",
    "number_channels = len(electrodes_names_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 22\n"
     ]
    }
   ],
   "source": [
    "# Lectura de registros\n",
    "lTaskData = []\n",
    "\n",
    "total_records_used = 0\n",
    "for i_rec in range(1,total_records+1):\n",
    "    i_rec_record = i_rec\n",
    "    if i_rec_record <10:\n",
    "        i_rec_record = \"0\"+str(i_rec_record)\n",
    "    if i_rec % 2 != 0: # Registros impares primero: USUARIO SIN MOVIMIENTO SOLO PENSANDO\n",
    "        record = \"./RegistrosSinProcesar/\"+folder_day+\"/W29_2021\"+day+\"_openloop_\"+str(i_rec_record)+\".mat\"\n",
    "        output = read_outputs(record) # output.task será y, output.data será x\n",
    "\n",
    "        outT = (output.task == task1) | (output.task == task2)\n",
    "\n",
    "        outData = output.data[0:np.shape(output.data)[0], outT[0,:]]\n",
    "        outTask = output.task[0, outT[0,:]]\n",
    "        outTD = OutTaskData(outTask, outData)\n",
    "        lTaskData.append(outTD)\n",
    "        total_records_used+=1\n",
    "\n",
    "print(total_records_used, total_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (8, 31, 5600)\n",
      "y_train: (8, 5600)\n",
      "X_dev: (2, 31, 5600)\n",
      "y_dev: (2, 5600)\n",
      "X_test: (1, 31, 5600)\n",
      "y_test: (1, 5600)\n",
      "WINDOWING & ONE HOT ENCODER:\n",
      "X_train: (392, 31, 300, 1)\n",
      "y_train: (392, 2)\n",
      "X_dev: (98, 31, 300, 1)\n",
      "y_dev: (98, 2)\n",
      "X_test: (49, 31, 300, 1)\n",
      "y_test: (49, 2)\n"
     ]
    }
   ],
   "source": [
    "# Vamos a coger 2 registros para el entrenamiento, 1 para el conjunto dev set, 1 para el test set\n",
    "X_train, y_train, X_dev, y_dev, X_test, y_test = [],[],[],[],[],[] \n",
    "for j in range(0,total_records_used-3): # Cogemos 8 registros para entrenamiento\n",
    "    X_train.append(lTaskData[j].data)\n",
    "    y_train.append(lTaskData[j].task)\n",
    "\n",
    "for j in range(total_records_used-3,total_records_used-1): # Cogemos 2 registros para el dev set\n",
    "    X_dev.append(lTaskData[j].data)\n",
    "    y_dev.append(lTaskData[j].task)\n",
    "for j in range(total_records_used-1,total_records_used): # Cogemos 1 registros para el test set\n",
    "    X_test.append(lTaskData[j].data)\n",
    "    y_test.append(lTaskData[j].task)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "#y_train = np.ravel(np.array(y_train))\n",
    "y_train = np.array(y_train)\n",
    "X_dev = np.array(X_dev)\n",
    "#y_dev = np.ravel(np.array(y_dev))\n",
    "y_dev = np.array(y_dev)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "#y_test = np.ravel(np.array(y_test))\n",
    "\n",
    "print (\"X_train:\",X_train.shape)\n",
    "print (\"y_train:\",y_train.shape)\n",
    "print (\"X_dev:\",X_dev.shape)\n",
    "print (\"y_dev:\",y_dev.shape)\n",
    "print (\"X_test:\",X_test.shape)\n",
    "print (\"y_test:\",y_test.shape)\n",
    "\n",
    "\n",
    "# VENTANEO Y ONE HOT ENCODING \n",
    "window = 300\n",
    "samples_advance = 100\n",
    "\n",
    "# Ventaneo X_train\n",
    "\n",
    "X_train_l = []\n",
    "y_train_l = []\n",
    "for num_X_train in range(np.shape(X_train)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_train)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_train)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_train[num_X_train,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_train[num_X_train, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_train_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_train_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_train_l = np.array(X_train_l)\n",
    "y_train_l = np.array(y_train_l)\n",
    "\n",
    "\n",
    "# Ventaneo X_dev\n",
    "X_dev_l = []\n",
    "y_dev_l = []\n",
    "for num_X_dev in range(np.shape(X_dev)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_dev)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_dev)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_dev[num_X_dev,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_dev[num_X_dev, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_dev_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_dev_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_dev_l = np.array(X_dev_l)\n",
    "y_dev_l = np.array(y_dev_l)\n",
    "\n",
    "# Ventaneo X_test\n",
    "X_test_l = []\n",
    "y_test_l = []\n",
    "for num_X_test in range(np.shape(X_test)[0]):\n",
    "    win_init = int(0)\n",
    "    window_position = 0\n",
    "    \n",
    "    for i in range(np.shape(X_test)[2]): # For each signal registered\n",
    "        win_end = int(win_init + window)\n",
    "        if win_end >= np.shape(X_test)[2]:\n",
    "            break\n",
    "\n",
    "        task = np.unique(y_test[num_X_test,win_init:win_end])\n",
    "\n",
    "        if len(task)==1:\n",
    "        #if task1 in task or task2 in task:\n",
    "            signal_window = X_test[num_X_test, :, win_init:win_end]\n",
    "            \n",
    "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
    "            #X_train_l.append(data_filtered)\n",
    "            X_test_l.append(signal_window)\n",
    "            taskOH = task_OneHotEnconding[task[0]]\n",
    "            y_test_l.append(taskOH)\n",
    "            \n",
    "        win_init += int(samples_advance)\n",
    "\n",
    "X_test_l = np.array(X_test_l)\n",
    "y_test_l = np.array(y_test_l)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_l = X_train_l.reshape((np.shape(X_train_l)[0],np.shape(X_train_l)[1],np.shape(X_train_l)[2], 1))\n",
    "X_dev_l = X_dev_l.reshape((np.shape(X_dev_l)[0],np.shape(X_dev_l)[1],np.shape(X_dev_l)[2], 1))\n",
    "X_test_l = X_test_l.reshape((np.shape(X_test_l)[0],np.shape(X_test_l)[1],np.shape(X_test_l)[2], 1))\n",
    "\n",
    "\n",
    "print(\"WINDOWING & ONE HOT ENCODER:\")\n",
    "print (\"X_train:\",X_train_l.shape)\n",
    "print (\"y_train:\",y_train_l.shape)\n",
    "print (\"X_dev:\",X_dev_l.shape)\n",
    "print (\"y_dev:\",y_dev_l.shape)\n",
    "print (\"X_test:\",X_test_l.shape)\n",
    "print (\"y_test:\",y_test_l.shape)\n",
    "\n",
    "X_train = X_train_l\n",
    "y_train = y_train_l\n",
    "X_dev = X_dev_l\n",
    "y_dev = y_dev_l\n",
    "X_test = X_test_l\n",
    "y_test = y_test_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = X_train.shape[1]\n",
    "OUTPUTS = y_train.shape[1]\n",
    "NUM_TRAINING_EXAMPLES = int(round(X_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int(round(y_train.shape[0]/1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data is displayed to test correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1.63837945e+00],\n",
       "         [ 2.20531940e+00],\n",
       "         [ 1.08166718e+00],\n",
       "         ...,\n",
       "         [-7.69870853e+00],\n",
       "         [-7.50134087e+00],\n",
       "         [-3.70585847e+00]],\n",
       "\n",
       "        [[ 6.15227413e+00],\n",
       "         [ 8.16357422e+00],\n",
       "         [ 5.36804342e+00],\n",
       "         ...,\n",
       "         [-6.46570969e+00],\n",
       "         [-6.51845026e+00],\n",
       "         [-5.20556355e+00]],\n",
       "\n",
       "        [[ 6.65675211e+00],\n",
       "         [ 9.17980576e+00],\n",
       "         [ 8.19011593e+00],\n",
       "         ...,\n",
       "         [-6.55358267e+00],\n",
       "         [-6.37352753e+00],\n",
       "         [-5.62285948e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-4.94387865e-01],\n",
       "         [-1.97431183e+00],\n",
       "         [-8.94389057e+00],\n",
       "         ...,\n",
       "         [ 4.44912243e+00],\n",
       "         [-1.64592183e+00],\n",
       "         [ 1.73675954e+00]],\n",
       "\n",
       "        [[-1.28213561e+00],\n",
       "         [ 1.47745371e+00],\n",
       "         [ 1.70585126e-01],\n",
       "         ...,\n",
       "         [-8.88283825e+00],\n",
       "         [-9.43045998e+00],\n",
       "         [-8.93878365e+00]],\n",
       "\n",
       "        [[ 6.41901970e-01],\n",
       "         [-8.17931294e-01],\n",
       "         [-9.39325094e-01],\n",
       "         ...,\n",
       "         [-8.25282466e-03],\n",
       "         [-8.77431393e+00],\n",
       "         [-3.84023595e+00]]],\n",
       "\n",
       "\n",
       "       [[[ 1.69484978e+01],\n",
       "         [ 1.86464500e+01],\n",
       "         [ 1.24771957e+01],\n",
       "         ...,\n",
       "         [ 4.46837187e+00],\n",
       "         [ 5.84637737e+00],\n",
       "         [ 4.14651108e+00]],\n",
       "\n",
       "        [[ 1.68185482e+01],\n",
       "         [ 1.90246754e+01],\n",
       "         [ 1.47022705e+01],\n",
       "         ...,\n",
       "         [ 4.49282265e+00],\n",
       "         [ 5.42434883e+00],\n",
       "         [ 1.93960619e+00]],\n",
       "\n",
       "        [[ 1.45323267e+01],\n",
       "         [ 1.51867390e+01],\n",
       "         [ 1.08603868e+01],\n",
       "         ...,\n",
       "         [ 4.02501392e+00],\n",
       "         [ 5.23153496e+00],\n",
       "         [ 3.10907316e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.25546122e+00],\n",
       "         [ 7.47265482e+00],\n",
       "         [ 1.13948736e+01],\n",
       "         ...,\n",
       "         [-4.74669695e+00],\n",
       "         [-7.22247779e-01],\n",
       "         [-1.22101569e+00]],\n",
       "\n",
       "        [[ 1.49734278e+01],\n",
       "         [ 1.56853352e+01],\n",
       "         [ 1.22481947e+01],\n",
       "         ...,\n",
       "         [-9.44317722e+00],\n",
       "         [-3.20037031e+00],\n",
       "         [-4.31645393e+00]],\n",
       "\n",
       "        [[ 1.22683535e+01],\n",
       "         [ 9.33251476e+00],\n",
       "         [ 2.12607169e+00],\n",
       "         ...,\n",
       "         [-2.34979177e+00],\n",
       "         [ 6.50495148e+00],\n",
       "         [ 5.06911278e-01]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 5.50050306],\n",
       "         [ 5.6836648 ],\n",
       "         [-5.3074975 ],\n",
       "         ...,\n",
       "         [ 8.19852161],\n",
       "         [15.6428957 ],\n",
       "         [ 9.3330164 ]],\n",
       "\n",
       "        [[ 5.65569592],\n",
       "         [ 2.28644156],\n",
       "         [-3.18987131],\n",
       "         ...,\n",
       "         [ 3.22134876],\n",
       "         [11.0755682 ],\n",
       "         [ 5.50965309]],\n",
       "\n",
       "        [[ 2.44729424],\n",
       "         [ 2.05143237],\n",
       "         [-5.08194828],\n",
       "         ...,\n",
       "         [ 7.54894161],\n",
       "         [14.42216301],\n",
       "         [ 7.48953295]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.43806443],\n",
       "         [-0.49860212],\n",
       "         [-1.9200567 ],\n",
       "         ...,\n",
       "         [ 2.77134609],\n",
       "         [ 6.57677603],\n",
       "         [ 3.73756266]],\n",
       "\n",
       "        [[ 4.81264067],\n",
       "         [ 3.28164649],\n",
       "         [ 2.94088817],\n",
       "         ...,\n",
       "         [ 3.63828754],\n",
       "         [ 8.6048851 ],\n",
       "         [ 3.68720198]],\n",
       "\n",
       "        [[ 6.80233622],\n",
       "         [ 4.83839464],\n",
       "         [ 0.93156183],\n",
       "         ...,\n",
       "         [ 5.38316822],\n",
       "         [ 8.53020191],\n",
       "         [ 7.53892756]]],\n",
       "\n",
       "\n",
       "       [[[-6.26466084],\n",
       "         [-6.15324593],\n",
       "         [-1.10400891],\n",
       "         ...,\n",
       "         [ 4.47097206],\n",
       "         [ 5.17013931],\n",
       "         [ 3.15775967]],\n",
       "\n",
       "        [[-6.07983255],\n",
       "         [-2.69345903],\n",
       "         [-0.67772537],\n",
       "         ...,\n",
       "         [ 2.39768767],\n",
       "         [ 3.21470809],\n",
       "         [-1.28485382]],\n",
       "\n",
       "        [[-1.61589003],\n",
       "         [ 1.27869785],\n",
       "         [ 3.91547132],\n",
       "         ...,\n",
       "         [ 2.43919039],\n",
       "         [ 2.20211935],\n",
       "         [-4.0079093 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.45212984],\n",
       "         [-3.00187922],\n",
       "         [-1.36171377],\n",
       "         ...,\n",
       "         [ 2.13893747],\n",
       "         [ 0.57818264],\n",
       "         [-1.14474118]],\n",
       "\n",
       "        [[-0.57153338],\n",
       "         [ 0.35499391],\n",
       "         [ 0.50478792],\n",
       "         ...,\n",
       "         [ 1.90875089],\n",
       "         [-0.56034398],\n",
       "         [-2.04518533]],\n",
       "\n",
       "        [[ 0.74303365],\n",
       "         [-1.98587632],\n",
       "         [ 2.93099594],\n",
       "         ...,\n",
       "         [ 6.24030733],\n",
       "         [ 4.67267084],\n",
       "         [ 5.08503675]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 300, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 31, 300, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 31, 300, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_epochs = 100 #2000\\n#learning_rate = 0.001\\nbatch_size = 32 #250 \\nn_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\\nrate_dropout = [0.8, 0.4, 0.2, 0.1]\\nweight_decay = 1e-4\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "n_epochs = 100 #2000\n",
    "#learning_rate = 0.001\n",
    "batch_size = 32 #250 \n",
    "n_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\n",
    "rate_dropout = [0.8, 0.4, 0.2, 0.1]\n",
    "weight_decay = 1e-4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Build the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 31, 300, 4)        104       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 300, 4)        500       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 150, 4)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 18002     \n",
      "=================================================================\n",
      "Total params: 18,606\n",
      "Trainable params: 18,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, DepthwiseConv2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import optimizers, regularizers\n",
    "import keras.backend as K\n",
    "#K.set_image_data_format('channels_first')\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "# Convolution2D(filtrosConv1, tamaño_filtro1, padding=\"same\", input_shape=(longitud, altura,3), activation = \"relu\")\n",
    "    # - filtrosConv1 número de filtros que aplicaremos tras la primera convolución, normalmente este tamaño va a aumentando\n",
    "    # tras convoluciones para que aumente la dimensión de profundidad (qué cosas hay en mi imagen)\n",
    "    # - tamaño_filtro1 tamaño espacial del kernel (de los filtros)\n",
    "    # - padding = si es same es que es igual que la imagen, vamos crea una imagen del mismo tamaño con el filtro, si es \n",
    "    # valid es que no hay padding y crea una imagen más pequeña que la imagen (creo)\n",
    "    # - input_shape = longitud y altura, tamaño que usará para convolucionar al entrenar\n",
    "    \n",
    "# CAPA PARA FILTRADO TEMPORAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(1,25), padding=\"same\", activation=\"relu\",input_shape=(31, 300,1 ), kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "# CAPA PARA FILTRADO ESPACIAL\n",
    "model.add(Conv2D(filters = 4, kernel_size=(31,1), padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\"\"\"\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## Siguientes capas convolucionales: \n",
    "model.add(Conv2D(20, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(40, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Conv2D(80, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model.add(Conv2D(160, (3,3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\",kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(96, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "#model.add(Conv2D(192, (3, 3), padding='same',activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\"\"\"\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y_train.shape[1], activation=\"softmax\"))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)        \n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x23cfe615430>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x23cfdd98040>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x23cfb90ba00>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x23cfdf2c8e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x23cfdf1a9d0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "conv2d_1\n",
      "max_pooling2d\n",
      "flatten\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers: print (l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the parameters of a layer can bee accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25, 1, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[0].get_weights()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.1532172 , -0.20849425,  0.0485065 , -0.37119463]],\n",
       "\n",
       "        [[-0.21602999, -0.20849276,  0.0629084 , -0.19164433]],\n",
       "\n",
       "        [[ 0.12295178,  0.4643256 ,  0.2767015 , -0.1720766 ]],\n",
       "\n",
       "        [[ 0.5903148 ,  0.30264047,  0.0805942 ,  0.36152852]],\n",
       "\n",
       "        [[-0.12902272, -0.36615562, -0.3908539 ,  0.41253367]],\n",
       "\n",
       "        [[ 0.3850019 , -0.29160255, -0.13007161, -0.0164095 ]],\n",
       "\n",
       "        [[ 0.2728376 ,  0.0578099 , -0.12600513,  0.00799719]],\n",
       "\n",
       "        [[-0.41857728,  0.47645405,  0.11807712,  0.07278504]],\n",
       "\n",
       "        [[-0.3567477 , -0.03834686,  0.11043587,  0.38229826]],\n",
       "\n",
       "        [[-0.15948437, -0.27717376,  0.19983876,  0.05716303]],\n",
       "\n",
       "        [[-0.10114663, -0.4522165 , -0.2500864 , -0.11178658]],\n",
       "\n",
       "        [[-0.16893   ,  0.20036054,  0.4611704 ,  0.07653406]],\n",
       "\n",
       "        [[-0.47548023, -0.04341074,  0.10631858, -0.20744924]],\n",
       "\n",
       "        [[ 0.44569764, -0.06536909, -0.43447796,  0.13651298]],\n",
       "\n",
       "        [[ 0.5059916 , -0.3362988 ,  0.63893825,  0.62694556]],\n",
       "\n",
       "        [[-0.36358818,  0.4265423 , -0.06362001, -0.1156939 ]],\n",
       "\n",
       "        [[-0.17352669,  0.36728007,  0.07860499,  0.21690549]],\n",
       "\n",
       "        [[ 0.1629417 ,  0.27032506, -0.21446502, -0.06796964]],\n",
       "\n",
       "        [[-0.01419076, -0.07262596,  0.30380896,  0.05667759]],\n",
       "\n",
       "        [[ 0.0762696 , -0.18579666,  0.21584752, -0.1688675 ]],\n",
       "\n",
       "        [[-0.5984499 , -0.21514173,  0.4467872 , -0.20125574]],\n",
       "\n",
       "        [[ 0.4444709 , -0.6369511 ,  0.52667737, -0.09214767]],\n",
       "\n",
       "        [[ 0.33350235,  0.21064672, -0.23773678,  0.05773746]],\n",
       "\n",
       "        [[ 0.6065274 ,  0.33212277, -0.48159194, -0.13617066]],\n",
       "\n",
       "        [[ 0.0134394 , -0.26853782, -0.52198666,  0.19317141]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases # Bias de la primera capa: 500 bias inicializados a 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train the model with M-BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 - 4s - loss: 10.3517 - accuracy: 0.5306 - val_loss: 3.5498 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "13/13 - 3s - loss: 3.1410 - accuracy: 0.5587 - val_loss: 2.6045 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "13/13 - 2s - loss: 1.2580 - accuracy: 0.6658 - val_loss: 1.9346 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "13/13 - 2s - loss: 0.5328 - accuracy: 0.7857 - val_loss: 1.7991 - val_accuracy: 0.6020\n",
      "Epoch 5/100\n",
      "13/13 - 2s - loss: 0.3202 - accuracy: 0.8648 - val_loss: 1.7158 - val_accuracy: 0.5816\n",
      "Epoch 6/100\n",
      "13/13 - 3s - loss: 0.2062 - accuracy: 0.9107 - val_loss: 1.7484 - val_accuracy: 0.6020\n",
      "Epoch 7/100\n",
      "13/13 - 3s - loss: 0.1079 - accuracy: 0.9592 - val_loss: 1.8420 - val_accuracy: 0.6020\n",
      "Epoch 8/100\n",
      "13/13 - 3s - loss: 0.0541 - accuracy: 0.9949 - val_loss: 1.7206 - val_accuracy: 0.5816\n",
      "Epoch 9/100\n",
      "13/13 - 2s - loss: 0.0347 - accuracy: 1.0000 - val_loss: 1.7156 - val_accuracy: 0.5816\n",
      "Epoch 10/100\n",
      "13/13 - 2s - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.7565 - val_accuracy: 0.6020\n",
      "Epoch 11/100\n",
      "13/13 - 2s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.7580 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "13/13 - 2s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.7857 - val_accuracy: 0.5816\n",
      "Epoch 13/100\n",
      "13/13 - 3s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.8046 - val_accuracy: 0.5816\n",
      "Epoch 14/100\n",
      "13/13 - 3s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.8202 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "13/13 - 3s - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.8360 - val_accuracy: 0.5612\n",
      "Epoch 16/100\n",
      "13/13 - 3s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.8488 - val_accuracy: 0.5612\n",
      "Epoch 17/100\n",
      "13/13 - 3s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.8663 - val_accuracy: 0.5612\n",
      "Epoch 18/100\n",
      "13/13 - 3s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.8831 - val_accuracy: 0.5612\n",
      "Epoch 19/100\n",
      "13/13 - 3s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.8927 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "13/13 - 3s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.9063 - val_accuracy: 0.5612\n",
      "Epoch 21/100\n",
      "13/13 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.9154 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "13/13 - 2s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.9309 - val_accuracy: 0.5612\n",
      "Epoch 23/100\n",
      "13/13 - 3s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.9431 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "13/13 - 3s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.9566 - val_accuracy: 0.5612\n",
      "Epoch 25/100\n",
      "13/13 - 3s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.9691 - val_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "13/13 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.9820 - val_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "13/13 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.9932 - val_accuracy: 0.5612\n",
      "Epoch 28/100\n",
      "13/13 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.0039 - val_accuracy: 0.5612\n",
      "Epoch 29/100\n",
      "13/13 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.0143 - val_accuracy: 0.5612\n",
      "Epoch 30/100\n",
      "13/13 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.0280 - val_accuracy: 0.5714\n",
      "Epoch 31/100\n",
      "13/13 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.0377 - val_accuracy: 0.5612\n",
      "Epoch 32/100\n",
      "13/13 - 3s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.0471 - val_accuracy: 0.5612\n",
      "Epoch 33/100\n",
      "13/13 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.0584 - val_accuracy: 0.5510\n",
      "Epoch 34/100\n",
      "13/13 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.0703 - val_accuracy: 0.5408\n",
      "Epoch 35/100\n",
      "13/13 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.0844 - val_accuracy: 0.5612\n",
      "Epoch 36/100\n",
      "13/13 - 3s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.0933 - val_accuracy: 0.5306\n",
      "Epoch 37/100\n",
      "13/13 - 3s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.1040 - val_accuracy: 0.5306\n",
      "Epoch 38/100\n",
      "13/13 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1120 - val_accuracy: 0.5306\n",
      "Epoch 39/100\n",
      "13/13 - 3s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.1190 - val_accuracy: 0.5408\n",
      "Epoch 40/100\n",
      "13/13 - 3s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1270 - val_accuracy: 0.5408\n",
      "Epoch 41/100\n",
      "13/13 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1344 - val_accuracy: 0.5408\n",
      "Epoch 42/100\n",
      "13/13 - 3s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1407 - val_accuracy: 0.5306\n",
      "Epoch 43/100\n",
      "13/13 - 3s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1492 - val_accuracy: 0.5510\n",
      "Epoch 44/100\n",
      "13/13 - 4s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1554 - val_accuracy: 0.5408\n",
      "Epoch 45/100\n",
      "13/13 - 4s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1638 - val_accuracy: 0.5408\n",
      "Epoch 46/100\n",
      "13/13 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1713 - val_accuracy: 0.5408\n",
      "Epoch 47/100\n",
      "13/13 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1792 - val_accuracy: 0.5408\n",
      "Epoch 48/100\n",
      "13/13 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1868 - val_accuracy: 0.5408\n",
      "Epoch 49/100\n",
      "13/13 - 5s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1953 - val_accuracy: 0.5408\n",
      "Epoch 50/100\n",
      "13/13 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.2020 - val_accuracy: 0.5408\n",
      "Epoch 51/100\n",
      "13/13 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.2098 - val_accuracy: 0.5408\n",
      "Epoch 52/100\n",
      "13/13 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.2188 - val_accuracy: 0.5408\n",
      "Epoch 53/100\n",
      "13/13 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.2254 - val_accuracy: 0.5408\n",
      "Epoch 54/100\n",
      "13/13 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.2330 - val_accuracy: 0.5408\n",
      "Epoch 55/100\n",
      "13/13 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.2395 - val_accuracy: 0.5408\n",
      "Epoch 56/100\n",
      "13/13 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.2461 - val_accuracy: 0.5408\n",
      "Epoch 57/100\n",
      "13/13 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.2520 - val_accuracy: 0.5408\n",
      "Epoch 58/100\n",
      "13/13 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.2579 - val_accuracy: 0.5408\n",
      "Epoch 59/100\n",
      "13/13 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.2655 - val_accuracy: 0.5408\n",
      "Epoch 60/100\n",
      "13/13 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.2731 - val_accuracy: 0.5408\n",
      "Epoch 61/100\n",
      "13/13 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.2814 - val_accuracy: 0.5408\n",
      "Epoch 62/100\n",
      "13/13 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.2893 - val_accuracy: 0.5408\n",
      "Epoch 63/100\n",
      "13/13 - 5s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.2974 - val_accuracy: 0.5408\n",
      "Epoch 64/100\n",
      "13/13 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.3050 - val_accuracy: 0.5306\n",
      "Epoch 65/100\n",
      "13/13 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.3105 - val_accuracy: 0.5408\n",
      "Epoch 66/100\n",
      "13/13 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3178 - val_accuracy: 0.5408\n",
      "Epoch 67/100\n",
      "13/13 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3237 - val_accuracy: 0.5408\n",
      "Epoch 68/100\n",
      "13/13 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3301 - val_accuracy: 0.5408\n",
      "Epoch 69/100\n",
      "13/13 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3372 - val_accuracy: 0.5306\n",
      "Epoch 70/100\n",
      "13/13 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3428 - val_accuracy: 0.5408\n",
      "Epoch 71/100\n",
      "13/13 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3492 - val_accuracy: 0.5408\n",
      "Epoch 72/100\n",
      "13/13 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3559 - val_accuracy: 0.5306\n",
      "Epoch 73/100\n",
      "13/13 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3623 - val_accuracy: 0.5408\n",
      "Epoch 74/100\n",
      "13/13 - 5s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3686 - val_accuracy: 0.5306\n",
      "Epoch 75/100\n",
      "13/13 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3754 - val_accuracy: 0.5306\n",
      "Epoch 76/100\n",
      "13/13 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3819 - val_accuracy: 0.5306\n",
      "Epoch 77/100\n",
      "13/13 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3881 - val_accuracy: 0.5306\n",
      "Epoch 78/100\n",
      "13/13 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3938 - val_accuracy: 0.5306\n",
      "Epoch 79/100\n",
      "13/13 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.3989 - val_accuracy: 0.5306\n",
      "Epoch 80/100\n",
      "13/13 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4045 - val_accuracy: 0.5306\n",
      "Epoch 81/100\n",
      "13/13 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4099 - val_accuracy: 0.5306\n",
      "Epoch 82/100\n",
      "13/13 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4157 - val_accuracy: 0.5306\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4224 - val_accuracy: 0.5306\n",
      "Epoch 84/100\n",
      "13/13 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4287 - val_accuracy: 0.5306\n",
      "Epoch 85/100\n",
      "13/13 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4351 - val_accuracy: 0.5306\n",
      "Epoch 86/100\n",
      "13/13 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4403 - val_accuracy: 0.5408\n",
      "Epoch 87/100\n",
      "13/13 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4458 - val_accuracy: 0.5306\n",
      "Epoch 88/100\n",
      "13/13 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4510 - val_accuracy: 0.5408\n",
      "Epoch 89/100\n",
      "13/13 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4568 - val_accuracy: 0.5408\n",
      "Epoch 90/100\n",
      "13/13 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4621 - val_accuracy: 0.5408\n",
      "Epoch 91/100\n",
      "13/13 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4695 - val_accuracy: 0.5408\n",
      "Epoch 92/100\n",
      "13/13 - 5s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4761 - val_accuracy: 0.5408\n",
      "Epoch 93/100\n",
      "13/13 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4817 - val_accuracy: 0.5408\n",
      "Epoch 94/100\n",
      "13/13 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4868 - val_accuracy: 0.5408\n",
      "Epoch 95/100\n",
      "13/13 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4922 - val_accuracy: 0.5408\n",
      "Epoch 96/100\n",
      "13/13 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4980 - val_accuracy: 0.5408\n",
      "Epoch 97/100\n",
      "13/13 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5027 - val_accuracy: 0.5408\n",
      "Epoch 98/100\n",
      "13/13 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5082 - val_accuracy: 0.5408\n",
      "Epoch 99/100\n",
      "13/13 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5132 - val_accuracy: 0.5408\n",
      "Epoch 100/100\n",
      "13/13 - 5s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5191 - val_accuracy: 0.5408\n",
      "356.2461462020874\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#history = model.fit(X_train, y_train, batch_size=32, steps_per_epoch=len(y_train)/32, epochs=100, verbose=2, validation_data=(X_dev, y_dev),callbacks=[tensorboard])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=2, validation_data=(X_dev, y_dev))\n",
    "print (time.time() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results=pd.DataFrame(history.history)\n",
    "results.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel (\"Epochs\")\n",
    "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
    "plt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "# categorical_accuracy es el training accuracy\n",
    "# val_categorical_accuracy es el validation accuracy\n",
    "# loss es el training loss\n",
    "# val_loss es el validation loss\n",
    "\n",
    "# Overfitting:\n",
    "# Por un lado la Accuracy de los datos de entrenamiento aumenta con las epochs,\n",
    "# mientras que la Accuracy de los datos de validación disminuye o se mantiene constante a lo largo de las epochs. \n",
    "# La Loss de los datos de validación alcanza su mínimo después de pocos epochs y luego empieza a subir, \n",
    "# mientras que la Loss de los datos de entrenamiento disminuye linealmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 2, 'epochs': 100, 'steps': 13}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.002066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51911</td>\n",
       "      <td>0.540816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "99  0.002066       1.0   2.51911      0.540816"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set:  1.0\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the training set: \", results.values[-1:][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the development test set:  0.5408163070678711\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for the development test set: \", results.values[-1:][0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how the model predicts using the development test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01, 0.99],\n",
       "       [0.  , 1.  ],\n",
       "       [0.03, 0.97],\n",
       "       [0.  , 1.  ],\n",
       "       [0.01, 0.99],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.98, 0.02],\n",
       "       [0.  , 1.  ],\n",
       "       [0.07, 0.93],\n",
       "       [0.  , 1.  ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.01, 0.99],\n",
       "       [0.99, 0.01],\n",
       "       [0.13, 0.87],\n",
       "       [0.01, 0.99],\n",
       "       [0.96, 0.04],\n",
       "       [0.  , 1.  ],\n",
       "       [0.5 , 0.5 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions=model.predict(X_dev).round(2) \n",
    "dev_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_rounded_predictions=np.round(dev_predictions)\n",
    "indices = np.argmax(dev_predictions,1)\n",
    "for row, index in zip(dev_rounded_predictions, indices): row[index]=1\n",
    "dev_rounded_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False  True False  True False False False\n",
      " False  True False  True  True False  True False False  True False False\n",
      "  True False False False False  True]\n"
     ]
    }
   ],
   "source": [
    "dev_correct_predictions = np.equal(np.argmax(dev_rounded_predictions,1),np.argmax(y_dev,1))\n",
    "print (dev_correct_predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 46, True: 52})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter (dev_correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model if it is better than others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "model.save('./Modelos/CNN_model1_IMPARES_DIA31.h5') # Change the name in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnew_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\\n\\nimport numpy as np\\n\\n# Verify state\\nnew_predictions = new_model.predict(X_dev)\\nnp.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\\n\\n# Note that the optimizer state is also preserved:\\n# you can resume training where you left off.\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract\n",
    "\"\"\"\n",
    "new_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Verify state\n",
    "new_predictions = new_model.predict(X_dev)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is also preserved:\n",
    "# you can resume training where you left off.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Final Test\n",
    "\n",
    "#### 10.1 - Load the final test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def predictWithModel(model, X_test, y_test, task1, task2, task3=\"\"):\n",
    "    model.evaluate(X_test, y_test)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_rounded_predictions=np.round(test_predictions)\n",
    "    indices = np.argmax(test_predictions,1)\n",
    "    for row, index in zip(test_rounded_predictions, indices): row[index]=1\n",
    "    print(test_rounded_predictions[:20])\n",
    "    \n",
    "    # ACCURACY:\n",
    "    test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(y_test,1))\n",
    "    print()\n",
    "    print(test_correct_predictions)\n",
    "    print(type(test_correct_predictions))\n",
    "    final_test_prediction_results=Counter(test_correct_predictions)\n",
    "    \n",
    "    success = np.mean(test_rounded_predictions == y_test)*100\n",
    "    \n",
    "    return final_test_prediction_results, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 83ms/step - loss: 2.9272 - accuracy: 0.5306\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "[ True False False  True False False False False False False False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False False  True False False  True  True False  True  True  True  True\n",
      "  True  True  True False False False  True False False False False False\n",
      " False]\n",
      "<class 'numpy.ndarray'>\n",
      "Counter({True: 26, False: 23}) 53.06122448979592\n"
     ]
    }
   ],
   "source": [
    "accuracy, success = predictWithModel(model, X_test, y_test, 402,404)\n",
    "print(accuracy, success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
