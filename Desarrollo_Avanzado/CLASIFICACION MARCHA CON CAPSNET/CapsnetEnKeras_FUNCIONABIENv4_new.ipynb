{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CapsnetEnKeras.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oieoYd8_NJl4"
      },
      "source": [
        "# Parte 4: Clasificación con Capsnet\n",
        "\n",
        "La implementación de esta red Capsnet se ha basado en el código implementado por Aurélien Géron (https://github.com/ageron/handson-ml/blob/master/extra_capsnets.ipynb) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOYsNIkfNJl7"
      },
      "source": [
        "### Resultados con la arquitectura anterior: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zeUMdGrNJl8"
      },
      "source": [
        "### Cambios realizados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvWOKZzaNJl8"
      },
      "source": [
        "Se aumenta de 100 a 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5eey6oGNJl8"
      },
      "source": [
        "### Nuevos resultados: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGdAPW3NNJl9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRy2Mth1NJl9"
      },
      "source": [
        "### 1 - Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cse2ICU7NJl-"
      },
      "source": [
        "# Tensorflow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#Helper libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Signal libraries\n",
        "from scipy import signal"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZdDJXPXNJl-"
      },
      "source": [
        "# Reset the default graph, in case you re-run this notebook without restarting the kernel:\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "# Random seeds so that this notebook always produces the same output:\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(45)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4TwxUdJNJl_"
      },
      "source": [
        "### 2 - Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19rmC_7VNJl_"
      },
      "source": [
        "class ROutput:\n",
        "    def __init__(self, task, data):\n",
        "        self.task = task\n",
        "        self.data = data\n",
        "        \n",
        "class OutTaskData: \n",
        "    def __init__(self, task, data): \n",
        "        self.task = task\n",
        "        self.data = data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMzZss4DNJmA"
      },
      "source": [
        "import scipy.io as sio\n",
        "# Primero leemos los registros\n",
        "def read_outputs(rec):\n",
        "    '''read_outputs(\"userS0091f1.mat\")'''\n",
        "    mat = sio.loadmat(rec)\n",
        "    mdata = mat['session']\n",
        "    val = mdata[0,0]\n",
        "    #output = ROutput(np.array(val[\"task\"]), np.array(val[\"data\"]))\n",
        "    output = ROutput(np.array(val[\"task_EEG_p\"]), np.array(val[\"data_processed_EEG\"]))\n",
        "    return output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7EF2GDqNJmA"
      },
      "source": [
        "### Cargamos los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdNLHsqfNJmA"
      },
      "source": [
        "# Configuración\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import Perceptron\n",
        "#from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "task1 = 402 # SE PUEDE CAMBIAR\n",
        "task2 = 404 # SE PUEDE CAMBIAR\n",
        "task_OneHotEnconding = {402: [1], 404: [0]}\n",
        "user = 'W29' # SE PUEDE CAMBIAR\n",
        "day = '0329'\n",
        "folder_day = 'W29-29_03_2021'\n",
        "total_records = 22 # CAMBIAR SI HAY MAS REGISTROS\n",
        "fm = 200\n",
        "electrodes_names_selected = ['F3', 'FZ', 'FC1','FCZ','C1','CZ','CP1','CPZ', 'FC5', 'FC3','C5','C3','CP5','CP3','P3',\n",
        "                             'PZ','F4','FC2','FC4','FC6','C2','C4','CP2','CP4','C6','CP6','P4','HR' ,'HL', 'VU', 'VD']\n",
        "number_channels = len(electrodes_names_selected)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW2fa7fbNJmB",
        "outputId": "f1b4fa8a-b39f-42c2-e2d2-c03d891bb564"
      },
      "source": [
        "lTaskData = []\n",
        "total_records_used = 0\n",
        "for i_rec in range(1,total_records+1):\n",
        "    i_rec_record = i_rec\n",
        "    if i_rec_record <10:\n",
        "        i_rec_record = \"0\"+str(i_rec_record)\n",
        "    if i_rec % 2 == 0: # Registros impares primero: USUARIO SIN MOVIMIENTO SOLO PENSANDO\n",
        "        record = \"./RegistrosProcesados2/W29_2021\"+day+\"_openloop_\"+str(i_rec_record)+\"_processed.mat\"\n",
        "        output = read_outputs(record) # output.task será y, output.data será x\n",
        "\n",
        "\n",
        "        output.task = np.transpose(output.task)\n",
        "        output.data = output.data.reshape((np.shape(output.data)[0],np.shape(output.data)[1]))\n",
        "        output.data = np.transpose(output.data)\n",
        "        #output.data = output.data.reshape((np.shape(output.data)[0],np.shape(output.data)[1],1))\n",
        "\n",
        "        outT = (output.task == task1) | (output.task == task2)\n",
        "        outData = output.data[0:np.shape(output.data)[0], outT[0,:]]\n",
        "        outTask = output.task[0, outT[0,:]]\n",
        "        outTD = OutTaskData(outTask, outData)\n",
        "\n",
        "        lTaskData.append(outTD)\n",
        "        total_records_used+=1\n",
        "print(total_records_used, total_records)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqrivmkzNJmC",
        "outputId": "4c7613f4-fd37-4332-c99c-42e57f5c491d"
      },
      "source": [
        "# Vamos a coger 2 registros para el entrenamiento, 1 para el conjunto dev set, 1 para el test set\n",
        "X_train, y_train, X_dev, y_dev, X_test, y_test = [],[],[],[],[],[] \n",
        "for j in range(0,total_records_used-3): # Cogemos 18 registros para entrenamiento\n",
        "    X_train.append(lTaskData[j].data)\n",
        "    y_train.append(lTaskData[j].task)\n",
        "\n",
        "for j in range(total_records_used-3,total_records_used-1): # Cogemos 2 registros para el dev set\n",
        "    X_dev.append(lTaskData[j].data)\n",
        "    y_dev.append(lTaskData[j].task)\n",
        "for j in range(total_records_used-1,total_records_used): # Cogemos 2 registros para el test set\n",
        "    X_test.append(lTaskData[j].data)\n",
        "    y_test.append(lTaskData[j].task)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "#y_train = np.ravel(np.array(y_train))\n",
        "y_train = np.array(y_train)\n",
        "X_dev = np.array(X_dev)\n",
        "#y_dev = np.ravel(np.array(y_dev))\n",
        "y_dev = np.array(y_dev)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "#y_test = np.ravel(np.array(y_test))\n",
        "\n",
        "print (\"X_train:\",X_train.shape)\n",
        "print (\"y_train:\",y_train.shape)\n",
        "print (\"X_dev:\",X_dev.shape)\n",
        "print (\"y_dev:\",y_dev.shape)\n",
        "print (\"X_test:\",X_test.shape)\n",
        "print (\"y_test:\",y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# VENTANEO Y ONE HOT ENCODING \n",
        "window = 5\n",
        "samples_advance = 3\n",
        "\n",
        "# Ventaneo X_train\n",
        "\n",
        "X_train_l = []\n",
        "y_train_l = []\n",
        "for num_X_train in range(np.shape(X_train)[0]): # Para no mezclar registros\n",
        "    win_init = int(0)\n",
        "    window_position = 0\n",
        "    \n",
        "    for i in range(np.shape(X_train)[2]): # For each signal registered\n",
        "        win_end = int(win_init + window)\n",
        "        if win_end >= np.shape(X_train)[2]:\n",
        "            break\n",
        "\n",
        "        task = np.unique(y_train[num_X_train,win_init:win_end])\n",
        "\n",
        "        if len(task)==1:\n",
        "        #if task1 in task or task2 in task:\n",
        "            signal_window = X_train[num_X_train, :, win_init:win_end]\n",
        "            \n",
        "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
        "            #X_train_l.append(data_filtered)\n",
        "            X_train_l.append(signal_window)\n",
        "            taskOH = task_OneHotEnconding[task[0]]\n",
        "            y_train_l.append(taskOH)\n",
        "            #y_train_l.append([str(task[0])])\n",
        "            \n",
        "            \n",
        "        win_init += int(samples_advance)\n",
        "\n",
        "X_train_l = np.array(X_train_l)\n",
        "y_train_l = np.array(y_train_l)\n",
        "\n",
        "\n",
        "# Ventaneo X_dev\n",
        "X_dev_l = []\n",
        "y_dev_l = []\n",
        "for num_X_dev in range(np.shape(X_dev)[0]):\n",
        "    win_init = int(0)\n",
        "    window_position = 0\n",
        "    \n",
        "    for i in range(np.shape(X_dev)[2]): # For each signal registered\n",
        "        win_end = int(win_init + window)\n",
        "        if win_end >= np.shape(X_dev)[2]:\n",
        "            break\n",
        "\n",
        "        task = np.unique(y_dev[num_X_dev,win_init:win_end])\n",
        "\n",
        "        if len(task)==1:\n",
        "        #if task1 in task or task2 in task:\n",
        "            signal_window = X_dev[num_X_dev, :, win_init:win_end]\n",
        "            \n",
        "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
        "            #X_train_l.append(data_filtered)\n",
        "            X_dev_l.append(signal_window)\n",
        "            taskOH = task_OneHotEnconding[task[0]]\n",
        "            y_dev_l.append(taskOH)\n",
        "            #y_dev_l.append([str(task[0])])\n",
        "            \n",
        "        win_init += int(samples_advance)\n",
        "\n",
        "X_dev_l = np.array(X_dev_l)\n",
        "y_dev_l = np.array(y_dev_l)\n",
        "\n",
        "# Ventaneo X_test\n",
        "X_test_l = []\n",
        "y_test_l = []\n",
        "for num_X_test in range(np.shape(X_test)[0]): \n",
        "    win_init = int(0)\n",
        "    window_position = 0\n",
        "    \n",
        "    for i in range(np.shape(X_test)[2]): # For each signal registered\n",
        "        win_end = int(win_init + window)\n",
        "        if win_end >= np.shape(X_test)[2]:\n",
        "            break\n",
        "\n",
        "        task = np.unique(y_test[num_X_test,win_init:win_end])\n",
        "\n",
        "        if len(task)==1:\n",
        "        #if task1 in task or task2 in task:\n",
        "            signal_window = X_test[num_X_test, :, win_init:win_end]\n",
        "            \n",
        "            #data_filtered = preprocessing(signal_window, fm, number_channels)\n",
        "            #X_train_l.append(data_filtered)\n",
        "            X_test_l.append(signal_window)\n",
        "            taskOH = task_OneHotEnconding[task[0]]\n",
        "            #y_test_l.append([str(task[0])])\n",
        "            y_test_l.append(taskOH)\n",
        "            \n",
        "        win_init += int(samples_advance)\n",
        "\n",
        "X_test_l = np.array(X_test_l)\n",
        "y_test_l = np.array(y_test_l)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train_l = X_train_l.reshape((np.shape(X_train_l)[0],np.shape(X_train_l)[1],np.shape(X_train_l)[2], 1))\n",
        "X_dev_l = X_dev_l.reshape((np.shape(X_dev_l)[0],np.shape(X_dev_l)[1],np.shape(X_dev_l)[2], 1))\n",
        "X_test_l = X_test_l.reshape((np.shape(X_test_l)[0],np.shape(X_test_l)[1],np.shape(X_test_l)[2], 1))\n",
        "\n",
        "print()\n",
        "print(\"ONE HOT ENCODER & WINDOWING:\")\n",
        "print (\"X_train:\",X_train_l.shape)\n",
        "print (\"y_train:\",y_train_l.shape)\n",
        "print (\"X_dev:\",X_dev_l.shape)\n",
        "print (\"y_dev:\",y_dev_l.shape)\n",
        "print (\"X_test:\",X_test_l.shape)\n",
        "print (\"y_test:\",y_test_l.shape)\n",
        "\n",
        "X_train = X_train_l\n",
        "y_train = y_train_l\n",
        "X_dev = X_dev_l\n",
        "y_dev = y_dev_l\n",
        "X_test = X_test_l\n",
        "y_test = y_test_l\n",
        "\n",
        "print(y_train)\n",
        "X_train = X_train.astype('float32')\n",
        "X_dev = X_dev.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_train = to_categorical(y_train).astype('float32')\n",
        "y_dev = to_categorical(y_dev).astype('float32')\n",
        "y_test = to_categorical(y_test).astype('float32')\n",
        "print()\n",
        "print(\"RESHAPE:\")\n",
        "print (\"X_train:\",X_train.shape)\n",
        "print (\"y_train:\",y_train.shape)\n",
        "print (\"X_dev:\",X_dev.shape)\n",
        "print (\"y_dev:\",y_dev.shape)\n",
        "print (\"X_test:\",X_test.shape)\n",
        "print (\"y_test:\",y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (8, 32, 49)\n",
            "y_train: (8, 49)\n",
            "X_dev: (2, 32, 49)\n",
            "y_dev: (2, 49)\n",
            "X_test: (1, 32, 49)\n",
            "y_test: (1, 49)\n",
            "\n",
            "ONE HOT ENCODER & WINDOWING:\n",
            "X_train: (104, 32, 5, 1)\n",
            "y_train: (104, 1)\n",
            "X_dev: (26, 32, 5, 1)\n",
            "y_dev: (26, 1)\n",
            "X_test: (13, 32, 5, 1)\n",
            "y_test: (13, 1)\n",
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]]\n",
            "\n",
            "RESHAPE:\n",
            "X_train: (104, 32, 5, 1)\n",
            "y_train: (104, 2)\n",
            "X_dev: (26, 32, 5, 1)\n",
            "y_dev: (26, 2)\n",
            "X_test: (13, 32, 5, 1)\n",
            "y_test: (13, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7MjujBzYdtz",
        "outputId": "0b7baf41-e178-4ac8-90fb-1d522efffb2f"
      },
      "source": [
        "y_dev"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG1aSct6xkOm",
        "outputId": "27b04bc5-8090-4b3e-f3f8-4a454a5a09ba"
      },
      "source": [
        "len(np.unique(np.argmax(y_train, 1)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gQbqp_NJmG"
      },
      "source": [
        "### 4 - Construcción de la Capsnet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvwXwu0cNJmH"
      },
      "source": [
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras import initializers, layers, regularizers\n",
        "\n",
        "\n",
        "class Length(layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
        "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
        "    inputs: shape=[None, num_vectors, dim_vector]\n",
        "    output: shape=[None, num_vectors]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return K.sqrt(K.sum(K.square(inputs), -1) + K.epsilon())\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Length, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
        "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
        "    masked Tensor.\n",
        "    For example:\n",
        "        ```\n",
        "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
        "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
        "        out = Mask()(x)  # out.shape=[8, 6]\n",
        "        # or\n",
        "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
        "        ```\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        \"\"\"\n",
        "        if isinstance(inputs, list):  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
        "            # compute lengths of capsules\n",
        "            x = K.sqrt(K.sum(K.square(inputs), -1))\n",
        "            # generate the mask which is a one-hot code.\n",
        "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
        "            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
        "        \"\"\"\n",
        "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
        "            # compute lengths of capsules\n",
        "            x = K.sqrt(K.sum(K.square(inputs), -1))\n",
        "            # generate the mask which is a one-hot code.\n",
        "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
        "            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
        "            \n",
        "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
        "        # mask.shape=[None, num_capsule]\n",
        "        # masked.shape=[None, num_capsule * dim_capsule]\n",
        "        masked = K.batch_flatten(inputs * K.expand_dims(mask, -1))\n",
        "        return masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if isinstance(input_shape[0], tuple):  # true label provided\n",
        "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
        "        else:  # no true label provided\n",
        "            return tuple([None, input_shape[1] * input_shape[2]])\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the \n",
        "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
        "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
        "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
        "    \n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, num_capsule, dim_capsule, routings,lam_regularize,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.lam_regularize = lam_regularize\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "\n",
        "        # Transform matrix\n",
        "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
        "                                        self.dim_capsule, self.input_dim_capsule],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 regularizer=regularizers.l2(self.lam_regularize),\n",
        "                                 name='W')\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
        "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule]\n",
        "        #inputs_expand = K.expand_dims(inputs, 1)   SANDRA\n",
        "        inputs_expand = tf.expand_dims(inputs, 1)\n",
        "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
        "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule]\n",
        "        #inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1]) SANDRA\n",
        "        inputs_tiled  = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
        "        inputs_tiled  = tf.expand_dims(inputs_tiled, 4)\n",
        "        print(\"inputs_tiled\",np.shape(inputs_tiled))\n",
        "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
        "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule]\n",
        "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
        "        # Regard the first two dimensions as `batch` dimension,\n",
        "        # then matmul: [input_dim_capsule] x [dim_capsule, input_dim_capsule]^T -> [dim_capsule].\n",
        "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
        "        \n",
        "        #inputs_hat = K.map_fn(lambda x: K.batch_dot(x, self.W, [2, 3]), elems=inputs_tiled) SANDRA\n",
        "        inputs_hat = tf.map_fn(lambda x: tf.matmul(self.W, x), elems=inputs_tiled)\n",
        "        \n",
        "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
        "        # The prior for coupling coefficient, initialized as zeros.\n",
        "        # b.shape = [None, self.num_capsule, self.input_num_capsule].\n",
        "        #b = tf.zeros(shape=[K.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule]) SANDRA\n",
        "        b = tf.zeros(shape=[tf.shape(inputs_hat)[0], self.num_capsule, \n",
        "                      self.input_num_capsule, 1, 1])\n",
        "        \n",
        "        assert self.routings > 0, 'The routings should be > 0.'\n",
        "        for i in range(self.routings):\n",
        "            # c.shape=[batch_size, num_capsule, input_num_capsule]\n",
        "            #c = tf.nn.softmax(b, dim=1)\n",
        "            # c =tf.compat.v1.math.softmax(b, axis = 1) SANDRA\n",
        "            c = layers.Softmax(axis=1)(b)\n",
        "            print(\"c\",np.shape(c))\n",
        "            \n",
        "\n",
        "            # c.shape =  [batch_size, num_capsule, input_num_capsule]\n",
        "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "            # The first two dimensions as `batch` dimension,\n",
        "            # then matmal: [input_num_capsule] x [input_num_capsule, dim_capsule] -> [dim_capsule].\n",
        "            # outputs.shape=[None, num_capsule, dim_capsule]\n",
        "            #dot_c = K.batch_dot(c, inputs_hat, [2,2]) sandra\n",
        "            #print(\"dot_c\",np.shape(dot_c)) sandra\n",
        "\n",
        "            #outputs = squash(dot_c)  # [None, 10, 16] # sandra\n",
        "            outputs = tf.multiply(c, inputs_hat)\n",
        "            outputs = tf.reduce_sum(outputs, axis=2, keepdims=True)\n",
        "            outputs = squash(outputs, axis=-2)  # [None, 10, 1, 16, 1]\n",
        "      \n",
        "            if i < self.routings - 1:\n",
        "                # outputs.shape =  [None, num_capsule, dim_capsule]\n",
        "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "                # The first two dimensions as `batch` dimension,\n",
        "                # then matmal: [dim_capsule] x [input_num_capsule, dim_capsule]^T -> [input_num_capsule].\n",
        "                # b.shape=[batch_size, num_capsule, input_num_capsule]\n",
        "                # b += K.batch_dot(outputs, inputs_hat, [2, 3]) SANDRA\n",
        "                outputs_tiled = tf.tile(outputs, [1, 1, self.input_num_capsule, 1, 1])\n",
        "                agreement = tf.matmul(inputs_hat, outputs_tiled, transpose_a=True)\n",
        "                b = tf.add(b, agreement)\n",
        "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
        "        # Squeeze the outputs to remove useless axis:\n",
        "        #  From  --> outputs.shape=[None, num_capsule, 1, dim_capsule, 1]\n",
        "        #  To    --> outputs.shape=[None, num_capsule,    dim_capsule]\n",
        "        outputs = tf.squeeze(outputs, [2, 4])\n",
        "        return outputs\n",
        "    \n",
        "\n",
        "\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding, lam_regularize):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_capsule: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
        "    \"\"\"\n",
        "    outputs = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                           name='primarycap_conv2d',kernel_regularizer= regularizers.l2(lam_regularize))(inputs)\n",
        "    \n",
        "\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(outputs)#(conca_maps)#(output)\n",
        "    return layers.Lambda(squash, name='primarycap_squash')(outputs)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQvXFC9GNJmK"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras import layers, models, optimizers,regularizers\n",
        "from keras.layers import InputSpec, Dense\n",
        "#from capsulelayers import CapsuleLayer, PrimaryCap, Length\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "class CapsToScalars(layers.Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CapsToScalars, self).__init__(**kwargs)\n",
        "        self.input_spec = InputSpec(min_ndim=3)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[1])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return K.sqrt(K.sum(K.square(inputs + K.epsilon()), axis=-1))\n",
        "\n",
        "def CapsNet(input_shape, n_class, routings, lam_regularize):\n",
        "    \"\"\"\n",
        "    A Capsule Network .\n",
        "    :param input_shape: data shape, 3d, [width, height, channels]\n",
        "    :param n_class: number of classes\n",
        "    :param routings: number of routing iterations\n",
        "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
        "            `eval_model` can also be used for training.\n",
        "    \"\"\"\n",
        "    x = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Layer 1: Just a conventional Conv2D layer\n",
        "    conv1 = layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='valid', activation='relu', name='conv1',kernel_regularizer=regularizers.l2(lam_regularize))(x) \n",
        "\n",
        "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
        "    primarycaps = PrimaryCap(conv1, dim_capsule=4, n_channels=128, kernel_size=3, strides=2, padding='valid',lam_regularize = lam_regularize)\n",
        "    \n",
        "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "    micaps = CapsuleLayer(num_capsule=n_class, dim_capsule=8, routings=routings,\n",
        "                             name='micaps', lam_regularize = lam_regularize)(primarycaps)\n",
        "\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    out_caps = Length(name='capsnet')(micaps)\n",
        "\n",
        "    # Decoder network.\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked_by_y = Mask()([micaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
        "    masked = Mask()(micaps)  # Mask using the capsule with maximal length. For prediction\n",
        "\n",
        "    # Shared Decoder model in training and prediction\n",
        "    decoder = models.Sequential(name='decoder')\n",
        "    decoder.add(layers.Dense(512, activation='relu', input_dim=8*n_class))\n",
        "    decoder.add(layers.Dense(1024, activation='relu'))\n",
        "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
        "\n",
        "    # Models for training and evaluation (prediction)\n",
        "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
        "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
        "    \"\"\"\n",
        "    return train_model, eval_model\n",
        "    \"\"\"\n",
        "    # manipulate model\n",
        "    \n",
        "    noise = layers.Input(shape=(n_class, 8))\n",
        "    noised_micaps = layers.Add()([micaps, noise])\n",
        "    masked_noised_y = Mask()([noised_micaps, y])\n",
        "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
        "    \n",
        "    return train_model, eval_model, manipulate_model\n",
        "    \n",
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return K.mean(K.sum(L, 1))\n",
        "\n",
        "def train(model, data, args):\n",
        "    \"\"\"\n",
        "    Training a CapsuleNet\n",
        "    :param model: the CapsuleNet model\n",
        "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
        "    :param args: arguments\n",
        "    :return: The trained model\n",
        "    \"\"\"\n",
        "    # unpacking the data\n",
        "    (X_train, y_train), (X_dev, y_dev) = data\n",
        "\n",
        "    # callbacks\n",
        "    log = callbacks.CSVLogger(args.save_dir + '/' + 'log_fold.csv')\n",
        "    tb = callbacks.TensorBoard(log_dir=args.save_dir + '/tensorboard-logs_fold',\n",
        "                               batch_size=args.batch_size, histogram_freq=args.debug)\n",
        "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights-{epoch:02d}_fold.h5', monitor='val_acc',\n",
        "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (1.0 ** epoch))\n",
        "\n",
        "    #EarlyStop = callbacks.EarlyStopping(monitor='val_capsnet_acc', patience=5)\n",
        "    # compile the model\n",
        "    model.compile(optimizer= optimizers.Adam(lr=args.lr),\n",
        "                  loss=[margin_loss, 'mse'],\n",
        "                  loss_weights=[1., args.lam_recon],\n",
        "                  metrics={'capsnet': 'accuracy'})\n",
        "\n",
        "    # Training without validation set\n",
        "    history = model.fit([X_train, y_train],[y_train, X_train], batch_size=args.batch_size, epochs=args.epochs,\n",
        "                validation_data=([X_dev, y_dev], [y_dev, X_dev]), callbacks=[log, tb, lr_decay])\n",
        "\n",
        "    return history\n",
        "\n",
        "time_start_whole = time.time()\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mh87zwHsEGV",
        "outputId": "7ec852fd-b7d1-44b9-cbb1-7dc135751a3e"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_5bwR72aNJmL",
        "outputId": "cfda68f3-97bc-4395-9f47-3e0209c72ffe"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras import callbacks\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "# setting the hyper parameters\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Capsule Network on \" + folder_day)\n",
        "parser.add_argument('--epochs', default=100, type=int)  \n",
        "parser.add_argument('--batch_size', default=20, type=int)\n",
        "parser.add_argument('--lam_regularize', default=0.0, type=float,\n",
        "                    help=\"The coefficient for the regularizers\")\n",
        "parser.add_argument('--lam_recon', default=0.392, type=float,\n",
        "                        help=\"The coefficient for the loss of decoder\")\n",
        "parser.add_argument('-r', '--routings', default=2, type=int,\n",
        "                    help=\"Number of iterations used in routing algorithm. should > 0\")\n",
        "parser.add_argument('--debug', default=0, type=int,\n",
        "                    help=\"Save weights by TensorBoard\")\n",
        "parser.add_argument('--save_dir', default='./result_/sub_dependent_/') # other\n",
        "parser.add_argument('-t', '--testing', action='store_true',\n",
        "                    help=\"Test the trained model on testing dataset\")\n",
        "parser.add_argument('-w', '--weights', default=None,\n",
        "                    help=\"The path of the saved weights. Should be specified when testing\")\n",
        "parser.add_argument('--lr', default=0.00001, type=float,\n",
        "                    help=\"Initial learning rate\") \n",
        "\n",
        "parser.add_argument('--gpus', default=2, type=int)\n",
        "\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "\n",
        "print(time.asctime(time.localtime(time.time())))\n",
        "print(args)\n",
        "if not os.path.exists(args.save_dir):\n",
        "    os.makedirs(args.save_dir)\n",
        "\n",
        "args.save_dir = args.save_dir\n",
        "if not os.path.exists(args.save_dir):\n",
        "    os.makedirs(args.save_dir)\n",
        "\n",
        "# define model\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    model, eval_model, manipulate_model = CapsNet(input_shape=X_train.shape[1:],\n",
        "                                                  n_class=len(np.unique(np.argmax(y_train, 1))),\n",
        "                                                  routings=args.routings,\n",
        "                                                  lam_regularize = args.lam_regularize) #len(np.unique(np.argmax(y_train, 1)))\n",
        "\n",
        "model.summary()\n",
        "plot_model(model, to_file=args.save_dir+'/model_fold.png', show_shapes=True)\n",
        "\n",
        "\n",
        "# train\n",
        "train_start_time = time.time()\n",
        "history = train(model, data=((X_train, y_train), (X_dev, y_dev)), args=args)\n",
        "train_used_time = time.time() - train_start_time\n",
        "\n",
        "results=pd.DataFrame(history.history)\n",
        "results.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.xlabel (\"Epochs\")\n",
        "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
        "plt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 30 21:32:41 2021\n",
            "Namespace(batch_size=20, debug=0, epochs=100, gpus=2, lam_recon=0.392, lam_regularize=0.0, lr=1e-05, routings=2, save_dir='./result_/sub_dependent_/', testing=False, weights=None)\n",
            "inputs_tiled (None, 2, 1792, 4, 1)\n",
            "c (None, 2, 1792, 1, 1)\n",
            "c (None, 2, 1792, 1, 1)\n",
            "Tensor(\"mask_1/one_hot:0\", shape=(None, 2), dtype=float32)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 5, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 30, 3, 512)   5120        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (None, 14, 1, 512)   2359808     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (None, 1792, 4)      0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (None, 1792, 4)      0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "micaps (CapsuleLayer)           (None, 2, 8)         114688      primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask (Mask)                     (None, None)         0           micaps[0][0]                     \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (None, 2)            0           micaps[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 32, 5, 1)     698016      mask[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 3,177,632\n",
            "Trainable params: 3,177,632\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer CapsuleLayer has arguments in `__init__` and therefore must override `get_config`.\n",
            "Epoch 1/100\n",
            "inputs_tiled (None, 2, 1792, 4, 1)\n",
            "c (None, 2, 1792, 1, 1)\n",
            "c (None, 2, 1792, 1, 1)\n",
            "inputs_tiled (None, 2, 1792, 4, 1)\n",
            "c (None, 2, 1792, 1, 1)\n",
            "c (None, 2, 1792, 1, 1)\n",
            "6/6 [==============================] - ETA: 0s - loss: 1.6912 - capsnet_loss: 0.8094 - decoder_loss: 2.2493 - capsnet_accuracy: 0.6063inputs_tiled (None, 2, 1792, 4, 1)\n",
            "c (None, 2, 1792, 1, 1)\n",
            "c (None, 2, 1792, 1, 1)\n",
            "6/6 [==============================] - 15s 425ms/step - loss: 1.6910 - capsnet_loss: 0.8094 - decoder_loss: 2.2488 - capsnet_accuracy: 0.6076 - val_loss: 1.6905 - val_capsnet_loss: 0.8094 - val_decoder_loss: 2.2476 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.6892 - capsnet_loss: 0.8094 - decoder_loss: 2.2443 - capsnet_accuracy: 0.6187 - val_loss: 1.6904 - val_capsnet_loss: 0.8094 - val_decoder_loss: 2.2475 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.6893 - capsnet_loss: 0.8094 - decoder_loss: 2.2445 - capsnet_accuracy: 0.6328 - val_loss: 1.6904 - val_capsnet_loss: 0.8094 - val_decoder_loss: 2.2474 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.6886 - capsnet_loss: 0.8094 - decoder_loss: 2.2429 - capsnet_accuracy: 0.6090 - val_loss: 1.6902 - val_capsnet_loss: 0.8092 - val_decoder_loss: 2.2473 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.6877 - capsnet_loss: 0.8092 - decoder_loss: 2.2412 - capsnet_accuracy: 0.6064 - val_loss: 1.6897 - val_capsnet_loss: 0.8088 - val_decoder_loss: 2.2471 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 1.6890 - capsnet_loss: 0.8086 - decoder_loss: 2.2458 - capsnet_accuracy: 0.6249 - val_loss: 1.6884 - val_capsnet_loss: 0.8076 - val_decoder_loss: 2.2470 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 1.6881 - capsnet_loss: 0.8071 - decoder_loss: 2.2475 - capsnet_accuracy: 0.6245 - val_loss: 1.6856 - val_capsnet_loss: 0.8048 - val_decoder_loss: 2.2469 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 1.6858 - capsnet_loss: 0.8038 - decoder_loss: 2.2499 - capsnet_accuracy: 0.6117 - val_loss: 1.6793 - val_capsnet_loss: 0.7986 - val_decoder_loss: 2.2467 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.6734 - capsnet_loss: 0.7964 - decoder_loss: 2.2373 - capsnet_accuracy: 0.6284 - val_loss: 1.6664 - val_capsnet_loss: 0.7857 - val_decoder_loss: 2.2466 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.6615 - capsnet_loss: 0.7811 - decoder_loss: 2.2458 - capsnet_accuracy: 0.6296 - val_loss: 1.6405 - val_capsnet_loss: 0.7599 - val_decoder_loss: 2.2465 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 1.6320 - capsnet_loss: 0.7489 - decoder_loss: 2.2529 - capsnet_accuracy: 0.6652 - val_loss: 1.5927 - val_capsnet_loss: 0.7121 - val_decoder_loss: 2.2462 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5728 - capsnet_loss: 0.6947 - decoder_loss: 2.2399 - capsnet_accuracy: 0.6581 - val_loss: 1.5142 - val_capsnet_loss: 0.6339 - val_decoder_loss: 2.2457 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.4928 - capsnet_loss: 0.6119 - decoder_loss: 2.2472 - capsnet_accuracy: 0.6219 - val_loss: 1.4041 - val_capsnet_loss: 0.5241 - val_decoder_loss: 2.2447 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 1.3734 - capsnet_loss: 0.4956 - decoder_loss: 2.2395 - capsnet_accuracy: 0.6390 - val_loss: 1.2788 - val_capsnet_loss: 0.3995 - val_decoder_loss: 2.2431 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2591 - capsnet_loss: 0.3834 - decoder_loss: 2.2340 - capsnet_accuracy: 0.5924 - val_loss: 1.1748 - val_capsnet_loss: 0.2965 - val_decoder_loss: 2.2406 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 1.1658 - capsnet_loss: 0.2887 - decoder_loss: 2.2375 - capsnet_accuracy: 0.5868 - val_loss: 1.1121 - val_capsnet_loss: 0.2350 - val_decoder_loss: 2.2375 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 1.1091 - capsnet_loss: 0.2345 - decoder_loss: 2.2310 - capsnet_accuracy: 0.5871 - val_loss: 1.0861 - val_capsnet_loss: 0.2103 - val_decoder_loss: 2.2343 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 1.0849 - capsnet_loss: 0.2105 - decoder_loss: 2.2308 - capsnet_accuracy: 0.6055 - val_loss: 1.0789 - val_capsnet_loss: 0.2043 - val_decoder_loss: 2.2311 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 1.0781 - capsnet_loss: 0.2041 - decoder_loss: 2.2295 - capsnet_accuracy: 0.6177 - val_loss: 1.0776 - val_capsnet_loss: 0.2041 - val_decoder_loss: 2.2282 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 1.0794 - capsnet_loss: 0.2067 - decoder_loss: 2.2262 - capsnet_accuracy: 0.5963 - val_loss: 1.0772 - val_capsnet_loss: 0.2048 - val_decoder_loss: 2.2255 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 1.0777 - capsnet_loss: 0.2042 - decoder_loss: 2.2284 - capsnet_accuracy: 0.6243 - val_loss: 1.0764 - val_capsnet_loss: 0.2050 - val_decoder_loss: 2.2230 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 1.0748 - capsnet_loss: 0.2046 - decoder_loss: 2.2199 - capsnet_accuracy: 0.6186 - val_loss: 1.0752 - val_capsnet_loss: 0.2047 - val_decoder_loss: 2.2207 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 1.0703 - capsnet_loss: 0.2001 - decoder_loss: 2.2200 - capsnet_accuracy: 0.6420 - val_loss: 1.0740 - val_capsnet_loss: 0.2044 - val_decoder_loss: 2.2184 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 1.0692 - capsnet_loss: 0.2000 - decoder_loss: 2.2172 - capsnet_accuracy: 0.6408 - val_loss: 1.0729 - val_capsnet_loss: 0.2042 - val_decoder_loss: 2.2162 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 1.0731 - capsnet_loss: 0.2052 - decoder_loss: 2.2140 - capsnet_accuracy: 0.6073 - val_loss: 1.0719 - val_capsnet_loss: 0.2041 - val_decoder_loss: 2.2139 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 1.0719 - capsnet_loss: 0.2039 - decoder_loss: 2.2143 - capsnet_accuracy: 0.6121 - val_loss: 1.0708 - val_capsnet_loss: 0.2039 - val_decoder_loss: 2.2116 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 1.0705 - capsnet_loss: 0.2047 - decoder_loss: 2.2087 - capsnet_accuracy: 0.6067 - val_loss: 1.0697 - val_capsnet_loss: 0.2037 - val_decoder_loss: 2.2093 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 1.0674 - capsnet_loss: 0.2032 - decoder_loss: 2.2046 - capsnet_accuracy: 0.6144 - val_loss: 1.0687 - val_capsnet_loss: 0.2036 - val_decoder_loss: 2.2069 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 1.0664 - capsnet_loss: 0.2024 - decoder_loss: 2.2039 - capsnet_accuracy: 0.6174 - val_loss: 1.0676 - val_capsnet_loss: 0.2035 - val_decoder_loss: 2.2044 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.0643 - capsnet_loss: 0.2019 - decoder_loss: 2.1999 - capsnet_accuracy: 0.6200 - val_loss: 1.0666 - val_capsnet_loss: 0.2035 - val_decoder_loss: 2.2018 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 1.0641 - capsnet_loss: 0.2030 - decoder_loss: 2.1967 - capsnet_accuracy: 0.6130 - val_loss: 1.0655 - val_capsnet_loss: 0.2035 - val_decoder_loss: 2.1990 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 1.0582 - capsnet_loss: 0.2008 - decoder_loss: 2.1872 - capsnet_accuracy: 0.6252 - val_loss: 1.0644 - val_capsnet_loss: 0.2035 - val_decoder_loss: 2.1963 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.0642 - capsnet_loss: 0.2053 - decoder_loss: 2.1911 - capsnet_accuracy: 0.5993 - val_loss: 1.0632 - val_capsnet_loss: 0.2034 - val_decoder_loss: 2.1935 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 1.0640 - capsnet_loss: 0.2057 - decoder_loss: 2.1896 - capsnet_accuracy: 0.5975 - val_loss: 1.0620 - val_capsnet_loss: 0.2033 - val_decoder_loss: 2.1906 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0535 - capsnet_loss: 0.2000 - decoder_loss: 2.1771 - capsnet_accuracy: 0.6287 - val_loss: 1.0608 - val_capsnet_loss: 0.2033 - val_decoder_loss: 2.1876 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0546 - capsnet_loss: 0.1982 - decoder_loss: 2.1847 - capsnet_accuracy: 0.6380 - val_loss: 1.0595 - val_capsnet_loss: 0.2032 - val_decoder_loss: 2.1844 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0554 - capsnet_loss: 0.2036 - decoder_loss: 2.1730 - capsnet_accuracy: 0.6064 - val_loss: 1.0582 - val_capsnet_loss: 0.2032 - val_decoder_loss: 2.1811 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 1.0591 - capsnet_loss: 0.2024 - decoder_loss: 2.1853 - capsnet_accuracy: 0.6159 - val_loss: 1.0568 - val_capsnet_loss: 0.2032 - val_decoder_loss: 2.1776 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 1.0539 - capsnet_loss: 0.1990 - decoder_loss: 2.1809 - capsnet_accuracy: 0.6308 - val_loss: 1.0554 - val_capsnet_loss: 0.2032 - val_decoder_loss: 2.1741 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 1.0611 - capsnet_loss: 0.2113 - decoder_loss: 2.1678 - capsnet_accuracy: 0.5646 - val_loss: 1.0539 - val_capsnet_loss: 0.2032 - val_decoder_loss: 2.1703 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 1.0572 - capsnet_loss: 0.2077 - decoder_loss: 2.1673 - capsnet_accuracy: 0.5834 - val_loss: 1.0524 - val_capsnet_loss: 0.2032 - val_decoder_loss: 2.1662 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.0509 - capsnet_loss: 0.2020 - decoder_loss: 2.1657 - capsnet_accuracy: 0.6144 - val_loss: 1.0508 - val_capsnet_loss: 0.2033 - val_decoder_loss: 2.1622 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0559 - capsnet_loss: 0.2105 - decoder_loss: 2.1567 - capsnet_accuracy: 0.5653 - val_loss: 1.0493 - val_capsnet_loss: 0.2033 - val_decoder_loss: 2.1580 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 1.0399 - capsnet_loss: 0.1984 - decoder_loss: 2.1467 - capsnet_accuracy: 0.6332 - val_loss: 1.0476 - val_capsnet_loss: 0.2032 - val_decoder_loss: 2.1540 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 1.0328 - capsnet_loss: 0.1928 - decoder_loss: 2.1429 - capsnet_accuracy: 0.6659 - val_loss: 1.0458 - val_capsnet_loss: 0.2031 - val_decoder_loss: 2.1499 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0400 - capsnet_loss: 0.1990 - decoder_loss: 2.1454 - capsnet_accuracy: 0.6290 - val_loss: 1.0441 - val_capsnet_loss: 0.2030 - val_decoder_loss: 2.1456 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 1.0398 - capsnet_loss: 0.1971 - decoder_loss: 2.1499 - capsnet_accuracy: 0.6396 - val_loss: 1.0423 - val_capsnet_loss: 0.2030 - val_decoder_loss: 2.1410 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.0342 - capsnet_loss: 0.2000 - decoder_loss: 2.1281 - capsnet_accuracy: 0.6227 - val_loss: 1.0403 - val_capsnet_loss: 0.2030 - val_decoder_loss: 2.1360 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 1.0405 - capsnet_loss: 0.2033 - decoder_loss: 2.1356 - capsnet_accuracy: 0.6019 - val_loss: 1.0384 - val_capsnet_loss: 0.2031 - val_decoder_loss: 2.1308 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 1.0401 - capsnet_loss: 0.2049 - decoder_loss: 2.1306 - capsnet_accuracy: 0.5957 - val_loss: 1.0364 - val_capsnet_loss: 0.2031 - val_decoder_loss: 2.1256 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 1.0404 - capsnet_loss: 0.2068 - decoder_loss: 2.1265 - capsnet_accuracy: 0.5828 - val_loss: 1.0343 - val_capsnet_loss: 0.2031 - val_decoder_loss: 2.1204 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 1.0245 - capsnet_loss: 0.1973 - decoder_loss: 2.1103 - capsnet_accuracy: 0.6382 - val_loss: 1.0321 - val_capsnet_loss: 0.2030 - val_decoder_loss: 2.1151 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 61ms/step - loss: 1.0242 - capsnet_loss: 0.1934 - decoder_loss: 2.1195 - capsnet_accuracy: 0.6624 - val_loss: 1.0299 - val_capsnet_loss: 0.2030 - val_decoder_loss: 2.1096 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0250 - capsnet_loss: 0.2013 - decoder_loss: 2.1011 - capsnet_accuracy: 0.6132 - val_loss: 1.0277 - val_capsnet_loss: 0.2029 - val_decoder_loss: 2.1039 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0212 - capsnet_loss: 0.1968 - decoder_loss: 2.1031 - capsnet_accuracy: 0.6386 - val_loss: 1.0253 - val_capsnet_loss: 0.2029 - val_decoder_loss: 2.0980 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 1.0239 - capsnet_loss: 0.2029 - decoder_loss: 2.0944 - capsnet_accuracy: 0.6005 - val_loss: 1.0229 - val_capsnet_loss: 0.2029 - val_decoder_loss: 2.0918 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.0141 - capsnet_loss: 0.1975 - decoder_loss: 2.0832 - capsnet_accuracy: 0.6328 - val_loss: 1.0204 - val_capsnet_loss: 0.2029 - val_decoder_loss: 2.0855 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 1.0290 - capsnet_loss: 0.2099 - decoder_loss: 2.0897 - capsnet_accuracy: 0.5627 - val_loss: 1.0178 - val_capsnet_loss: 0.2029 - val_decoder_loss: 2.0788 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 1.0158 - capsnet_loss: 0.2049 - decoder_loss: 2.0685 - capsnet_accuracy: 0.5892 - val_loss: 1.0152 - val_capsnet_loss: 0.2028 - val_decoder_loss: 2.0724 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.0187 - capsnet_loss: 0.2092 - decoder_loss: 2.0652 - capsnet_accuracy: 0.5639 - val_loss: 1.0126 - val_capsnet_loss: 0.2028 - val_decoder_loss: 2.0658 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 1.0151 - capsnet_loss: 0.2065 - decoder_loss: 2.0629 - capsnet_accuracy: 0.5856 - val_loss: 1.0099 - val_capsnet_loss: 0.2028 - val_decoder_loss: 2.0590 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.9972 - capsnet_loss: 0.1926 - decoder_loss: 2.0525 - capsnet_accuracy: 0.6573 - val_loss: 1.0072 - val_capsnet_loss: 0.2029 - val_decoder_loss: 2.0518 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 1.0039 - capsnet_loss: 0.1991 - decoder_loss: 2.0529 - capsnet_accuracy: 0.6189 - val_loss: 1.0041 - val_capsnet_loss: 0.2030 - val_decoder_loss: 2.0436 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.9945 - capsnet_loss: 0.1940 - decoder_loss: 2.0421 - capsnet_accuracy: 0.6473 - val_loss: 1.0010 - val_capsnet_loss: 0.2031 - val_decoder_loss: 2.0354 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 1.0048 - capsnet_loss: 0.2086 - decoder_loss: 2.0312 - capsnet_accuracy: 0.5767 - val_loss: 0.9979 - val_capsnet_loss: 0.2032 - val_decoder_loss: 2.0272 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.9897 - capsnet_loss: 0.1942 - decoder_loss: 2.0294 - capsnet_accuracy: 0.6474 - val_loss: 0.9947 - val_capsnet_loss: 0.2033 - val_decoder_loss: 2.0188 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9793 - capsnet_loss: 0.1905 - decoder_loss: 2.0121 - capsnet_accuracy: 0.6614 - val_loss: 0.9913 - val_capsnet_loss: 0.2035 - val_decoder_loss: 2.0095 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9877 - capsnet_loss: 0.2013 - decoder_loss: 2.0061 - capsnet_accuracy: 0.6096 - val_loss: 0.9878 - val_capsnet_loss: 0.2038 - val_decoder_loss: 2.0000 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.9750 - capsnet_loss: 0.1940 - decoder_loss: 1.9922 - capsnet_accuracy: 0.6496 - val_loss: 0.9843 - val_capsnet_loss: 0.2039 - val_decoder_loss: 1.9910 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.9780 - capsnet_loss: 0.1999 - decoder_loss: 1.9850 - capsnet_accuracy: 0.6182 - val_loss: 0.9808 - val_capsnet_loss: 0.2037 - val_decoder_loss: 1.9825 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.9757 - capsnet_loss: 0.2009 - decoder_loss: 1.9766 - capsnet_accuracy: 0.6120 - val_loss: 0.9772 - val_capsnet_loss: 0.2037 - val_decoder_loss: 1.9732 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 0.9754 - capsnet_loss: 0.2027 - decoder_loss: 1.9713 - capsnet_accuracy: 0.6046 - val_loss: 0.9735 - val_capsnet_loss: 0.2037 - val_decoder_loss: 1.9639 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.9711 - capsnet_loss: 0.2042 - decoder_loss: 1.9562 - capsnet_accuracy: 0.5953 - val_loss: 0.9698 - val_capsnet_loss: 0.2035 - val_decoder_loss: 1.9547 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9652 - capsnet_loss: 0.1989 - decoder_loss: 1.9550 - capsnet_accuracy: 0.6194 - val_loss: 0.9660 - val_capsnet_loss: 0.2035 - val_decoder_loss: 1.9453 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9623 - capsnet_loss: 0.2000 - decoder_loss: 1.9446 - capsnet_accuracy: 0.6126 - val_loss: 0.9622 - val_capsnet_loss: 0.2037 - val_decoder_loss: 1.9349 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.9663 - capsnet_loss: 0.2078 - decoder_loss: 1.9351 - capsnet_accuracy: 0.5669 - val_loss: 0.9584 - val_capsnet_loss: 0.2040 - val_decoder_loss: 1.9244 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.9493 - capsnet_loss: 0.1962 - decoder_loss: 1.9210 - capsnet_accuracy: 0.6412 - val_loss: 0.9543 - val_capsnet_loss: 0.2037 - val_decoder_loss: 1.9149 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 61ms/step - loss: 0.9487 - capsnet_loss: 0.2018 - decoder_loss: 1.9054 - capsnet_accuracy: 0.5989 - val_loss: 0.9503 - val_capsnet_loss: 0.2036 - val_decoder_loss: 1.9047 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.9394 - capsnet_loss: 0.1961 - decoder_loss: 1.8960 - capsnet_accuracy: 0.6307 - val_loss: 0.9461 - val_capsnet_loss: 0.2037 - val_decoder_loss: 1.8940 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.9378 - capsnet_loss: 0.1988 - decoder_loss: 1.8851 - capsnet_accuracy: 0.6233 - val_loss: 0.9420 - val_capsnet_loss: 0.2041 - val_decoder_loss: 1.8825 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 0.9276 - capsnet_loss: 0.1948 - decoder_loss: 1.8693 - capsnet_accuracy: 0.6462 - val_loss: 0.9378 - val_capsnet_loss: 0.2043 - val_decoder_loss: 1.8712 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.9296 - capsnet_loss: 0.1985 - decoder_loss: 1.8651 - capsnet_accuracy: 0.6281 - val_loss: 0.9336 - val_capsnet_loss: 0.2047 - val_decoder_loss: 1.8597 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.9221 - capsnet_loss: 0.1957 - decoder_loss: 1.8530 - capsnet_accuracy: 0.6456 - val_loss: 0.9294 - val_capsnet_loss: 0.2047 - val_decoder_loss: 1.8487 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 0.9144 - capsnet_loss: 0.1951 - decoder_loss: 1.8350 - capsnet_accuracy: 0.6477 - val_loss: 0.9251 - val_capsnet_loss: 0.2047 - val_decoder_loss: 1.8375 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9149 - capsnet_loss: 0.1969 - decoder_loss: 1.8317 - capsnet_accuracy: 0.6361 - val_loss: 0.9207 - val_capsnet_loss: 0.2047 - val_decoder_loss: 1.8266 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.9074 - capsnet_loss: 0.1926 - decoder_loss: 1.8235 - capsnet_accuracy: 0.6695 - val_loss: 0.9163 - val_capsnet_loss: 0.2047 - val_decoder_loss: 1.8153 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9137 - capsnet_loss: 0.2006 - decoder_loss: 1.8189 - capsnet_accuracy: 0.6118 - val_loss: 0.9117 - val_capsnet_loss: 0.2044 - val_decoder_loss: 1.8043 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9050 - capsnet_loss: 0.1983 - decoder_loss: 1.8027 - capsnet_accuracy: 0.6284 - val_loss: 0.9071 - val_capsnet_loss: 0.2039 - val_decoder_loss: 1.7939 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.8976 - capsnet_loss: 0.1952 - decoder_loss: 1.7916 - capsnet_accuracy: 0.6459 - val_loss: 0.9024 - val_capsnet_loss: 0.2034 - val_decoder_loss: 1.7833 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 0.8978 - capsnet_loss: 0.1996 - decoder_loss: 1.7810 - capsnet_accuracy: 0.6108 - val_loss: 0.8978 - val_capsnet_loss: 0.2035 - val_decoder_loss: 1.7711 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8914 - capsnet_loss: 0.1977 - decoder_loss: 1.7698 - capsnet_accuracy: 0.6133 - val_loss: 0.8931 - val_capsnet_loss: 0.2038 - val_decoder_loss: 1.7586 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8806 - capsnet_loss: 0.1926 - decoder_loss: 1.7551 - capsnet_accuracy: 0.6459 - val_loss: 0.8885 - val_capsnet_loss: 0.2036 - val_decoder_loss: 1.7472 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.8883 - capsnet_loss: 0.2023 - decoder_loss: 1.7501 - capsnet_accuracy: 0.5969 - val_loss: 0.8838 - val_capsnet_loss: 0.2038 - val_decoder_loss: 1.7349 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.8743 - capsnet_loss: 0.1971 - decoder_loss: 1.7276 - capsnet_accuracy: 0.6273 - val_loss: 0.8792 - val_capsnet_loss: 0.2039 - val_decoder_loss: 1.7226 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 0.8748 - capsnet_loss: 0.2025 - decoder_loss: 1.7152 - capsnet_accuracy: 0.5961 - val_loss: 0.8745 - val_capsnet_loss: 0.2040 - val_decoder_loss: 1.7106 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 65ms/step - loss: 0.8649 - capsnet_loss: 0.1969 - decoder_loss: 1.7039 - capsnet_accuracy: 0.6263 - val_loss: 0.8700 - val_capsnet_loss: 0.2038 - val_decoder_loss: 1.6994 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 0.8622 - capsnet_loss: 0.1980 - decoder_loss: 1.6944 - capsnet_accuracy: 0.6246 - val_loss: 0.8653 - val_capsnet_loss: 0.2041 - val_decoder_loss: 1.6868 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 65ms/step - loss: 0.8559 - capsnet_loss: 0.1991 - decoder_loss: 1.6756 - capsnet_accuracy: 0.6132 - val_loss: 0.8607 - val_capsnet_loss: 0.2041 - val_decoder_loss: 1.6749 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 0.8542 - capsnet_loss: 0.1991 - decoder_loss: 1.6712 - capsnet_accuracy: 0.6118 - val_loss: 0.8560 - val_capsnet_loss: 0.2046 - val_decoder_loss: 1.6616 - val_capsnet_accuracy: 0.6154\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 0.8437 - capsnet_loss: 0.1959 - decoder_loss: 1.6526 - capsnet_accuracy: 0.6319 - val_loss: 0.8513 - val_capsnet_loss: 0.2050 - val_decoder_loss: 1.6488 - val_capsnet_accuracy: 0.6154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5mlzs4mNJmM",
        "outputId": "fb05b71d-a50e-4bd2-dba5-2922811ef023"
      },
      "source": [
        "history.params"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epochs': 100, 'steps': 6, 'verbose': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "r6ONyQF_y_CM",
        "outputId": "4c13c1c2-4cdc-4cc6-f9e9-a194b2ffca31"
      },
      "source": [
        "results[-1:]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>capsnet_loss</th>\n",
              "      <th>decoder_loss</th>\n",
              "      <th>capsnet_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_capsnet_loss</th>\n",
              "      <th>val_decoder_loss</th>\n",
              "      <th>val_capsnet_accuracy</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.847334</td>\n",
              "      <td>0.198919</td>\n",
              "      <td>1.654121</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.851307</td>\n",
              "      <td>0.204974</td>\n",
              "      <td>1.648809</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.00001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  capsnet_loss  ...  val_capsnet_accuracy       lr\n",
              "99  0.847334      0.198919  ...              0.615385  0.00001\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXlIdxcwzBHO",
        "outputId": "e7f545fa-6886-4a4e-d585-6281c6002550"
      },
      "source": [
        "print (\"Accuracy for the training set: \", results.values[-1:][0][1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the training set:  0.19891875982284546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytHVOXIczBpy",
        "outputId": "a491d69f-6f35-4630-d545-fc91a146af19"
      },
      "source": [
        "print (\"Accuracy for the development test set: \", results.values[-1:][0][3])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the development test set:  0.6153846383094788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU2LFu7DVuE0",
        "outputId": "1e1f836f-9213-4c38-d2a2-4829f1479861"
      },
      "source": [
        "dev_predictions=model.predict([X_dev, y_dev])[0].round(2) \n",
        "type(dev_predictions[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs_tiled (None, 2, 1792, 4, 1)\n",
            "c (None, 2, 1792, 1, 1)\n",
            "c (None, 2, 1792, 1, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnHjrm3IXQo8",
        "outputId": "ccfa850d-b074-4e4e-8839-029cd45bc015"
      },
      "source": [
        "dev_predictions"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.77, 0.59],\n",
              "       [0.79, 0.59],\n",
              "       [0.77, 0.57],\n",
              "       [0.78, 0.55],\n",
              "       [0.8 , 0.57],\n",
              "       [0.77, 0.54],\n",
              "       [0.79, 0.56],\n",
              "       [0.8 , 0.57],\n",
              "       [0.79, 0.53],\n",
              "       [0.77, 0.54],\n",
              "       [0.79, 0.52],\n",
              "       [0.77, 0.57],\n",
              "       [0.77, 0.56],\n",
              "       [0.78, 0.6 ],\n",
              "       [0.77, 0.59],\n",
              "       [0.79, 0.6 ],\n",
              "       [0.8 , 0.63],\n",
              "       [0.78, 0.6 ],\n",
              "       [0.77, 0.59],\n",
              "       [0.79, 0.64],\n",
              "       [0.78, 0.63],\n",
              "       [0.8 , 0.63],\n",
              "       [0.82, 0.63],\n",
              "       [0.77, 0.57],\n",
              "       [0.78, 0.6 ],\n",
              "       [0.79, 0.61]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmD73r83VzaY",
        "outputId": "757aa796-dff8-46c7-9aab-ec798e95870a"
      },
      "source": [
        "dev_rounded_predictions=np.round(dev_predictions)\n",
        "indices = np.argmax(dev_predictions,1)\n",
        "for row, index in zip(dev_rounded_predictions, indices): row[index]=1\n",
        "dev_rounded_predictions[:20]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KISYV9umXuIm",
        "outputId": "678c9506-b905-4fc1-9c7e-6dfe127d11a6"
      },
      "source": [
        "y_dev[:20]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}