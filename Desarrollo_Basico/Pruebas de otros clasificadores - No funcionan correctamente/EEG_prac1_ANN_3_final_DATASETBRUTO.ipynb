{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2: Clasificación con ANN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos overfitting en la gráfica. Además:\n",
    "    \n",
    "    loss = 0.01\n",
    "    accuracy = 0.999 \n",
    "    val_loss = 2.09\n",
    "    val_accuracy = 0.68\n",
    "    \n",
    "Por tanto: \n",
    "\n",
    "    Etrain = 1-0.999 = 0.001\n",
    "    Etest = 1- 0.68 = 0.32\n",
    "    \n",
    "    Bias = Etrain - Ehuman = 0.001\n",
    "    Variance = Etest - Etrain = 0.32 - 0.001 = 0.319\n",
    "\n",
    "Observamos que hay un bajo bias pero una alta varianza: podemos regularizar, cambiar la arquitectura, añadir más datos...\n",
    "\n",
    "Se ha probado con , kernel_regularizer = keras.regularizers.l1_l2(0.001) pero ha tenido un mal resultado.\n",
    "Se ha añadido Dropout(rate = rate_dropout[i]) rate_dropout = [0.8, 0.4, 0.2, 0.1]\n",
    "Así: \n",
    "\n",
    "    loss = 0.345817\n",
    "    accuracy = 0.868716 \n",
    "    val_loss = 0.85344\n",
    "    val_accuracy = 0.688326\n",
    "    \n",
    "Por tanto: \n",
    "\n",
    "    Etrain = 1 - 0.868716  = 0.13\n",
    "    Etest = 1 - 0.688326 = 0.31\n",
    "    \n",
    "    Bias = Etrain - Ehuman = 0.13\n",
    "    Variance = Etest - Etrain = 0.31 - 0.13 = 0.18\n",
    "    \n",
    "El bias vuelve a estar alto (13%)\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROutput:\n",
    "    def __init__(self, task, data):\n",
    "        self.task = task\n",
    "        self.data = data\n",
    "        \n",
    "class OutTaskData: \n",
    "    def __init__(self, task, data): \n",
    "        self.task = task\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "# Primero leemos los registros\n",
    "def read_outputs(rec):\n",
    "    '''read_outputs(\"userS0091f1.mat\")'''\n",
    "    mat = sio.loadmat(rec)\n",
    "    mdata = mat['session']\n",
    "    val = mdata[0,0]\n",
    "    #output = ROutput(np.array(val[\"task\"]), np.array(val[\"data\"]))\n",
    "    output = ROutput(np.array(val[\"task\"]), np.array(val[\"data\"]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122368, 1) (122368, 32)\n",
      "(121856, 1) (121856, 32)\n",
      "(122368, 1) (122368, 32)\n",
      "(120832, 1) (120832, 32)\n",
      "X_train: (244224, 32)\n",
      "y_train: (244224,)\n",
      "X_dev: (122368, 32)\n",
      "y_dev: (122368,)\n",
      "ONE HOT ENCODER:\n",
      "X_train: (244224, 32)\n",
      "y_train: (244224, 3)\n",
      "X_dev: (122368, 32)\n",
      "y_dev: (122368, 3)\n",
      "\n",
      "X_test: (120832, 32)\n",
      "y_test: (120832,)\n",
      "ONE HOT ENCODER:\n",
      "X_test: (120832, 32)\n",
      "y_test: (120832, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "total_records = 4 # CAMBIAR SI HAY MAS REGISTROS\n",
    "\n",
    "task1 = 122 # SE PUEDE CAMBIAR\n",
    "task2 = 123 # SE PUEDE CAMBIAR\n",
    "task3 = 127 # SE PUEDE CAMBIAR\n",
    "user = '0091' # SE PUEDE CAMBIAR\n",
    "\n",
    "lTaskData = []\n",
    "for i_rec in range(1,total_records+1):\n",
    "        record = \"./RegistrosDeAzorin/user#\"+user+\"#20040101#0\"+str(i_rec)+\"#reg001.mat\"\n",
    "        output = read_outputs(record) # output.task será y, output.data será x\n",
    "        \n",
    "        if task3 != \"\":\n",
    "            outT = (output.task == task1) | (output.task == task2) | (output.task == task3) \n",
    "        else: \n",
    "            outT = (output.task == task1) | (output.task == task2)\n",
    "      \n",
    "        \n",
    "        outData = output.data[0:np.shape(output.data)[0],outT[0,:]]\n",
    "        outData = output.data[0:np.shape(output.data)[0],outT[0,:]]\n",
    "        \n",
    "        outTask = output.task[:,outT[0,:]]\n",
    "        outTD = OutTaskData(outTask, outData)\n",
    "        outTD.task = np.transpose(outTD.task)\n",
    "        outTD.data = np.transpose(outTD.data)\n",
    "        print(np.shape(outTD.task), np.shape(outTD.data))\n",
    "        lTaskData.append(outTD)\n",
    "        \n",
    "# Vamos a coger 2 registros para el entrenamiento, 1 para el conjunto dev set, 1 para el test set\n",
    "X_train, y_train, X_dev, y_dev = [],[],[],[] \n",
    "for j in range(0,total_records-2): # Cogemos 2 registros para entrenamiento\n",
    "    X_train.extend(lTaskData[j].data)\n",
    "    y_train.extend(lTaskData[j].task)\n",
    "\n",
    "\n",
    "X_dev.extend(lTaskData[total_records-2].data) # Cogemos un registro para el dev set\n",
    "y_dev.extend(lTaskData[total_records-2].task)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.ravel(np.array(y_train))\n",
    "X_dev = np.array(X_dev)\n",
    "y_dev = np.ravel(np.array(y_dev))\n",
    "\n",
    "print (\"X_train:\",X_train.shape)\n",
    "print (\"y_train:\",y_train.shape)\n",
    "\n",
    "print (\"X_dev:\",X_dev.shape)\n",
    "print (\"y_dev:\",y_dev.shape)\n",
    "\n",
    "# ONE HOT ENCODER\n",
    "encoder = make_pipeline(StandardScaler(), OneHotEncoder(categories=\"auto\", sparse=False)) # Function that one-hot encodes integers))\n",
    "y_one_hot = np.concatenate((y_train, y_dev), axis=0)\n",
    "y_one_hot = encoder.fit_transform (y_one_hot.reshape(-1,1))\n",
    "y_train = y_one_hot[:np.shape(y_train)[0]]\n",
    "y_dev = y_one_hot[np.shape(y_train)[0]:]\n",
    "\n",
    "print(\"ONE HOT ENCODER:\")\n",
    "print (\"X_train:\",X_train.shape)\n",
    "print (\"y_train:\",y_train.shape)\n",
    "\n",
    "print (\"X_dev:\",X_dev.shape)\n",
    "print (\"y_dev:\",y_dev.shape)\n",
    "\n",
    "\n",
    "X_test, y_test = [],[]\n",
    "X_test.extend(lTaskData[total_records-1].data) # Cogemos un registro para el test set\n",
    "y_test.extend(lTaskData[total_records-1].task)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.ravel(np.array(y_test))\n",
    "print()\n",
    "print (\"X_test:\",X_test.shape)\n",
    "print (\"y_test:\",y_test.shape)\n",
    "\n",
    "# ONE HOT ENCODER\n",
    "encoder = make_pipeline(StandardScaler(), OneHotEncoder(categories=\"auto\", sparse=False)) # Function that one-hot encodes integers))\n",
    "y_test = encoder.fit_transform (y_test.reshape(-1,1)) # y_one_hot\n",
    "\n",
    "print(\"ONE HOT ENCODER:\")\n",
    "print (\"X_test:\",X_test.shape)\n",
    "print (\"y_test:\",y_test.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = X_train.shape[1]\n",
    "OUTPUTS = y_train.shape[1]\n",
    "NUM_TRAINING_EXAMPLES = int(round(X_train.shape[0]/1))\n",
    "NUM_DEV_EXAMPLES = int(round(y_train.shape[0]/1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data is displayed to test correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2376.6362 ,  -3993.0707 ,   -292.01509,  -1714.575  ,\n",
       "         -8560.3748 , -12959.398  , -15365.081  ,   6104.5356 ,\n",
       "          3067.4475 ,   4910.1941 ,   -543.51462,   -660.07691,\n",
       "          3463.7905 ,  -4059.2894 ,  11748.775  ,   9284.2172 ,\n",
       "          3479.9779 ,  -2588.5108 ,   3064.4787 ,  -3694.9775 ,\n",
       "         -1908.1059 ,   4332.8826 , -13441.991  ,  -7562.5642 ,\n",
       "         -4529.9448 ,  -3280.6658 ,  -3277.9158 ,   2412.3237 ,\n",
       "         -2788.7917 ,   5308.7558 ,   7220.2523 ,  11014.589  ],\n",
       "       [  2385.5737 ,  -3979.3833 ,   -284.7026 ,  -1706.6062 ,\n",
       "         -8550.4998 , -12953.335  , -15362.925  ,   6113.7543 ,\n",
       "          3079.7912 ,   4918.819  ,   -531.70214,   -650.48317,\n",
       "          3474.6342 ,  -4048.6019 ,  11762.463  ,   9295.5297 ,\n",
       "          3491.3842 ,  -2576.7296 ,   3075.9787 ,  -3683.0401 ,\n",
       "         -1896.6059 ,   4344.7888 , -13428.397  ,  -7562.2517 ,\n",
       "         -4517.101  ,  -3269.2596 ,  -3267.8221 ,   2422.1049 ,\n",
       "         -2779.4792 ,   5306.6933 ,   7232.2835 ,  11026.745  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6107.5043 ,  -5426.6931 ,   -518.45217,    171.85906,\n",
       "         -7640.2203 , -11927.744  , -11750.088  ,   4710.3819 ,\n",
       "          5837.4736 ,   2545.0734 ,    693.73309,    293.98383,\n",
       "           395.38989,  -3308.9158 ,  10355.028  ,   8593.156  ,\n",
       "          4236.5078 ,   2777.2917 ,   6293.0352 ,  -1344.2944 ,\n",
       "          1547.2628 ,   8932.1241 ,  -8558.7811 ,  -9692.154  ,\n",
       "          -624.98322,  -2038.1994 ,   1662.9813 ,   1707.7312 ,\n",
       "           266.51513,   6810.1593 ,   7133.4087 ,  12385.899  ],\n",
       "       [  6117.7231 ,  -5417.9431 ,   -507.42094,    181.39029,\n",
       "         -7630.6265 , -11920.275  , -11741.119  ,   4720.0069 ,\n",
       "          5850.2861 ,   2556.1672 ,    707.57682,    305.98381,\n",
       "           407.10862,  -3294.1658 ,  10369.621  ,   8603.781  ,\n",
       "          4245.6015 ,   2785.198  ,   6303.3477 ,  -1341.4506 ,\n",
       "          1555.5752 ,   8944.6553 ,  -8547.1873 ,  -9680.4977 ,\n",
       "          -614.45199,  -2026.1056 ,   1674.1688 ,   1720.7937 ,\n",
       "           278.10886,   6820.628  ,   7144.8462 ,  12395.118  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "learning_rate = 0.001\n",
    "batch_size = 250 \n",
    "n_neurons_per_hlayer = [500, 250, 75, 25] # Number of units per layer, 4 hidden layers\n",
    "rate_dropout = [0.8, 0.4, 0.2, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Build the model: 96-500-250-75-25-3 deep neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepFeedforward\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 500)               16500     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 75)                18825     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 25)                1900      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 162,553\n",
      "Trainable params: 162,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"DeepFeedforward\")\n",
    "\n",
    "model.add(keras.layers.InputLayer(input_shape=(INPUTS,), batch_size=None))\n",
    "\n",
    "i = 0\n",
    "for neurons in n_neurons_per_hlayer:\n",
    "    model.add(keras.layers.Dense(neurons, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "    #model.add(keras.layers.Dropout(rate = rate_dropout[i]))\n",
    "    #model.add(keras.layers.BatchNormalization())\n",
    "    i+=1\n",
    "\n",
    "model.add(keras.layers.Dense(OUTPUTS, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x18ca61de820>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18ca595afd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18ca56947f0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18ca568cfd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x18ca5975370>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_5\n",
      "dense_6\n",
      "dense_7\n",
      "dense_8\n",
      "dense_9\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers: print (l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the parameters of a layer can bee accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[0].get_weights()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24012922,  0.5682347 , -0.2092413 , ...,  0.03145886,\n",
       "         0.36078095, -0.28126195],\n",
       "       [-0.04698908,  0.26469404,  0.43809462, ..., -0.56633115,\n",
       "        -0.21256223,  0.49595243],\n",
       "       [ 0.03572486, -0.09099077,  0.13319801, ..., -0.07594829,\n",
       "         0.10134641,  0.24191952],\n",
       "       ...,\n",
       "       [ 0.41282037,  0.00662193, -0.39523727, ..., -0.0466457 ,\n",
       "         0.02559994, -0.39150625],\n",
       "       [-0.42238045, -0.49491793, -0.2566481 , ...,  0.25114343,\n",
       "        -0.1365795 ,  0.21539097],\n",
       "       [ 0.22570309,  0.11395899,  0.02570103, ..., -0.18149869,\n",
       "        -0.16666283,  0.38738167]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases # Bias de la primera capa: 500 bias inicializados a 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=[\"categorical_accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train the model with M-BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "977/977 [==============================] - 16s 15ms/step - loss: 538.7100 - categorical_accuracy: 0.3528 - val_loss: 160.6158 - val_categorical_accuracy: 0.3975\n",
      "Epoch 2/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 55.0120 - categorical_accuracy: 0.3966 - val_loss: 125.2513 - val_categorical_accuracy: 0.2803\n",
      "Epoch 3/2000\n",
      "977/977 [==============================] - 13s 14ms/step - loss: 11.6136 - categorical_accuracy: 0.4398 - val_loss: 36.5344 - val_categorical_accuracy: 0.3973\n",
      "Epoch 4/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 2.6617 - categorical_accuracy: 0.5303 - val_loss: 42.8657 - val_categorical_accuracy: 0.2904\n",
      "Epoch 5/2000\n",
      "977/977 [==============================] - 13s 14ms/step - loss: 1.4077 - categorical_accuracy: 0.5994 - val_loss: 44.5819 - val_categorical_accuracy: 0.3052\n",
      "Epoch 6/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 4.2840 - categorical_accuracy: 0.4184 - val_loss: 39.9398 - val_categorical_accuracy: 0.3601\n",
      "Epoch 7/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 0.9103 - categorical_accuracy: 0.5216 - val_loss: 42.0780 - val_categorical_accuracy: 0.3209\n",
      "Epoch 8/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 0.9419 - categorical_accuracy: 0.5011 - val_loss: 41.1496 - val_categorical_accuracy: 0.3508\n",
      "Epoch 9/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.1004 - categorical_accuracy: 0.4311 - val_loss: 461.6013 - val_categorical_accuracy: 0.3975\n",
      "Epoch 10/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0850 - categorical_accuracy: 0.3869 - val_loss: 461.5072 - val_categorical_accuracy: 0.3975\n",
      "Epoch 11/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0844 - categorical_accuracy: 0.3883 - val_loss: 444.8504 - val_categorical_accuracy: 0.3975\n",
      "Epoch 12/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0844 - categorical_accuracy: 0.3894 - val_loss: 424.1456 - val_categorical_accuracy: 0.3975\n",
      "Epoch 13/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0848 - categorical_accuracy: 0.3849 - val_loss: 427.0676 - val_categorical_accuracy: 0.3975\n",
      "Epoch 14/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0846 - categorical_accuracy: 0.3883 - val_loss: 418.0771 - val_categorical_accuracy: 0.3975\n",
      "Epoch 15/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0847 - categorical_accuracy: 0.3878 - val_loss: 410.1524 - val_categorical_accuracy: 0.3975\n",
      "Epoch 16/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0845 - categorical_accuracy: 0.3892 - val_loss: 383.8878 - val_categorical_accuracy: 0.3975\n",
      "Epoch 17/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0849 - categorical_accuracy: 0.3870 - val_loss: 384.9584 - val_categorical_accuracy: 0.3975\n",
      "Epoch 18/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0847 - categorical_accuracy: 0.3868 - val_loss: 378.6083 - val_categorical_accuracy: 0.3975\n",
      "Epoch 19/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0848 - categorical_accuracy: 0.3864 - val_loss: 355.4742 - val_categorical_accuracy: 0.3975\n",
      "Epoch 20/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0852 - categorical_accuracy: 0.3871 - val_loss: 368.9866 - val_categorical_accuracy: 0.3975\n",
      "Epoch 21/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0848 - categorical_accuracy: 0.3886 - val_loss: 353.2130 - val_categorical_accuracy: 0.3975\n",
      "Epoch 22/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0841 - categorical_accuracy: 0.3885 - val_loss: 339.5016 - val_categorical_accuracy: 0.3975\n",
      "Epoch 23/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0844 - categorical_accuracy: 0.3886 - val_loss: 335.7540 - val_categorical_accuracy: 0.3975\n",
      "Epoch 24/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0839 - categorical_accuracy: 0.3902 - val_loss: 319.2050 - val_categorical_accuracy: 0.3975.0837 - categorical_accuracy: \n",
      "Epoch 25/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0844 - categorical_accuracy: 0.3872 - val_loss: 313.6599 - val_categorical_accuracy: 0.3975\n",
      "Epoch 26/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0845 - categorical_accuracy: 0.3877 - val_loss: 317.8942 - val_categorical_accuracy: 0.3975\n",
      "Epoch 27/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0845 - categorical_accuracy: 0.3871 - val_loss: 289.6469 - val_categorical_accuracy: 0.3975\n",
      "Epoch 28/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0849 - categorical_accuracy: 0.3881 - val_loss: 298.3982 - val_categorical_accuracy: 0.3975\n",
      "Epoch 29/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0846 - categorical_accuracy: 0.3879 - val_loss: 297.2758 - val_categorical_accuracy: 0.3975\n",
      "Epoch 30/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0846 - categorical_accuracy: 0.3871 - val_loss: 267.2624 - val_categorical_accuracy: 0.3975\n",
      "Epoch 31/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0840 - categorical_accuracy: 0.3884 - val_loss: 259.7862 - val_categorical_accuracy: 0.3975\n",
      "Epoch 32/2000\n",
      "977/977 [==============================] - 13s 14ms/step - loss: 1.0850 - categorical_accuracy: 0.3867 - val_loss: 263.6993 - val_categorical_accuracy: 0.3975\n",
      "Epoch 33/2000\n",
      "977/977 [==============================] - 15s 15ms/step - loss: 1.0844 - categorical_accuracy: 0.3866 - val_loss: 270.2722 - val_categorical_accuracy: 0.3975\n",
      "Epoch 34/2000\n",
      "977/977 [==============================] - 15s 15ms/step - loss: 1.0842 - categorical_accuracy: 0.3874 - val_loss: 254.3873 - val_categorical_accuracy: 0.3975\n",
      "Epoch 35/2000\n",
      "977/977 [==============================] - 15s 15ms/step - loss: 1.0846 - categorical_accuracy: 0.3867 - val_loss: 248.9285 - val_categorical_accuracy: 0.3975\n",
      "Epoch 36/2000\n",
      "977/977 [==============================] - 15s 15ms/step - loss: 1.0842 - categorical_accuracy: 0.3882 - val_loss: 248.3163 - val_categorical_accuracy: 0.3975\n",
      "Epoch 37/2000\n",
      "977/977 [==============================] - 15s 16ms/step - loss: 1.0847 - categorical_accuracy: 0.3876 - val_loss: 250.2104 - val_categorical_accuracy: 0.3975\n",
      "Epoch 38/2000\n",
      "977/977 [==============================] - 16s 16ms/step - loss: 1.0846 - categorical_accuracy: 0.3875 - val_loss: 244.0123 - val_categorical_accuracy: 0.3975\n",
      "Epoch 39/2000\n",
      "977/977 [==============================] - 14s 14ms/step - loss: 1.0844 - categorical_accuracy: 0.3871 - val_loss: 242.6267 - val_categorical_accuracy: 0.3975\n",
      "Epoch 40/2000\n",
      "977/977 [==============================] - 14s 15ms/step - loss: 1.0851 - categorical_accuracy: 0.3877 - val_loss: 261.4934 - val_categorical_accuracy: 0.3975\n",
      "Epoch 41/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0840 - categorical_accuracy: 0.3891 - val_loss: 233.6441 - val_categorical_accuracy: 0.3975\n",
      "Epoch 42/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0844 - categorical_accuracy: 0.3880 - val_loss: 238.4957 - val_categorical_accuracy: 0.3975\n",
      "Epoch 43/2000\n",
      "977/977 [==============================] - 14s 14ms/step - loss: 1.0846 - categorical_accuracy: 0.3892 - val_loss: 241.7120 - val_categorical_accuracy: 0.3975\n",
      "Epoch 44/2000\n",
      "977/977 [==============================] - 12s 13ms/step - loss: 1.0847 - categorical_accuracy: 0.3893 - val_loss: 217.6337 - val_categorical_accuracy: 0.3975\n",
      "Epoch 45/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3877 - val_loss: 224.4470 - val_categorical_accuracy: 0.3975\n",
      "Epoch 46/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0848 - categorical_accuracy: 0.3870 - val_loss: 226.2416 - val_categorical_accuracy: 0.3975\n",
      "Epoch 47/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3871 - val_loss: 225.1524 - val_categorical_accuracy: 0.3975\n",
      "Epoch 48/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3876 - val_loss: 217.6362 - val_categorical_accuracy: 0.3975\n",
      "Epoch 49/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3875 - val_loss: 218.8291 - val_categorical_accuracy: 0.3975\n",
      "Epoch 50/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0849 - categorical_accuracy: 0.3869 - val_loss: 223.5700 - val_categorical_accuracy: 0.3975\n",
      "Epoch 51/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0849 - categorical_accuracy: 0.3876 - val_loss: 208.6927 - val_categorical_accuracy: 0.3975\n",
      "Epoch 52/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0841 - categorical_accuracy: 0.3889 - val_loss: 212.2182 - val_categorical_accuracy: 0.3975\n",
      "Epoch 53/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0851 - categorical_accuracy: 0.3875 - val_loss: 210.9988 - val_categorical_accuracy: 0.3975\n",
      "Epoch 54/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3870 - val_loss: 205.7636 - val_categorical_accuracy: 0.3975\n",
      "Epoch 55/2000\n",
      "977/977 [==============================] - 14s 14ms/step - loss: 1.0849 - categorical_accuracy: 0.3882 - val_loss: 220.4972 - val_categorical_accuracy: 0.3975\n",
      "Epoch 56/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3874 - val_loss: 223.7827 - val_categorical_accuracy: 0.3975\n",
      "Epoch 57/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0847 - categorical_accuracy: 0.3886 - val_loss: 222.8023 - val_categorical_accuracy: 0.3975\n",
      "Epoch 58/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3870 - val_loss: 214.1508 - val_categorical_accuracy: 0.3975\n",
      "Epoch 59/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3881 - val_loss: 216.2837 - val_categorical_accuracy: 0.3975\n",
      "Epoch 60/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3877 - val_loss: 213.0053 - val_categorical_accuracy: 0.3975\n",
      "Epoch 61/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3862 - val_loss: 212.7391 - val_categorical_accuracy: 0.3975\n",
      "Epoch 62/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3871 - val_loss: 207.6910 - val_categorical_accuracy: 0.3975\n",
      "Epoch 63/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3889 - val_loss: 205.1281 - val_categorical_accuracy: 0.3975\n",
      "Epoch 64/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3891 - val_loss: 200.8675 - val_categorical_accuracy: 0.3975\n",
      "Epoch 65/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0838 - categorical_accuracy: 0.3890 - val_loss: 201.7867 - val_categorical_accuracy: 0.3975\n",
      "Epoch 66/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3881 - val_loss: 193.9881 - val_categorical_accuracy: 0.3975\n",
      "Epoch 67/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3852 - val_loss: 188.4772 - val_categorical_accuracy: 0.3975\n",
      "Epoch 68/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0849 - categorical_accuracy: 0.3870 - val_loss: 184.4191 - val_categorical_accuracy: 0.3975\n",
      "Epoch 69/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3895 - val_loss: 179.0543 - val_categorical_accuracy: 0.3975\n",
      "Epoch 70/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3884 - val_loss: 179.0876 - val_categorical_accuracy: 0.3975\n",
      "Epoch 71/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3901 - val_loss: 176.1622 - val_categorical_accuracy: 0.3975\n",
      "Epoch 72/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3877 - val_loss: 180.3998 - val_categorical_accuracy: 0.3975\n",
      "Epoch 73/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3872 - val_loss: 176.1604 - val_categorical_accuracy: 0.3975\n",
      "Epoch 74/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0848 - categorical_accuracy: 0.3864 - val_loss: 179.7270 - val_categorical_accuracy: 0.3975\n",
      "Epoch 75/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3879 - val_loss: 174.6042 - val_categorical_accuracy: 0.3975\n",
      "Epoch 76/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3876 - val_loss: 174.5879 - val_categorical_accuracy: 0.3975\n",
      "Epoch 77/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3872 - val_loss: 174.3877 - val_categorical_accuracy: 0.3975\n",
      "Epoch 78/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3886 - val_loss: 172.6926 - val_categorical_accuracy: 0.3975\n",
      "Epoch 79/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3881 - val_loss: 173.2516 - val_categorical_accuracy: 0.3975\n",
      "Epoch 80/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3877 - val_loss: 170.5744 - val_categorical_accuracy: 0.3975\n",
      "Epoch 81/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0850 - categorical_accuracy: 0.3876 - val_loss: 170.0653 - val_categorical_accuracy: 0.3975\n",
      "Epoch 82/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3871 - val_loss: 177.4021 - val_categorical_accuracy: 0.3975\n",
      "Epoch 83/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3876 - val_loss: 172.6626 - val_categorical_accuracy: 0.3975\n",
      "Epoch 84/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0851 - categorical_accuracy: 0.3862 - val_loss: 175.0629 - val_categorical_accuracy: 0.3975\n",
      "Epoch 85/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0840 - categorical_accuracy: 0.3893 - val_loss: 172.1758 - val_categorical_accuracy: 0.3975\n",
      "Epoch 86/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0852 - categorical_accuracy: 0.3858 - val_loss: 175.4315 - val_categorical_accuracy: 0.3975\n",
      "Epoch 87/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0840 - categorical_accuracy: 0.3885 - val_loss: 174.2879 - val_categorical_accuracy: 0.3975\n",
      "Epoch 88/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0841 - categorical_accuracy: 0.3886 - val_loss: 173.1873 - val_categorical_accuracy: 0.3975\n",
      "Epoch 89/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3883 - val_loss: 172.0581 - val_categorical_accuracy: 0.3975\n",
      "Epoch 90/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3887 - val_loss: 170.6537 - val_categorical_accuracy: 0.3975\n",
      "Epoch 91/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3874 - val_loss: 172.1798 - val_categorical_accuracy: 0.3975\n",
      "Epoch 92/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3875 - val_loss: 171.8357 - val_categorical_accuracy: 0.3975\n",
      "Epoch 93/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3864 - val_loss: 168.1380 - val_categorical_accuracy: 0.3975\n",
      "Epoch 94/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3876 - val_loss: 171.3721 - val_categorical_accuracy: 0.3975\n",
      "Epoch 95/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0849 - categorical_accuracy: 0.3868 - val_loss: 170.8678 - val_categorical_accuracy: 0.3975\n",
      "Epoch 96/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3890 - val_loss: 170.9116 - val_categorical_accuracy: 0.3975\n",
      "Epoch 97/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3878 - val_loss: 168.2817 - val_categorical_accuracy: 0.3975\n",
      "Epoch 98/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3878 - val_loss: 168.8708 - val_categorical_accuracy: 0.3975\n",
      "Epoch 99/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0848 - categorical_accuracy: 0.3865 - val_loss: 167.2402 - val_categorical_accuracy: 0.3975\n",
      "Epoch 100/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0841 - categorical_accuracy: 0.3880 - val_loss: 166.3116 - val_categorical_accuracy: 0.3975\n",
      "Epoch 101/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3879 - val_loss: 169.5081 - val_categorical_accuracy: 0.3975\n",
      "Epoch 102/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3883 - val_loss: 165.8433 - val_categorical_accuracy: 0.3975\n",
      "Epoch 103/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3883 - val_loss: 166.6248 - val_categorical_accuracy: 0.3975\n",
      "Epoch 104/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0852 - categorical_accuracy: 0.3863 - val_loss: 167.4008 - val_categorical_accuracy: 0.3975\n",
      "Epoch 105/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0840 - categorical_accuracy: 0.3884 - val_loss: 166.7557 - val_categorical_accuracy: 0.3975\n",
      "Epoch 106/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3893 - val_loss: 167.1754 - val_categorical_accuracy: 0.3975\n",
      "Epoch 107/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3881 - val_loss: 165.2441 - val_categorical_accuracy: 0.3975\n",
      "Epoch 108/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0840 - categorical_accuracy: 0.3882 - val_loss: 164.6172 - val_categorical_accuracy: 0.3975\n",
      "Epoch 109/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3897 - val_loss: 162.1585 - val_categorical_accuracy: 0.3975\n",
      "Epoch 110/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0840 - categorical_accuracy: 0.3876 - val_loss: 166.4176 - val_categorical_accuracy: 0.3975\n",
      "Epoch 111/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3878 - val_loss: 164.6042 - val_categorical_accuracy: 0.3975\n",
      "Epoch 112/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0853 - categorical_accuracy: 0.3864 - val_loss: 164.4973 - val_categorical_accuracy: 0.3975\n",
      "Epoch 113/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0848 - categorical_accuracy: 0.3867 - val_loss: 164.0347 - val_categorical_accuracy: 0.3975\n",
      "Epoch 114/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3875 - val_loss: 163.5584 - val_categorical_accuracy: 0.3975\n",
      "Epoch 115/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0851 - categorical_accuracy: 0.3875 - val_loss: 162.7721 - val_categorical_accuracy: 0.3975\n",
      "Epoch 116/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3866 - val_loss: 162.0865 - val_categorical_accuracy: 0.3975\n",
      "Epoch 117/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0848 - categorical_accuracy: 0.3879 - val_loss: 162.6385 - val_categorical_accuracy: 0.3975\n",
      "Epoch 118/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3890 - val_loss: 160.1223 - val_categorical_accuracy: 0.3975\n",
      "Epoch 119/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3887 - val_loss: 162.1689 - val_categorical_accuracy: 0.3975\n",
      "Epoch 120/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0852 - categorical_accuracy: 0.3853 - val_loss: 161.2216 - val_categorical_accuracy: 0.3975\n",
      "Epoch 121/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3871 - val_loss: 162.6050 - val_categorical_accuracy: 0.3975\n",
      "Epoch 122/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3867 - val_loss: 160.4991 - val_categorical_accuracy: 0.3975\n",
      "Epoch 123/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0848 - categorical_accuracy: 0.3894 - val_loss: 161.2196 - val_categorical_accuracy: 0.3975\n",
      "Epoch 124/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3900 - val_loss: 159.4467 - val_categorical_accuracy: 0.3975\n",
      "Epoch 125/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0848 - categorical_accuracy: 0.3881 - val_loss: 161.2931 - val_categorical_accuracy: 0.3975\n",
      "Epoch 126/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3884 - val_loss: 157.5799 - val_categorical_accuracy: 0.3975\n",
      "Epoch 127/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3877 - val_loss: 156.7831 - val_categorical_accuracy: 0.3975\n",
      "Epoch 128/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3878 - val_loss: 158.3465 - val_categorical_accuracy: 0.3975\n",
      "Epoch 129/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0853 - categorical_accuracy: 0.3867 - val_loss: 157.1850 - val_categorical_accuracy: 0.3975\n",
      "Epoch 130/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0841 - categorical_accuracy: 0.3886 - val_loss: 155.7897 - val_categorical_accuracy: 0.3975\n",
      "Epoch 131/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0848 - categorical_accuracy: 0.3875 - val_loss: 157.2178 - val_categorical_accuracy: 0.3975\n",
      "Epoch 132/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0849 - categorical_accuracy: 0.3873 - val_loss: 156.7236 - val_categorical_accuracy: 0.3975\n",
      "Epoch 133/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0835 - categorical_accuracy: 0.3902 - val_loss: 157.6912 - val_categorical_accuracy: 0.3975\n",
      "Epoch 134/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0850 - categorical_accuracy: 0.3861 - val_loss: 156.6309 - val_categorical_accuracy: 0.3975\n",
      "Epoch 135/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3875 - val_loss: 158.0730 - val_categorical_accuracy: 0.3975\n",
      "Epoch 136/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0848 - categorical_accuracy: 0.3872 - val_loss: 156.4039 - val_categorical_accuracy: 0.3975\n",
      "Epoch 137/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3878 - val_loss: 156.1514 - val_categorical_accuracy: 0.3975\n",
      "Epoch 138/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0839 - categorical_accuracy: 0.3880 - val_loss: 155.5981 - val_categorical_accuracy: 0.3975\n",
      "Epoch 139/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3875 - val_loss: 153.5829 - val_categorical_accuracy: 0.3975\n",
      "Epoch 140/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0840 - categorical_accuracy: 0.3878 - val_loss: 153.6706 - val_categorical_accuracy: 0.3975\n",
      "Epoch 141/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3872 - val_loss: 152.8798 - val_categorical_accuracy: 0.3975\n",
      "Epoch 142/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0840 - categorical_accuracy: 0.3888 - val_loss: 150.6015 - val_categorical_accuracy: 0.3975\n",
      "Epoch 143/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3875 - val_loss: 149.5464 - val_categorical_accuracy: 0.3975\n",
      "Epoch 144/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3882 - val_loss: 148.9969 - val_categorical_accuracy: 0.3975\n",
      "Epoch 145/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0849 - categorical_accuracy: 0.3871 - val_loss: 152.1486 - val_categorical_accuracy: 0.3975\n",
      "Epoch 146/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3882 - val_loss: 149.6264 - val_categorical_accuracy: 0.3975\n",
      "Epoch 147/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0850 - categorical_accuracy: 0.3859 - val_loss: 147.8869 - val_categorical_accuracy: 0.3975\n",
      "Epoch 148/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3887 - val_loss: 148.4985 - val_categorical_accuracy: 0.3975\n",
      "Epoch 149/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3880 - val_loss: 147.7551 - val_categorical_accuracy: 0.3975\n",
      "Epoch 150/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3872 - val_loss: 147.9434 - val_categorical_accuracy: 0.3975\n",
      "Epoch 151/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3880 - val_loss: 145.7017 - val_categorical_accuracy: 0.3975\n",
      "Epoch 152/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3861 - val_loss: 143.6642 - val_categorical_accuracy: 0.3975\n",
      "Epoch 153/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3873 - val_loss: 145.4383 - val_categorical_accuracy: 0.3975\n",
      "Epoch 154/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3879 - val_loss: 145.4474 - val_categorical_accuracy: 0.3975\n",
      "Epoch 155/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0841 - categorical_accuracy: 0.3889 - val_loss: 141.5125 - val_categorical_accuracy: 0.3975\n",
      "Epoch 156/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3877 - val_loss: 144.0303 - val_categorical_accuracy: 0.3975\n",
      "Epoch 157/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3890 - val_loss: 140.5346 - val_categorical_accuracy: 0.3975\n",
      "Epoch 158/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3886 - val_loss: 141.7119 - val_categorical_accuracy: 0.3975\n",
      "Epoch 159/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3869 - val_loss: 141.7304 - val_categorical_accuracy: 0.3975\n",
      "Epoch 160/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3867 - val_loss: 142.0683 - val_categorical_accuracy: 0.3975\n",
      "Epoch 161/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0849 - categorical_accuracy: 0.3863 - val_loss: 141.3066 - val_categorical_accuracy: 0.3975\n",
      "Epoch 162/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3882 - val_loss: 136.2779 - val_categorical_accuracy: 0.3975\n",
      "Epoch 163/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0851 - categorical_accuracy: 0.3873 - val_loss: 137.8787 - val_categorical_accuracy: 0.3975\n",
      "Epoch 164/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3886 - val_loss: 135.7085 - val_categorical_accuracy: 0.3975\n",
      "Epoch 165/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3875 - val_loss: 136.9372 - val_categorical_accuracy: 0.3975\n",
      "Epoch 166/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3855 - val_loss: 135.3333 - val_categorical_accuracy: 0.3975\n",
      "Epoch 167/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3890 - val_loss: 134.3127 - val_categorical_accuracy: 0.3975\n",
      "Epoch 168/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3869 - val_loss: 131.9029 - val_categorical_accuracy: 0.3975\n",
      "Epoch 169/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0844 - categorical_accuracy: 0.3889 - val_loss: 129.7703 - val_categorical_accuracy: 0.3975\n",
      "Epoch 170/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0847 - categorical_accuracy: 0.3872 - val_loss: 133.6833 - val_categorical_accuracy: 0.3975\n",
      "Epoch 171/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0850 - categorical_accuracy: 0.3866 - val_loss: 133.1057 - val_categorical_accuracy: 0.3975\n",
      "Epoch 172/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3884 - val_loss: 126.1144 - val_categorical_accuracy: 0.3975\n",
      "Epoch 173/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3872 - val_loss: 125.7863 - val_categorical_accuracy: 0.3975\n",
      "Epoch 174/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0851 - categorical_accuracy: 0.3875 - val_loss: 126.8214 - val_categorical_accuracy: 0.3975\n",
      "Epoch 175/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3891 - val_loss: 122.2346 - val_categorical_accuracy: 0.3975\n",
      "Epoch 176/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3877 - val_loss: 121.9274 - val_categorical_accuracy: 0.3975\n",
      "Epoch 177/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0848 - categorical_accuracy: 0.3875 - val_loss: 124.5446 - val_categorical_accuracy: 0.3975\n",
      "Epoch 178/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0840 - categorical_accuracy: 0.3888 - val_loss: 118.6596 - val_categorical_accuracy: 0.3975\n",
      "Epoch 179/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3882 - val_loss: 118.4307 - val_categorical_accuracy: 0.3975\n",
      "Epoch 180/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0837 - categorical_accuracy: 0.3895 - val_loss: 115.4432 - val_categorical_accuracy: 0.3975\n",
      "Epoch 181/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3878 - val_loss: 118.7576 - val_categorical_accuracy: 0.3975\n",
      "Epoch 182/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3877 - val_loss: 114.9573 - val_categorical_accuracy: 0.3975\n",
      "Epoch 183/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3886 - val_loss: 109.5818 - val_categorical_accuracy: 0.3975\n",
      "Epoch 184/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3875 - val_loss: 112.0586 - val_categorical_accuracy: 0.3975\n",
      "Epoch 185/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3861 - val_loss: 109.3729 - val_categorical_accuracy: 0.3975\n",
      "Epoch 186/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0839 - categorical_accuracy: 0.3879 - val_loss: 104.7823 - val_categorical_accuracy: 0.3973\n",
      "Epoch 187/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3883 - val_loss: 104.3489 - val_categorical_accuracy: 0.3971\n",
      "Epoch 188/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3887 - val_loss: 100.6969 - val_categorical_accuracy: 0.3958\n",
      "Epoch 189/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0838 - categorical_accuracy: 0.3893 - val_loss: 94.4336 - val_categorical_accuracy: 0.3889\n",
      "Epoch 190/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3876 - val_loss: 94.3458 - val_categorical_accuracy: 0.3886\n",
      "Epoch 191/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0849 - categorical_accuracy: 0.3866 - val_loss: 94.3480 - val_categorical_accuracy: 0.3886\n",
      "Epoch 192/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3877 - val_loss: 94.3486 - val_categorical_accuracy: 0.3886\n",
      "Epoch 193/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0843 - categorical_accuracy: 0.3878 - val_loss: 94.3550 - val_categorical_accuracy: 0.3886\n",
      "Epoch 194/2000\n",
      "977/977 [==============================] - 13s 14ms/step - loss: 1.0841 - categorical_accuracy: 0.3880 - val_loss: 94.3513 - val_categorical_accuracy: 0.3886\n",
      "Epoch 195/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3870 - val_loss: 94.3452 - val_categorical_accuracy: 0.3886\n",
      "Epoch 196/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0841 - categorical_accuracy: 0.3882 - val_loss: 94.3550 - val_categorical_accuracy: 0.3886\n",
      "Epoch 197/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3879 - val_loss: 94.3471 - val_categorical_accuracy: 0.3886\n",
      "Epoch 198/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3885 - val_loss: 94.3557 - val_categorical_accuracy: 0.3886\n",
      "Epoch 199/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3885 - val_loss: 94.3441 - val_categorical_accuracy: 0.3886\n",
      "Epoch 200/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0840 - categorical_accuracy: 0.3885 - val_loss: 94.3472 - val_categorical_accuracy: 0.3886\n",
      "Epoch 201/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0840 - categorical_accuracy: 0.3882 - val_loss: 94.3498 - val_categorical_accuracy: 0.3886\n",
      "Epoch 202/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0848 - categorical_accuracy: 0.3882 - val_loss: 94.3498 - val_categorical_accuracy: 0.3886\n",
      "Epoch 203/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3881 - val_loss: 94.3418 - val_categorical_accuracy: 0.3886\n",
      "Epoch 204/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3880 - val_loss: 94.3555 - val_categorical_accuracy: 0.3886\n",
      "Epoch 205/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3883 - val_loss: 94.3394 - val_categorical_accuracy: 0.3886\n",
      "Epoch 206/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3885 - val_loss: 94.3416 - val_categorical_accuracy: 0.3886\n",
      "Epoch 207/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0850 - categorical_accuracy: 0.3862 - val_loss: 94.3485 - val_categorical_accuracy: 0.3886\n",
      "Epoch 208/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3885 - val_loss: 94.3406 - val_categorical_accuracy: 0.3886\n",
      "Epoch 209/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3875 - val_loss: 94.3572 - val_categorical_accuracy: 0.3886\n",
      "Epoch 210/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0848 - categorical_accuracy: 0.3884 - val_loss: 94.3387 - val_categorical_accuracy: 0.3886\n",
      "Epoch 211/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0849 - categorical_accuracy: 0.3871 - val_loss: 94.3450 - val_categorical_accuracy: 0.3886\n",
      "Epoch 212/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3884 - val_loss: 94.3503 - val_categorical_accuracy: 0.3886\n",
      "Epoch 213/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3881 - val_loss: 94.3464 - val_categorical_accuracy: 0.3886\n",
      "Epoch 214/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3880 - val_loss: 94.3467 - val_categorical_accuracy: 0.3886\n",
      "Epoch 215/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3876 - val_loss: 94.3441 - val_categorical_accuracy: 0.3886\n",
      "Epoch 216/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3871 - val_loss: 94.3481 - val_categorical_accuracy: 0.3886\n",
      "Epoch 217/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3877 - val_loss: 94.3477 - val_categorical_accuracy: 0.3886\n",
      "Epoch 218/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0840 - categorical_accuracy: 0.3886 - val_loss: 94.3442 - val_categorical_accuracy: 0.3886\n",
      "Epoch 219/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0841 - categorical_accuracy: 0.3883 - val_loss: 94.3465 - val_categorical_accuracy: 0.3886\n",
      "Epoch 220/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3885 - val_loss: 94.3466 - val_categorical_accuracy: 0.3886\n",
      "Epoch 221/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3880 - val_loss: 94.3382 - val_categorical_accuracy: 0.3886\n",
      "Epoch 222/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3897 - val_loss: 94.3453 - val_categorical_accuracy: 0.3886\n",
      "Epoch 223/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3877 - val_loss: 94.3445 - val_categorical_accuracy: 0.3886\n",
      "Epoch 224/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3874 - val_loss: 94.3535 - val_categorical_accuracy: 0.3886\n",
      "Epoch 225/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3876 - val_loss: 94.3500 - val_categorical_accuracy: 0.3886\n",
      "Epoch 226/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0840 - categorical_accuracy: 0.3882 - val_loss: 94.3471 - val_categorical_accuracy: 0.3886\n",
      "Epoch 227/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0839 - categorical_accuracy: 0.3881 - val_loss: 94.3559 - val_categorical_accuracy: 0.3886\n",
      "Epoch 228/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0840 - categorical_accuracy: 0.3883 - val_loss: 94.3484 - val_categorical_accuracy: 0.3886\n",
      "Epoch 229/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3870 - val_loss: 94.3530 - val_categorical_accuracy: 0.3886\n",
      "Epoch 230/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3876 - val_loss: 94.3457 - val_categorical_accuracy: 0.3886\n",
      "Epoch 231/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3881 - val_loss: 94.3509 - val_categorical_accuracy: 0.3886\n",
      "Epoch 232/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0841 - categorical_accuracy: 0.3892 - val_loss: 94.3447 - val_categorical_accuracy: 0.3886\n",
      "Epoch 233/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0840 - categorical_accuracy: 0.3898 - val_loss: 94.3432 - val_categorical_accuracy: 0.3886\n",
      "Epoch 234/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3875 - val_loss: 94.3488 - val_categorical_accuracy: 0.3886\n",
      "Epoch 235/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3886 - val_loss: 94.3478 - val_categorical_accuracy: 0.3886\n",
      "Epoch 236/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3871 - val_loss: 94.3461 - val_categorical_accuracy: 0.3886\n",
      "Epoch 237/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3876 - val_loss: 94.3515 - val_categorical_accuracy: 0.3886\n",
      "Epoch 238/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0849 - categorical_accuracy: 0.3880 - val_loss: 94.3497 - val_categorical_accuracy: 0.3886\n",
      "Epoch 239/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3875 - val_loss: 94.3553 - val_categorical_accuracy: 0.3886\n",
      "Epoch 240/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3891 - val_loss: 94.3426 - val_categorical_accuracy: 0.3886\n",
      "Epoch 241/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3873 - val_loss: 94.3546 - val_categorical_accuracy: 0.3886\n",
      "Epoch 242/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3884 - val_loss: 94.3497 - val_categorical_accuracy: 0.3886\n",
      "Epoch 243/2000\n",
      "977/977 [==============================] - 18s 19ms/step - loss: 1.0845 - categorical_accuracy: 0.3892 - val_loss: 94.3406 - val_categorical_accuracy: 0.3886\n",
      "Epoch 244/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3886 - val_loss: 94.3495 - val_categorical_accuracy: 0.3886\n",
      "Epoch 245/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0843 - categorical_accuracy: 0.3891 - val_loss: 94.3429 - val_categorical_accuracy: 0.3886\n",
      "Epoch 246/2000\n",
      "977/977 [==============================] - 14s 14ms/step - loss: 1.0844 - categorical_accuracy: 0.3879 - val_loss: 94.3484 - val_categorical_accuracy: 0.3886\n",
      "Epoch 247/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3886 - val_loss: 94.3482 - val_categorical_accuracy: 0.3886\n",
      "Epoch 248/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3872 - val_loss: 94.3446 - val_categorical_accuracy: 0.3886\n",
      "Epoch 249/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0839 - categorical_accuracy: 0.3889 - val_loss: 94.3352 - val_categorical_accuracy: 0.3885\n",
      "Epoch 250/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3878 - val_loss: 94.3516 - val_categorical_accuracy: 0.3886\n",
      "Epoch 251/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3867 - val_loss: 94.3528 - val_categorical_accuracy: 0.3886\n",
      "Epoch 252/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0850 - categorical_accuracy: 0.3865 - val_loss: 94.3469 - val_categorical_accuracy: 0.3886\n",
      "Epoch 253/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0849 - categorical_accuracy: 0.3879 - val_loss: 94.3524 - val_categorical_accuracy: 0.3886\n",
      "Epoch 254/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3891 - val_loss: 94.3451 - val_categorical_accuracy: 0.3886\n",
      "Epoch 255/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3884 - val_loss: 94.3493 - val_categorical_accuracy: 0.3886\n",
      "Epoch 256/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0839 - categorical_accuracy: 0.3887 - val_loss: 94.3508 - val_categorical_accuracy: 0.3886\n",
      "Epoch 257/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3873 - val_loss: 94.3572 - val_categorical_accuracy: 0.3886\n",
      "Epoch 258/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0840 - categorical_accuracy: 0.3886 - val_loss: 94.3461 - val_categorical_accuracy: 0.3886\n",
      "Epoch 259/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0850 - categorical_accuracy: 0.3868 - val_loss: 94.3512 - val_categorical_accuracy: 0.3886\n",
      "Epoch 260/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3869 - val_loss: 94.3495 - val_categorical_accuracy: 0.3886\n",
      "Epoch 261/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3889 - val_loss: 94.3443 - val_categorical_accuracy: 0.3886\n",
      "Epoch 262/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3892 - val_loss: 94.3485 - val_categorical_accuracy: 0.3886\n",
      "Epoch 263/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0848 - categorical_accuracy: 0.3864 - val_loss: 94.3484 - val_categorical_accuracy: 0.3886\n",
      "Epoch 264/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3898 - val_loss: 94.3487 - val_categorical_accuracy: 0.3886\n",
      "Epoch 265/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3878 - val_loss: 94.3509 - val_categorical_accuracy: 0.3886\n",
      "Epoch 266/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3886 - val_loss: 94.3512 - val_categorical_accuracy: 0.3886\n",
      "Epoch 267/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3884 - val_loss: 94.3494 - val_categorical_accuracy: 0.3886\n",
      "Epoch 268/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0849 - categorical_accuracy: 0.3862 - val_loss: 94.3494 - val_categorical_accuracy: 0.3886\n",
      "Epoch 269/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3875 - val_loss: 94.3426 - val_categorical_accuracy: 0.3886\n",
      "Epoch 270/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0841 - categorical_accuracy: 0.3889 - val_loss: 94.3450 - val_categorical_accuracy: 0.3886\n",
      "Epoch 271/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3879 - val_loss: 94.3450 - val_categorical_accuracy: 0.3886\n",
      "Epoch 272/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3868 - val_loss: 94.3562 - val_categorical_accuracy: 0.3886\n",
      "Epoch 273/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3879 - val_loss: 94.3469 - val_categorical_accuracy: 0.3886\n",
      "Epoch 274/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3880 - val_loss: 94.3532 - val_categorical_accuracy: 0.3886\n",
      "Epoch 275/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3859 - val_loss: 94.3605 - val_categorical_accuracy: 0.3886\n",
      "Epoch 276/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3868 - val_loss: 94.3486 - val_categorical_accuracy: 0.3886\n",
      "Epoch 277/2000\n",
      "977/977 [==============================] - 12s 13ms/step - loss: 1.0846 - categorical_accuracy: 0.3876 - val_loss: 94.3499 - val_categorical_accuracy: 0.3886\n",
      "Epoch 278/2000\n",
      "977/977 [==============================] - 14s 14ms/step - loss: 1.0844 - categorical_accuracy: 0.3896 - val_loss: 94.3423 - val_categorical_accuracy: 0.3886\n",
      "Epoch 279/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3887 - val_loss: 94.3490 - val_categorical_accuracy: 0.3886\n",
      "Epoch 280/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3891 - val_loss: 94.3453 - val_categorical_accuracy: 0.3886\n",
      "Epoch 281/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3873 - val_loss: 94.3421 - val_categorical_accuracy: 0.3886\n",
      "Epoch 282/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3872 - val_loss: 94.3444 - val_categorical_accuracy: 0.3886\n",
      "Epoch 283/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3860 - val_loss: 94.3540 - val_categorical_accuracy: 0.3886\n",
      "Epoch 284/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3880 - val_loss: 94.3525 - val_categorical_accuracy: 0.3886\n",
      "Epoch 285/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0838 - categorical_accuracy: 0.3889 - val_loss: 94.3429 - val_categorical_accuracy: 0.3886\n",
      "Epoch 286/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3883 - val_loss: 94.3469 - val_categorical_accuracy: 0.3886\n",
      "Epoch 287/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0852 - categorical_accuracy: 0.3870 - val_loss: 94.3430 - val_categorical_accuracy: 0.3886\n",
      "Epoch 288/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3875 - val_loss: 94.3467 - val_categorical_accuracy: 0.3886\n",
      "Epoch 289/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3868 - val_loss: 94.3518 - val_categorical_accuracy: 0.3886\n",
      "Epoch 290/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3874 - val_loss: 94.3446 - val_categorical_accuracy: 0.3886\n",
      "Epoch 291/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3891 - val_loss: 94.3398 - val_categorical_accuracy: 0.3886\n",
      "Epoch 292/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3892 - val_loss: 94.3461 - val_categorical_accuracy: 0.3886\n",
      "Epoch 293/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3864 - val_loss: 94.3551 - val_categorical_accuracy: 0.3886\n",
      "Epoch 294/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0848 - categorical_accuracy: 0.3880 - val_loss: 94.3420 - val_categorical_accuracy: 0.3886\n",
      "Epoch 295/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0849 - categorical_accuracy: 0.3877 - val_loss: 94.3498 - val_categorical_accuracy: 0.3886\n",
      "Epoch 296/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3867 - val_loss: 94.3439 - val_categorical_accuracy: 0.3886\n",
      "Epoch 297/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0854 - categorical_accuracy: 0.3844 - val_loss: 94.3574 - val_categorical_accuracy: 0.3886\n",
      "Epoch 298/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3893 - val_loss: 94.3444 - val_categorical_accuracy: 0.3886\n",
      "Epoch 299/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3882 - val_loss: 94.3482 - val_categorical_accuracy: 0.3886\n",
      "Epoch 300/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0849 - categorical_accuracy: 0.3868 - val_loss: 94.3553 - val_categorical_accuracy: 0.3886\n",
      "Epoch 301/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3871 - val_loss: 94.3524 - val_categorical_accuracy: 0.3886\n",
      "Epoch 302/2000\n",
      "977/977 [==============================] - 12s 13ms/step - loss: 1.0839 - categorical_accuracy: 0.3881 - val_loss: 94.3515 - val_categorical_accuracy: 0.3886\n",
      "Epoch 303/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3887 - val_loss: 94.3459 - val_categorical_accuracy: 0.3886\n",
      "Epoch 304/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3876 - val_loss: 94.3482 - val_categorical_accuracy: 0.3886\n",
      "Epoch 305/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3870 - val_loss: 94.3518 - val_categorical_accuracy: 0.3886\n",
      "Epoch 306/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0849 - categorical_accuracy: 0.3872 - val_loss: 94.3519 - val_categorical_accuracy: 0.3886\n",
      "Epoch 307/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3857 - val_loss: 94.3537 - val_categorical_accuracy: 0.3886\n",
      "Epoch 308/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0848 - categorical_accuracy: 0.3860 - val_loss: 94.3566 - val_categorical_accuracy: 0.3886\n",
      "Epoch 309/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0849 - categorical_accuracy: 0.3863 - val_loss: 94.3578 - val_categorical_accuracy: 0.3886\n",
      "Epoch 310/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3876 - val_loss: 94.3456 - val_categorical_accuracy: 0.3886\n",
      "Epoch 311/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3895 - val_loss: 94.3501 - val_categorical_accuracy: 0.3886\n",
      "Epoch 312/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3877 - val_loss: 94.3508 - val_categorical_accuracy: 0.3886\n",
      "Epoch 313/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0851 - categorical_accuracy: 0.3857 - val_loss: 94.3593 - val_categorical_accuracy: 0.3886\n",
      "Epoch 314/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3881 - val_loss: 94.3416 - val_categorical_accuracy: 0.3886\n",
      "Epoch 315/2000\n",
      "977/977 [==============================] - 15s 15ms/step - loss: 1.0846 - categorical_accuracy: 0.3872 - val_loss: 94.3519 - val_categorical_accuracy: 0.3886\n",
      "Epoch 316/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0849 - categorical_accuracy: 0.3878 - val_loss: 94.3499 - val_categorical_accuracy: 0.3886\n",
      "Epoch 317/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0838 - categorical_accuracy: 0.3883 - val_loss: 94.3479 - val_categorical_accuracy: 0.3886\n",
      "Epoch 318/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0841 - categorical_accuracy: 0.3880 - val_loss: 94.3414 - val_categorical_accuracy: 0.3886\n",
      "Epoch 319/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3881 - val_loss: 94.3594 - val_categorical_accuracy: 0.3886\n",
      "Epoch 320/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3871 - val_loss: 94.3535 - val_categorical_accuracy: 0.3886\n",
      "Epoch 321/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3867 - val_loss: 94.3536 - val_categorical_accuracy: 0.3886\n",
      "Epoch 322/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0841 - categorical_accuracy: 0.3894 - val_loss: 94.3432 - val_categorical_accuracy: 0.3886\n",
      "Epoch 323/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0848 - categorical_accuracy: 0.3856 - val_loss: 94.3563 - val_categorical_accuracy: 0.3886\n",
      "Epoch 324/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3881 - val_loss: 94.3454 - val_categorical_accuracy: 0.3886\n",
      "Epoch 325/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0850 - categorical_accuracy: 0.3879 - val_loss: 94.3425 - val_categorical_accuracy: 0.3886\n",
      "Epoch 326/2000\n",
      "977/977 [==============================] - 15s 15ms/step - loss: 1.0847 - categorical_accuracy: 0.3876 - val_loss: 94.3522 - val_categorical_accuracy: 0.3886\n",
      "Epoch 327/2000\n",
      "977/977 [==============================] - 13s 14ms/step - loss: 1.0845 - categorical_accuracy: 0.3888 - val_loss: 94.3431 - val_categorical_accuracy: 0.3886\n",
      "Epoch 328/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3871 - val_loss: 94.3483 - val_categorical_accuracy: 0.3886\n",
      "Epoch 329/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3872 - val_loss: 94.3482 - val_categorical_accuracy: 0.3886\n",
      "Epoch 330/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3873 - val_loss: 94.3441 - val_categorical_accuracy: 0.3886\n",
      "Epoch 331/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3878 - val_loss: 94.3542 - val_categorical_accuracy: 0.3886\n",
      "Epoch 332/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0836 - categorical_accuracy: 0.3892 - val_loss: 94.3400 - val_categorical_accuracy: 0.3886\n",
      "Epoch 333/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3885 - val_loss: 94.3581 - val_categorical_accuracy: 0.3886\n",
      "Epoch 334/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3876 - val_loss: 94.3486 - val_categorical_accuracy: 0.3886\n",
      "Epoch 335/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0851 - categorical_accuracy: 0.3864 - val_loss: 94.3563 - val_categorical_accuracy: 0.3886\n",
      "Epoch 336/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3889 - val_loss: 94.3467 - val_categorical_accuracy: 0.3886\n",
      "Epoch 337/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3905 - val_loss: 94.3498 - val_categorical_accuracy: 0.3886\n",
      "Epoch 338/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0838 - categorical_accuracy: 0.3903 - val_loss: 94.3473 - val_categorical_accuracy: 0.3886\n",
      "Epoch 339/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3879 - val_loss: 94.3506 - val_categorical_accuracy: 0.3886\n",
      "Epoch 340/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3879 - val_loss: 94.3478 - val_categorical_accuracy: 0.3886\n",
      "Epoch 341/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3900 - val_loss: 94.3433 - val_categorical_accuracy: 0.3886\n",
      "Epoch 342/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3872 - val_loss: 94.3553 - val_categorical_accuracy: 0.3886\n",
      "Epoch 343/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3875 - val_loss: 94.3427 - val_categorical_accuracy: 0.3886\n",
      "Epoch 344/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3882 - val_loss: 94.3434 - val_categorical_accuracy: 0.3886\n",
      "Epoch 345/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3878 - val_loss: 94.3469 - val_categorical_accuracy: 0.3886\n",
      "Epoch 346/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3874 - val_loss: 94.3468 - val_categorical_accuracy: 0.3886\n",
      "Epoch 347/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3886 - val_loss: 94.3443 - val_categorical_accuracy: 0.3886\n",
      "Epoch 348/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3873 - val_loss: 94.3549 - val_categorical_accuracy: 0.3886\n",
      "Epoch 349/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3873 - val_loss: 94.3441 - val_categorical_accuracy: 0.3886\n",
      "Epoch 350/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3879 - val_loss: 94.3546 - val_categorical_accuracy: 0.3886\n",
      "Epoch 351/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3896 - val_loss: 94.3504 - val_categorical_accuracy: 0.3886 - categorical_accuracy: 0.\n",
      "Epoch 352/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3877 - val_loss: 94.3484 - val_categorical_accuracy: 0.3886\n",
      "Epoch 353/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3868 - val_loss: 94.3530 - val_categorical_accuracy: 0.3886\n",
      "Epoch 354/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0840 - categorical_accuracy: 0.3893 - val_loss: 94.3503 - val_categorical_accuracy: 0.3886\n",
      "Epoch 355/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3883 - val_loss: 94.3520 - val_categorical_accuracy: 0.3886\n",
      "Epoch 356/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3882 - val_loss: 94.3486 - val_categorical_accuracy: 0.3886\n",
      "Epoch 357/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0841 - categorical_accuracy: 0.3889 - val_loss: 94.3460 - val_categorical_accuracy: 0.3886\n",
      "Epoch 358/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0841 - categorical_accuracy: 0.3887 - val_loss: 94.3412 - val_categorical_accuracy: 0.3886\n",
      "Epoch 359/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3886 - val_loss: 94.3396 - val_categorical_accuracy: 0.3886\n",
      "Epoch 360/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3887 - val_loss: 94.3479 - val_categorical_accuracy: 0.3886\n",
      "Epoch 361/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3875 - val_loss: 94.3507 - val_categorical_accuracy: 0.3886\n",
      "Epoch 362/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3886 - val_loss: 94.3435 - val_categorical_accuracy: 0.3886\n",
      "Epoch 363/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3879 - val_loss: 94.3479 - val_categorical_accuracy: 0.3886\n",
      "Epoch 364/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0849 - categorical_accuracy: 0.3870 - val_loss: 94.3506 - val_categorical_accuracy: 0.3886\n",
      "Epoch 365/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3873 - val_loss: 94.3469 - val_categorical_accuracy: 0.3886\n",
      "Epoch 366/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3885 - val_loss: 94.3460 - val_categorical_accuracy: 0.3886\n",
      "Epoch 367/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0841 - categorical_accuracy: 0.3890 - val_loss: 94.3397 - val_categorical_accuracy: 0.3886\n",
      "Epoch 368/2000\n",
      "977/977 [==============================] - 16s 16ms/step - loss: 1.0841 - categorical_accuracy: 0.3887 - val_loss: 94.3508 - val_categorical_accuracy: 0.3886\n",
      "Epoch 369/2000\n",
      "977/977 [==============================] - 13s 14ms/step - loss: 1.0845 - categorical_accuracy: 0.3877 - val_loss: 94.3493 - val_categorical_accuracy: 0.3886\n",
      "Epoch 370/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3866 - val_loss: 94.3505 - val_categorical_accuracy: 0.3886\n",
      "Epoch 371/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3877 - val_loss: 94.3409 - val_categorical_accuracy: 0.3886\n",
      "Epoch 372/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3880 - val_loss: 94.3550 - val_categorical_accuracy: 0.3886\n",
      "Epoch 373/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3876 - val_loss: 94.3491 - val_categorical_accuracy: 0.3886\n",
      "Epoch 374/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3875 - val_loss: 94.3421 - val_categorical_accuracy: 0.3886\n",
      "Epoch 375/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3876 - val_loss: 94.3494 - val_categorical_accuracy: 0.3886\n",
      "Epoch 376/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3887 - val_loss: 94.3539 - val_categorical_accuracy: 0.3886\n",
      "Epoch 377/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3876 - val_loss: 94.3425 - val_categorical_accuracy: 0.3886\n",
      "Epoch 378/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3883 - val_loss: 94.3514 - val_categorical_accuracy: 0.3886\n",
      "Epoch 379/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3870 - val_loss: 94.3533 - val_categorical_accuracy: 0.3886\n",
      "Epoch 380/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0853 - categorical_accuracy: 0.3861 - val_loss: 94.3488 - val_categorical_accuracy: 0.3886\n",
      "Epoch 381/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3867 - val_loss: 94.3574 - val_categorical_accuracy: 0.3886\n",
      "Epoch 382/2000\n",
      "977/977 [==============================] - 14s 14ms/step - loss: 1.0845 - categorical_accuracy: 0.3878 - val_loss: 94.3511 - val_categorical_accuracy: 0.3886\n",
      "Epoch 383/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3890 - val_loss: 94.3423 - val_categorical_accuracy: 0.3886\n",
      "Epoch 384/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3878 - val_loss: 94.3431 - val_categorical_accuracy: 0.3886\n",
      "Epoch 385/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3886 - val_loss: 94.3466 - val_categorical_accuracy: 0.3886\n",
      "Epoch 386/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3877 - val_loss: 94.3558 - val_categorical_accuracy: 0.3886\n",
      "Epoch 387/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3881 - val_loss: 94.3501 - val_categorical_accuracy: 0.3886\n",
      "Epoch 388/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3881 - val_loss: 94.3535 - val_categorical_accuracy: 0.3886\n",
      "Epoch 389/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3884 - val_loss: 94.3468 - val_categorical_accuracy: 0.3886\n",
      "Epoch 390/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3874 - val_loss: 94.3518 - val_categorical_accuracy: 0.3886\n",
      "Epoch 391/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3878 - val_loss: 94.3478 - val_categorical_accuracy: 0.3886\n",
      "Epoch 392/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3872 - val_loss: 94.3537 - val_categorical_accuracy: 0.3886\n",
      "Epoch 393/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3892 - val_loss: 94.3445 - val_categorical_accuracy: 0.3886\n",
      "Epoch 394/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0840 - categorical_accuracy: 0.3884 - val_loss: 94.3460 - val_categorical_accuracy: 0.3886\n",
      "Epoch 395/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3856 - val_loss: 94.3513 - val_categorical_accuracy: 0.3886\n",
      "Epoch 396/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3893 - val_loss: 94.3483 - val_categorical_accuracy: 0.3886\n",
      "Epoch 397/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3878 - val_loss: 94.3442 - val_categorical_accuracy: 0.3886\n",
      "Epoch 398/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3892 - val_loss: 94.3429 - val_categorical_accuracy: 0.3886\n",
      "Epoch 399/2000\n",
      "977/977 [==============================] - 13s 14ms/step - loss: 1.0850 - categorical_accuracy: 0.3858 - val_loss: 94.3485 - val_categorical_accuracy: 0.3886\n",
      "Epoch 400/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0840 - categorical_accuracy: 0.3899 - val_loss: 94.3398 - val_categorical_accuracy: 0.3886\n",
      "Epoch 401/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0849 - categorical_accuracy: 0.3859 - val_loss: 94.3511 - val_categorical_accuracy: 0.3886\n",
      "Epoch 402/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0840 - categorical_accuracy: 0.3899 - val_loss: 94.3343 - val_categorical_accuracy: 0.3886\n",
      "Epoch 403/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3873 - val_loss: 94.3523 - val_categorical_accuracy: 0.3886\n",
      "Epoch 404/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3893 - val_loss: 94.3509 - val_categorical_accuracy: 0.3886\n",
      "Epoch 405/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0848 - categorical_accuracy: 0.3877 - val_loss: 94.3465 - val_categorical_accuracy: 0.3886\n",
      "Epoch 406/2000\n",
      "977/977 [==============================] - 14s 14ms/step - loss: 1.0848 - categorical_accuracy: 0.3885 - val_loss: 94.3470 - val_categorical_accuracy: 0.3886\n",
      "Epoch 407/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0842 - categorical_accuracy: 0.3884 - val_loss: 94.3450 - val_categorical_accuracy: 0.3886\n",
      "Epoch 408/2000\n",
      "977/977 [==============================] - 12s 13ms/step - loss: 1.0848 - categorical_accuracy: 0.3867 - val_loss: 94.3498 - val_categorical_accuracy: 0.3886\n",
      "Epoch 409/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0846 - categorical_accuracy: 0.3879 - val_loss: 94.3523 - val_categorical_accuracy: 0.3886\n",
      "Epoch 410/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0839 - categorical_accuracy: 0.3894 - val_loss: 94.3433 - val_categorical_accuracy: 0.3886\n",
      "Epoch 411/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0848 - categorical_accuracy: 0.3854 - val_loss: 94.3561 - val_categorical_accuracy: 0.3886\n",
      "Epoch 412/2000\n",
      "977/977 [==============================] - 14s 14ms/step - loss: 1.0847 - categorical_accuracy: 0.3876 - val_loss: 94.3420 - val_categorical_accuracy: 0.3886\n",
      "Epoch 413/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0845 - categorical_accuracy: 0.3867 - val_loss: 94.3510 - val_categorical_accuracy: 0.3886\n",
      "Epoch 414/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3877 - val_loss: 94.3502 - val_categorical_accuracy: 0.3886\n",
      "Epoch 415/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0851 - categorical_accuracy: 0.3857 - val_loss: 94.3496 - val_categorical_accuracy: 0.3886\n",
      "Epoch 416/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3888 - val_loss: 94.3457 - val_categorical_accuracy: 0.3886\n",
      "Epoch 417/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0839 - categorical_accuracy: 0.3890 - val_loss: 94.3407 - val_categorical_accuracy: 0.3886\n",
      "Epoch 418/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3897 - val_loss: 94.3377 - val_categorical_accuracy: 0.3886\n",
      "Epoch 419/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0840 - categorical_accuracy: 0.3885 - val_loss: 94.3504 - val_categorical_accuracy: 0.3886\n",
      "Epoch 420/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0848 - categorical_accuracy: 0.3883 - val_loss: 94.3495 - val_categorical_accuracy: 0.3886\n",
      "Epoch 421/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3875 - val_loss: 94.3468 - val_categorical_accuracy: 0.3886\n",
      "Epoch 422/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3863 - val_loss: 94.3514 - val_categorical_accuracy: 0.3886\n",
      "Epoch 423/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3874 - val_loss: 94.3494 - val_categorical_accuracy: 0.3886\n",
      "Epoch 424/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3889 - val_loss: 94.3443 - val_categorical_accuracy: 0.3886\n",
      "Epoch 425/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3876 - val_loss: 94.3519 - val_categorical_accuracy: 0.3886\n",
      "Epoch 426/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3876 - val_loss: 94.3461 - val_categorical_accuracy: 0.3886\n",
      "Epoch 427/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0853 - categorical_accuracy: 0.3855 - val_loss: 94.3538 - val_categorical_accuracy: 0.3886\n",
      "Epoch 428/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3888 - val_loss: 94.3485 - val_categorical_accuracy: 0.3886\n",
      "Epoch 429/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0850 - categorical_accuracy: 0.3864 - val_loss: 94.3433 - val_categorical_accuracy: 0.3886\n",
      "Epoch 430/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3891 - val_loss: 94.3470 - val_categorical_accuracy: 0.3886\n",
      "Epoch 431/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3872 - val_loss: 94.3491 - val_categorical_accuracy: 0.3886\n",
      "Epoch 432/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3890 - val_loss: 94.3531 - val_categorical_accuracy: 0.3886\n",
      "Epoch 433/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0849 - categorical_accuracy: 0.3860 - val_loss: 94.3482 - val_categorical_accuracy: 0.3886\n",
      "Epoch 434/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0849 - categorical_accuracy: 0.3853 - val_loss: 94.3561 - val_categorical_accuracy: 0.3886\n",
      "Epoch 435/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3880 - val_loss: 94.3531 - val_categorical_accuracy: 0.3886\n",
      "Epoch 436/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3873 - val_loss: 94.3495 - val_categorical_accuracy: 0.3886\n",
      "Epoch 437/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3887 - val_loss: 94.3471 - val_categorical_accuracy: 0.3886\n",
      "Epoch 438/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0840 - categorical_accuracy: 0.3894 - val_loss: 94.3504 - val_categorical_accuracy: 0.3886\n",
      "Epoch 439/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3887 - val_loss: 94.3496 - val_categorical_accuracy: 0.3886\n",
      "Epoch 440/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3882 - val_loss: 94.3396 - val_categorical_accuracy: 0.3886\n",
      "Epoch 441/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3888 - val_loss: 94.3450 - val_categorical_accuracy: 0.3886\n",
      "Epoch 442/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3886 - val_loss: 94.3500 - val_categorical_accuracy: 0.3886\n",
      "Epoch 443/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3874 - val_loss: 94.3510 - val_categorical_accuracy: 0.3886\n",
      "Epoch 444/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3878 - val_loss: 94.3420 - val_categorical_accuracy: 0.3886\n",
      "Epoch 445/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3880 - val_loss: 94.3501 - val_categorical_accuracy: 0.3886\n",
      "Epoch 446/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3885 - val_loss: 94.3497 - val_categorical_accuracy: 0.3886\n",
      "Epoch 447/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3868 - val_loss: 94.3478 - val_categorical_accuracy: 0.3886\n",
      "Epoch 448/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0850 - categorical_accuracy: 0.3874 - val_loss: 94.3479 - val_categorical_accuracy: 0.3886\n",
      "Epoch 449/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3888 - val_loss: 94.3457 - val_categorical_accuracy: 0.3886\n",
      "Epoch 450/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3906 - val_loss: 94.3437 - val_categorical_accuracy: 0.3886\n",
      "Epoch 451/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0849 - categorical_accuracy: 0.3868 - val_loss: 94.3518 - val_categorical_accuracy: 0.3886\n",
      "Epoch 452/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0847 - categorical_accuracy: 0.3882 - val_loss: 94.3388 - val_categorical_accuracy: 0.3886\n",
      "Epoch 453/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0848 - categorical_accuracy: 0.3876 - val_loss: 94.3447 - val_categorical_accuracy: 0.3886\n",
      "Epoch 454/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3875 - val_loss: 94.3461 - val_categorical_accuracy: 0.3886\n",
      "Epoch 455/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3888 - val_loss: 94.3401 - val_categorical_accuracy: 0.3886\n",
      "Epoch 456/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3883 - val_loss: 94.3442 - val_categorical_accuracy: 0.3886\n",
      "Epoch 457/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3872 - val_loss: 94.3486 - val_categorical_accuracy: 0.3886\n",
      "Epoch 458/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0848 - categorical_accuracy: 0.3866 - val_loss: 94.3516 - val_categorical_accuracy: 0.3886\n",
      "Epoch 459/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3882 - val_loss: 94.3402 - val_categorical_accuracy: 0.3886\n",
      "Epoch 460/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3893 - val_loss: 94.3449 - val_categorical_accuracy: 0.3886\n",
      "Epoch 461/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0842 - categorical_accuracy: 0.3884 - val_loss: 94.3525 - val_categorical_accuracy: 0.3886\n",
      "Epoch 462/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3882 - val_loss: 94.3525 - val_categorical_accuracy: 0.3886\n",
      "Epoch 463/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3874 - val_loss: 94.3474 - val_categorical_accuracy: 0.3886\n",
      "Epoch 464/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3876 - val_loss: 94.3485 - val_categorical_accuracy: 0.3886\n",
      "Epoch 465/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3882 - val_loss: 94.3400 - val_categorical_accuracy: 0.3886\n",
      "Epoch 466/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0841 - categorical_accuracy: 0.3890 - val_loss: 94.3442 - val_categorical_accuracy: 0.3886\n",
      "Epoch 467/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3881 - val_loss: 94.3474 - val_categorical_accuracy: 0.3886\n",
      "Epoch 468/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0844 - categorical_accuracy: 0.3864 - val_loss: 94.3523 - val_categorical_accuracy: 0.3886\n",
      "Epoch 469/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3880 - val_loss: 94.3519 - val_categorical_accuracy: 0.3886\n",
      "Epoch 470/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3881 - val_loss: 94.3488 - val_categorical_accuracy: 0.3886\n",
      "Epoch 471/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3888 - val_loss: 94.3430 - val_categorical_accuracy: 0.3886\n",
      "Epoch 472/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3881 - val_loss: 94.3459 - val_categorical_accuracy: 0.3886\n",
      "Epoch 473/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0854 - categorical_accuracy: 0.3859 - val_loss: 94.3518 - val_categorical_accuracy: 0.3886\n",
      "Epoch 474/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3897 - val_loss: 94.3481 - val_categorical_accuracy: 0.3886\n",
      "Epoch 475/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0848 - categorical_accuracy: 0.3864 - val_loss: 94.3574 - val_categorical_accuracy: 0.3886\n",
      "Epoch 476/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3877 - val_loss: 94.3507 - val_categorical_accuracy: 0.3886\n",
      "Epoch 477/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0847 - categorical_accuracy: 0.3866 - val_loss: 94.3511 - val_categorical_accuracy: 0.3886\n",
      "Epoch 478/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3880 - val_loss: 94.3403 - val_categorical_accuracy: 0.3886\n",
      "Epoch 479/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3883 - val_loss: 94.3434 - val_categorical_accuracy: 0.3886\n",
      "Epoch 480/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0849 - categorical_accuracy: 0.3871 - val_loss: 94.3515 - val_categorical_accuracy: 0.3886\n",
      "Epoch 481/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3870 - val_loss: 94.3530 - val_categorical_accuracy: 0.3886\n",
      "Epoch 482/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3879 - val_loss: 94.3524 - val_categorical_accuracy: 0.3886\n",
      "Epoch 483/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3874 - val_loss: 94.3504 - val_categorical_accuracy: 0.3886\n",
      "Epoch 484/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3883 - val_loss: 94.3491 - val_categorical_accuracy: 0.3886\n",
      "Epoch 485/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3879 - val_loss: 94.3594 - val_categorical_accuracy: 0.3886\n",
      "Epoch 486/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3885 - val_loss: 94.3450 - val_categorical_accuracy: 0.3886\n",
      "Epoch 487/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0839 - categorical_accuracy: 0.3905 - val_loss: 94.3317 - val_categorical_accuracy: 0.3886\n",
      "Epoch 488/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0842 - categorical_accuracy: 0.3888 - val_loss: 94.3499 - val_categorical_accuracy: 0.3886\n",
      "Epoch 489/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3886 - val_loss: 94.3490 - val_categorical_accuracy: 0.3886\n",
      "Epoch 490/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3867 - val_loss: 94.3457 - val_categorical_accuracy: 0.3886\n",
      "Epoch 491/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0850 - categorical_accuracy: 0.3872 - val_loss: 94.3532 - val_categorical_accuracy: 0.3886\n",
      "Epoch 492/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3873 - val_loss: 94.3523 - val_categorical_accuracy: 0.3886\n",
      "Epoch 493/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0841 - categorical_accuracy: 0.3891 - val_loss: 94.3430 - val_categorical_accuracy: 0.3886\n",
      "Epoch 494/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3877 - val_loss: 94.3530 - val_categorical_accuracy: 0.3886\n",
      "Epoch 495/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3872 - val_loss: 94.3461 - val_categorical_accuracy: 0.3886\n",
      "Epoch 496/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3878 - val_loss: 94.3542 - val_categorical_accuracy: 0.3886\n",
      "Epoch 497/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3896 - val_loss: 94.3430 - val_categorical_accuracy: 0.3886\n",
      "Epoch 498/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3886 - val_loss: 94.3418 - val_categorical_accuracy: 0.3886\n",
      "Epoch 499/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0841 - categorical_accuracy: 0.3900 - val_loss: 94.3452 - val_categorical_accuracy: 0.3886\n",
      "Epoch 500/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0840 - categorical_accuracy: 0.3894 - val_loss: 94.3427 - val_categorical_accuracy: 0.3886\n",
      "Epoch 501/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3882 - val_loss: 94.3405 - val_categorical_accuracy: 0.3886\n",
      "Epoch 502/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3863 - val_loss: 94.3480 - val_categorical_accuracy: 0.3886\n",
      "Epoch 503/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3880 - val_loss: 94.3373 - val_categorical_accuracy: 0.3886\n",
      "Epoch 504/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0848 - categorical_accuracy: 0.3876 - val_loss: 94.3600 - val_categorical_accuracy: 0.3886\n",
      "Epoch 505/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3873 - val_loss: 94.3475 - val_categorical_accuracy: 0.3886\n",
      "Epoch 506/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0845 - categorical_accuracy: 0.3869 - val_loss: 94.3501 - val_categorical_accuracy: 0.3886\n",
      "Epoch 507/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0842 - categorical_accuracy: 0.3883 - val_loss: 94.3427 - val_categorical_accuracy: 0.3886\n",
      "Epoch 508/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0845 - categorical_accuracy: 0.3878 - val_loss: 94.3445 - val_categorical_accuracy: 0.3886\n",
      "Epoch 509/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3873 - val_loss: 94.3418 - val_categorical_accuracy: 0.3886\n",
      "Epoch 510/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3870 - val_loss: 94.3481 - val_categorical_accuracy: 0.3886\n",
      "Epoch 511/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0847 - categorical_accuracy: 0.3875 - val_loss: 94.3451 - val_categorical_accuracy: 0.3886\n",
      "Epoch 512/2000\n",
      "977/977 [==============================] - 11s 12ms/step - loss: 1.0850 - categorical_accuracy: 0.3869 - val_loss: 94.3489 - val_categorical_accuracy: 0.3886\n",
      "Epoch 513/2000\n",
      "977/977 [==============================] - 13s 14ms/step - loss: 1.0850 - categorical_accuracy: 0.3857 - val_loss: 94.3577 - val_categorical_accuracy: 0.3886\n",
      "Epoch 514/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0844 - categorical_accuracy: 0.3894 - val_loss: 94.3536 - val_categorical_accuracy: 0.3886\n",
      "Epoch 515/2000\n",
      "977/977 [==============================] - 12s 13ms/step - loss: 1.0845 - categorical_accuracy: 0.3880 - val_loss: 94.3435 - val_categorical_accuracy: 0.3886\n",
      "Epoch 516/2000\n",
      "977/977 [==============================] - 14s 14ms/step - loss: 1.0842 - categorical_accuracy: 0.3877 - val_loss: 94.3521 - val_categorical_accuracy: 0.3886\n",
      "Epoch 517/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0840 - categorical_accuracy: 0.3900 - val_loss: 94.3426 - val_categorical_accuracy: 0.3886\n",
      "Epoch 518/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0849 - categorical_accuracy: 0.3867 - val_loss: 94.3435 - val_categorical_accuracy: 0.3886\n",
      "Epoch 519/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0849 - categorical_accuracy: 0.3861 - val_loss: 94.3487 - val_categorical_accuracy: 0.3886\n",
      "Epoch 520/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0847 - categorical_accuracy: 0.3864 - val_loss: 94.3584 - val_categorical_accuracy: 0.3886\n",
      "Epoch 521/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3877 - val_loss: 94.3510 - val_categorical_accuracy: 0.3886\n",
      "Epoch 522/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3885 - val_loss: 94.3426 - val_categorical_accuracy: 0.3886\n",
      "Epoch 523/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0845 - categorical_accuracy: 0.3893 - val_loss: 94.3442 - val_categorical_accuracy: 0.3886\n",
      "Epoch 524/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0851 - categorical_accuracy: 0.3869 - val_loss: 94.3471 - val_categorical_accuracy: 0.3886\n",
      "Epoch 525/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0848 - categorical_accuracy: 0.3869 - val_loss: 94.3534 - val_categorical_accuracy: 0.3886\n",
      "Epoch 526/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0846 - categorical_accuracy: 0.3872 - val_loss: 94.3438 - val_categorical_accuracy: 0.3886\n",
      "Epoch 527/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0840 - categorical_accuracy: 0.3898 - val_loss: 94.3421 - val_categorical_accuracy: 0.3886\n",
      "Epoch 528/2000\n",
      "977/977 [==============================] - 12s 12ms/step - loss: 1.0843 - categorical_accuracy: 0.3888 - val_loss: 94.3482 - val_categorical_accuracy: 0.3886\n",
      "Epoch 529/2000\n",
      "977/977 [==============================] - 12s 13ms/step - loss: 1.0842 - categorical_accuracy: 0.3883 - val_loss: 94.3438 - val_categorical_accuracy: 0.3886\n",
      "Epoch 530/2000\n",
      "977/977 [==============================] - 12s 13ms/step - loss: 1.0844 - categorical_accuracy: 0.3878 - val_loss: 94.3472 - val_categorical_accuracy: 0.3886\n",
      "Epoch 531/2000\n",
      "977/977 [==============================] - 14s 14ms/step - loss: 1.0843 - categorical_accuracy: 0.3878 - val_loss: 94.3468 - val_categorical_accuracy: 0.3886\n",
      "Epoch 532/2000\n",
      "977/977 [==============================] - 13s 13ms/step - loss: 1.0837 - categorical_accuracy: 0.3882 - val_loss: 94.3502 - val_categorical_accuracy: 0.3886\n",
      "Epoch 533/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0846 - categorical_accuracy: 0.3873 - val_loss: 94.3482 - val_categorical_accuracy: 0.3886\n",
      "Epoch 534/2000\n",
      "977/977 [==============================] - 10s 11ms/step - loss: 1.0843 - categorical_accuracy: 0.3878 - val_loss: 94.3460 - val_categorical_accuracy: 0.3886\n",
      "Epoch 535/2000\n",
      "977/977 [==============================] - 11s 11ms/step - loss: 1.0850 - categorical_accuracy: 0.3875 - val_loss: 94.3482 - val_categorical_accuracy: 0.3886\n",
      "Epoch 536/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0843 - categorical_accuracy: 0.3874 - val_loss: 94.3527 - val_categorical_accuracy: 0.3886\n",
      "Epoch 537/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0844 - categorical_accuracy: 0.3881 - val_loss: 94.3467 - val_categorical_accuracy: 0.3886\n",
      "Epoch 538/2000\n",
      "977/977 [==============================] - 10s 10ms/step - loss: 1.0840 - categorical_accuracy: 0.3892 - val_loss: 94.3453 - val_categorical_accuracy: 0.3886\n",
      "Epoch 539/2000\n",
      "224/977 [=====>........................] - ETA: 6s - loss: 1.0865 - categorical_accuracy: 0.3862"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, verbose=1, validation_data=(X_dev, y_dev))    \n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(history.history)\n",
    "results.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel (\"Epochs\")\n",
    "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
    "plt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "# categorical_accuracy es el training accuracy\n",
    "# val_categorical_accuracy es el validation accuracy\n",
    "# loss es el training loss\n",
    "# val_loss es el validation loss\n",
    "\n",
    "# Overfitting:\n",
    "# Por un lado la Accuracy de los datos de entrenamiento aumenta con las epochs,\n",
    "# mientras que la Accuracy de los datos de validación disminuye o se mantiene constante a lo largo de las epochs. \n",
    "# La Loss de los datos de validación alcanza su mínimo después de pocos epochs y luego empieza a subir, \n",
    "# mientras que la Loss de los datos de entrenamiento disminuye linealmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy for the training set: \", results.categorical_accuracy.values[-1:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy for the development test set: \", results.val_categorical_accuracy.values[-1:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how the model predicts using the development test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_predictions=model.predict(X_dev).round(2) \n",
    "dev_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_rounded_predictions=np.round(dev_predictions)\n",
    "indices = np.argmax(dev_predictions,1)\n",
    "for row, index in zip(dev_rounded_predictions, indices): row[index]=1\n",
    "dev_rounded_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_correct_predictions = np.equal(np.argmax(dev_rounded_predictions,1),np.argmax(y_dev,1))\n",
    "print (dev_correct_predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter (dev_correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model if it is better than others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "model.save('./Modelos/EGG_prac1_ANN_model3.h5') # Change the name in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract\n",
    "\"\"\"\n",
    "new_model = keras.models.load_model('./Modelos/EGG_prac1_ANN_model3.h5')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Verify state\n",
    "new_predictions = new_model.predict(X_dev)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is also preserved:\n",
    "# you can resume training where you left off.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Final Test\n",
    "\n",
    "#### 10.1 - Load the final test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "total_records = 4 # CAMBIAR SI HAY MAS REGISTROS\n",
    "\n",
    "task1 = 122 # SE PUEDE CAMBIAR\n",
    "task2 = 123 # SE PUEDE CAMBIAR\n",
    "task3 = 127 # SE PUEDE CAMBIAR\n",
    "users = [\"0091\"] # SE PUEDE CAMBIAR\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def readRegisterAndReturnXy(user, total_records, task1, task2, task3 = \"\"):\n",
    "    lTaskData = []\n",
    "    for i_rec in range(1,total_records+1):\n",
    "            record = \"userS\"+user+\"f\"+str(i_rec)+\".mat\"\n",
    "            output = read_outputs(record) # output.task será y, output.data será x\n",
    "\n",
    "            if task3 != \"\":\n",
    "                outT = (output.task == task1) | (output.task == task2) | (output.task == task3) \n",
    "            else: \n",
    "                outT = (output.task == task1) | (output.task == task2)\n",
    "            outData = output.data[outT[:,0],0:np.shape(output.data)[1]]\n",
    "\n",
    "            outTask = output.task[outT[:,0]]\n",
    "            outTD = OutTaskData(outTask, outData)\n",
    "            lTaskData.append(outTD)\n",
    "\n",
    "    X_test, y_test = [],[]\n",
    "    for j in range(0,total_records):\n",
    "        X_test.extend(lTaskData[j].data)\n",
    "        y_test.extend(lTaskData[j].task)\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.ravel(np.array(y_test))\n",
    "\n",
    "    print (\"X_test:\",X_test.shape)\n",
    "    print (\"y_test:\",y_test.shape)\n",
    "\n",
    "    # ONE HOT ENCODER\n",
    "    encoder = make_pipeline(StandardScaler(), OneHotEncoder(categories=\"auto\", sparse=False)) # Function that one-hot encodes integers))\n",
    "    y_test = encoder.fit_transform (y_test.reshape(-1,1)) # y_one_hot\n",
    "\n",
    "    print(\"ONE HOT ENCODER:\")\n",
    "    print (\"X_test:\",X_test.shape)\n",
    "    print (\"y_test:\",y_test.shape)\n",
    "    \n",
    "    return X_test, y_test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "n_final_test = n_instances-n_train-n_dev\n",
    "\n",
    "x_final_test = attributes.values[n_train+n_dev:n_instances]\n",
    "t_final_test = label.values[n_train+n_dev:n_instances]\n",
    "\n",
    "print (\"x_test:\",x_final_test.shape)\n",
    "print (\"t_test:\",t_final_test.shape)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2 - Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def predictWithModel(model, X_test, y_test, task1, task2, task3=\"\"):\n",
    "    model.evaluate(X_test, y_test)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_rounded_predictions=np.round(test_predictions)\n",
    "    indices = np.argmax(test_predictions,1)\n",
    "    for row, index in zip(test_rounded_predictions, indices): row[index]=1\n",
    "    print(test_rounded_predictions[:20])\n",
    "    \n",
    "    # ACCURACY:\n",
    "    test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(y_test,1))\n",
    "    print()\n",
    "    print(test_correct_predictions)\n",
    "    print(type(test_correct_predictions))\n",
    "    final_test_prediction_results=Counter(test_correct_predictions)\n",
    "    \n",
    "    success = np.mean(test_rounded_predictions == y_test)*100\n",
    "    \n",
    "    return final_test_prediction_results, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\"0091\"]\n",
    "for u in users:   \n",
    "    print(\"USER:\", u)\n",
    "    #X_test, y_test = readRegisterAndReturnXy(u, total_records, 122, 123, 127)\n",
    "    accuracy, success = predictWithModel(model, X_test, y_test, 122, 123, 127)\n",
    "    print(u, accuracy, success)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(x_final_test, t_final_test) # Un 77 es un accuracy bajo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs computed by the neural network for the final testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test_predictions=model.predict(x_final_test)\n",
    "test_rounded_predictions=np.round(test_predictions)\n",
    "indices = np.argmax(test_predictions,1)\n",
    "for row, index in zip(test_rounded_predictions, indices): row[index]=1\n",
    "test_rounded_predictions[:20]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_final_test[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 30 predictions. True means that the neural network correctly classifies the input vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_correct_predictions = np.equal(np.argmax(test_rounded_predictions,1),np.argmax(t_final_test,1))\n",
    "# test_correct_predictions[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from collections import Counter\n",
    "final_test_prediction_results=Counter(test_correct_predictions)\n",
    "final_test_prediction_results\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test_prediction_results[True]/sum(final_test_prediction_results.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
